{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_sentiment_estimation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0yuZWNPw0g31xk3kdDbj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NakamuraSTS/PyTorch_advanced/blob/main/BERT_sentiment_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIe8lN3sdp4J",
        "outputId": "226d356d-293d-4561-89e1-9a1bbac568aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Yncgiwdvhm",
        "outputId": "6d13bbd6-3b9c-4d26-dec7-26783e72d677"
      },
      "source": [
        "%cd \"drive/MyDrive/pytorch_advanced/8_nlp_sentiment_bert\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/pytorch_advanced/8_nlp_sentiment_bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhUliqPmd6Go",
        "outputId": "998453de-3739-40c4-edd5-af364f72adb6"
      },
      "source": [
        "!pip install attrdict"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting attrdict\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from attrdict) (1.15.0)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrXYwnEYeFAr",
        "outputId": "5c1919b3-c15c-4482-d087-5472d57ea4c8"
      },
      "source": [
        "import json\n",
        "\n",
        "config_file = \"./weights/bert_config.json\"\n",
        "\n",
        "json_file = open(config_file, 'r')\n",
        "config = json.load(json_file)\n",
        "\n",
        "config"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhtnr6NseWx_",
        "outputId": "d2192e04-a42a-4542-8803-cd20e9d3aa21"
      },
      "source": [
        "from attrdict import AttrDict\n",
        "\n",
        "config = AttrDict(config)\n",
        "config.hidden_size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uRI1QpAeo9n"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertLayerNorm(nn.Module):\n",
        "  def __init__(self, hidden_size, eps=1e-12):\n",
        "    super(BertLayerNorm, self).__init__()\n",
        "\n",
        "    self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
        "    self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
        "    self.variance_epsilon = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    u = x.mean(-1, keepdim=True)\n",
        "    s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "    x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "    return self.gamma * x + self.beta"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jml12lVOf_wG"
      },
      "source": [
        "class BertEmbeddings(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertEmbeddings, self).__init__()\n",
        "\n",
        "    self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
        "    self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "    self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "    self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None):\n",
        "    words_embedding = self.word_embeddings(input_ids)\n",
        "\n",
        "    if token_type_ids is None:\n",
        "      token_type_ids = torch.zeros_like(input_ids)\n",
        "    token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    position_embeddings = self.position_embeddings(position_ids)\n",
        "\n",
        "    embeddings = words_embedding + position_embeddings + token_type_embeddings\n",
        "\n",
        "    embeddings = self.LayerNorm(embeddings)\n",
        "    embeddings = self.dropout(embeddings)\n",
        "\n",
        "    return embeddings"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feDn2vBzl_-f"
      },
      "source": [
        "import math\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertLayer, self).__init__()\n",
        "\n",
        "    self.attention = BertAttention(config)\n",
        "\n",
        "    self.intermediate = BertIntermediate(config)\n",
        "\n",
        "    self.output = BertOutput(config)\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask, attention_show_flg=False):\n",
        "    '''\n",
        "    hidden_states: output tensor of Embedder [batch_size, seq_len, hidden_size]\n",
        "    attention_mask: the same mask of transformer\n",
        "    attention_show_flg: a flag of returning weights of self-attention\n",
        "    '''\n",
        "\n",
        "    if attention_show_flg == True:\n",
        "      attention_output, attention_probs = self.attention(hidden_states, attention_mask, attention_show_flg)\n",
        "      intermediate_output = self.intermediate(attention_output)\n",
        "      layer_output = self.output(intermediate_output, attention_output)\n",
        "      return layer_output, attention_probs\n",
        "\n",
        "    elif attention_show_flg == False:\n",
        "      attention_output = self.attention(hidden_states, attention_mask, attention_show_flg)\n",
        "      intermediate_output = self.intermediate(attention_output)\n",
        "      layer_output = self.output(intermediate_output, attention_output)\n",
        "      return layer_output\n",
        "\n",
        "class BertAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertAttention, self).__init__()\n",
        "    self.selfattn = BertSelfAttention(config)\n",
        "    self.output = BertSelfOutput(config)\n",
        "\n",
        "  def forward(self, input_tensor, attention_mask, attention_show_flg):\n",
        "    if attention_show_flg ==True:\n",
        "      self_output, attention_probs = self.selfattn(input_tensor, attention_mask, attention_show_flg)\n",
        "      attention_output = self.output(self_output, input_tensor)\n",
        "      return attention_output, attention_probs\n",
        "\n",
        "    elif attention_show_flg == False:\n",
        "      self_output = self.selfattn(input_tensor, attention_mask, attention_show_flg)\n",
        "      attention_output = self.output(self_output, input_tensor)\n",
        "      return attention_output\n",
        "\n",
        "class BertSelfAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertSelfAttention, self).__init__()\n",
        "\n",
        "    self.num_attention_heads = config.num_attention_heads\n",
        "\n",
        "    self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "    self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "    self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "    self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "    self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "    self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "  def transpose_for_scores(self, x):\n",
        "    new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "    x = x.view(*new_x_shape)\n",
        "    return x.permute(0, 2, 1, 3)\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask, attention_show_flg=False):\n",
        "    mixed_query_layer = self.query(hidden_states)\n",
        "    mixed_key_layer = self.key(hidden_states)\n",
        "    mixed_value_layer = self.value(hidden_states)\n",
        "    \n",
        "    query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "    key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "    value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "\n",
        "    attention_scores = attention_scores + attention_mask\n",
        "\n",
        "    attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "    attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "    context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "    context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "    new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "    context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "    if attention_show_flg ==True:\n",
        "      return context_layer, attention_probs\n",
        "    elif attention_show_flg == False:\n",
        "      return context_layer\n",
        "\n",
        "class BertSelfOutput(nn.Module):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super(BertSelfOutput, self).__init__()\n",
        "\n",
        "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, hidden_states, input_tensor):\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.dropout(hidden_states)\n",
        "    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "    return hidden_states\n",
        "\n",
        "def gelu(x):\n",
        "  return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "class BertIntermediate(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertIntermediate, self).__init__()\n",
        "\n",
        "    self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "\n",
        "    self.intermediate_act_fn = gelu\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "    return hidden_states\n",
        "\n",
        "class BertOutput(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertOutput, self).__init__()\n",
        "\n",
        "    self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "\n",
        "    self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, hidden_states, input_tensor):\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.dropout(hidden_states)\n",
        "    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "    return hidden_states"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5OOmsWtD2T4"
      },
      "source": [
        "class BertEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertEncoder, self).__init__()\n",
        "\n",
        "    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True, attention_show_flg=False):\n",
        "    all_encoder_layers = []\n",
        "\n",
        "    for layer_module in self.layer:\n",
        "      if attention_show_flg == True:\n",
        "        hidden_states, attention_probs = layer_module(hidden_states, attention_mask, attention_show_flg)\n",
        "      elif attention_show_flg ==False:\n",
        "        hidden_states = layer_module(hidden_states, attention_mask, attention_show_flg)\n",
        "\n",
        "      if output_all_encoded_layers:\n",
        "        all_encoder_layers.append(hidden_states)\n",
        "\n",
        "    if not output_all_encoded_layers:\n",
        "      all_encoder_layers.append(hidden_states)\n",
        "\n",
        "    if attention_show_flg == True:\n",
        "      return all_encoder_layers, attention_probs\n",
        "    elif attention_show_flg == False:\n",
        "      return all_encoder_layers"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmGFf24GGBnO"
      },
      "source": [
        "class BertPooler(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertPooler, self).__init__()\n",
        "\n",
        "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    first_token_tensor = hidden_states[:, 0]\n",
        "    pooled_output = self.dense(first_token_tensor)\n",
        "    pooled_output = self.activation(pooled_output)\n",
        "    return pooled_output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYUW4_OLG4FN",
        "outputId": "beba486a-4ee8-4fa7-f72f-71bbe9abd2c3"
      },
      "source": [
        "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
        "print(\"tensor size of input word id: \", input_ids.shape)\n",
        "\n",
        "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
        "print(\"tensor size of input mask: \", attention_mask.shape)\n",
        "\n",
        "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
        "print(\"tensor size of input sentence id: \", token_type_ids.shape)\n",
        "\n",
        "embeddings = BertEmbeddings(config)\n",
        "encoder = BertEncoder(config)\n",
        "pooler = BertPooler(config)\n",
        "\n",
        "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
        "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "print(\"tensor size of extended mask: \", extended_attention_mask.shape)\n",
        "\n",
        "out1 = embeddings(input_ids, token_type_ids)\n",
        "print(\"tensor size of BertEmbedding output: \", out1.shape)\n",
        "\n",
        "out2 = encoder(out1, extended_attention_mask)\n",
        "print(\"tensor size of BertEncoder output: \", out2[0].shape)\n",
        "\n",
        "out3 = pooler(out2[-1])\n",
        "print(\"tensor size of BertPooler output: \", out3.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor size of input word id:  torch.Size([2, 5])\n",
            "tensor size of input mask:  torch.Size([2, 5])\n",
            "tensor size of input sentence id:  torch.Size([2, 5])\n",
            "tensor size of extended mask:  torch.Size([2, 1, 1, 5])\n",
            "tensor size of BertEmbedding output:  torch.Size([2, 5, 768])\n",
            "tensor size of BertEncoder output:  torch.Size([2, 5, 768])\n",
            "tensor size of BertPooler output:  torch.Size([2, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sme0X-D8JyhD"
      },
      "source": [
        "import torch\n",
        "\n",
        "class BertModel(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertModel, self).__init__()\n",
        "\n",
        "    self.embeddings = BertEmbeddings(config)\n",
        "    self.encoder = BertEncoder(config)\n",
        "    self.pooler = BertPooler(config)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True, attention_show_flg=False):\n",
        "    if attention_mask is None:\n",
        "      attention_mask = torch.ones_like(input_ids)\n",
        "    if token_type_ids is None:\n",
        "      token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
        "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "    embedding_output = self.embeddings(input_ids, token_type_ids)\n",
        "\n",
        "    if attention_show_flg == True:\n",
        "      encoded_layers, attention_probs = self.encoder(embedding_output, extended_attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "    elif attention_show_flg == False:\n",
        "      encoded_layers = self.encoder(embedding_output, extended_attention_mask, output_all_encoded_layers, attention_show_flg)\n",
        "\n",
        "    pooled_output = self.pooler(encoded_layers[-1])\n",
        "\n",
        "    if not output_all_encoded_layers:\n",
        "      encoded_layers = encoded_layers[-1]\n",
        "\n",
        "    if attention_show_flg == True:\n",
        "      return encoded_layers, pooled_output, attention_probs\n",
        "    elif attention_show_flg == False:\n",
        "      return encoded_layers, pooled_output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE1x-lR7SoXq",
        "outputId": "8e2b1425-53a4-4293-a887-20f993823fdf"
      },
      "source": [
        "net_bert = BertModel(config)\n",
        "\n",
        "encoded_layers, pooled_output, attention_probs = net(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, attention_show_flg=True)\n",
        "\n",
        "print(\"tensor size of encoded_layers: \", encoded_layers.shape)\n",
        "print(\"tensor size of pooled_output: \", pooled_output.shape)\n",
        "print(\"tensor size of attention_probs: \", attention_probs.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor size of encoded_layers:  torch.Size([2, 5, 768])\n",
            "tensor size of pooled_output:  torch.Size([2, 768])\n",
            "tensor size of attention_probs:  torch.Size([2, 12, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmJN802ZTS8Y",
        "outputId": "d7273e56-a843-4d57-803f-3bc8eaadb303"
      },
      "source": [
        "weights_path = \"./weights/pytorch_model.bin\"\n",
        "loaded_state_dict = torch.load(weights_path)\n",
        "\n",
        "for s in loaded_state_dict.keys():\n",
        "  print(s)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "cls.predictions.bias\n",
            "cls.predictions.transform.dense.weight\n",
            "cls.predictions.transform.dense.bias\n",
            "cls.predictions.transform.LayerNorm.gamma\n",
            "cls.predictions.transform.LayerNorm.beta\n",
            "cls.predictions.decoder.weight\n",
            "cls.seq_relationship.weight\n",
            "cls.seq_relationship.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GNBNCkvVC7p",
        "outputId": "e0a8b62e-0ec5-48a3-986e-2dad1e80da67"
      },
      "source": [
        "net_bert = BertModel(config)\n",
        "net.eval()\n",
        "\n",
        "param_names = []\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "  print(name)\n",
        "  param_names.append(name)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings.word_embeddings.weight\n",
            "embeddings.position_embeddings.weight\n",
            "embeddings.token_type_embeddings.weight\n",
            "embeddings.LayerNorm.gamma\n",
            "embeddings.LayerNorm.beta\n",
            "encoder.layer.0.attention.selfattn.query.weight\n",
            "encoder.layer.0.attention.selfattn.query.bias\n",
            "encoder.layer.0.attention.selfattn.key.weight\n",
            "encoder.layer.0.attention.selfattn.key.bias\n",
            "encoder.layer.0.attention.selfattn.value.weight\n",
            "encoder.layer.0.attention.selfattn.value.bias\n",
            "encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "encoder.layer.0.attention.output.LayerNorm.beta\n",
            "encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias\n",
            "encoder.layer.0.output.LayerNorm.gamma\n",
            "encoder.layer.0.output.LayerNorm.beta\n",
            "encoder.layer.1.attention.selfattn.query.weight\n",
            "encoder.layer.1.attention.selfattn.query.bias\n",
            "encoder.layer.1.attention.selfattn.key.weight\n",
            "encoder.layer.1.attention.selfattn.key.bias\n",
            "encoder.layer.1.attention.selfattn.value.weight\n",
            "encoder.layer.1.attention.selfattn.value.bias\n",
            "encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "encoder.layer.1.attention.output.LayerNorm.beta\n",
            "encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias\n",
            "encoder.layer.1.output.LayerNorm.gamma\n",
            "encoder.layer.1.output.LayerNorm.beta\n",
            "encoder.layer.2.attention.selfattn.query.weight\n",
            "encoder.layer.2.attention.selfattn.query.bias\n",
            "encoder.layer.2.attention.selfattn.key.weight\n",
            "encoder.layer.2.attention.selfattn.key.bias\n",
            "encoder.layer.2.attention.selfattn.value.weight\n",
            "encoder.layer.2.attention.selfattn.value.bias\n",
            "encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "encoder.layer.2.attention.output.LayerNorm.beta\n",
            "encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias\n",
            "encoder.layer.2.output.LayerNorm.gamma\n",
            "encoder.layer.2.output.LayerNorm.beta\n",
            "encoder.layer.3.attention.selfattn.query.weight\n",
            "encoder.layer.3.attention.selfattn.query.bias\n",
            "encoder.layer.3.attention.selfattn.key.weight\n",
            "encoder.layer.3.attention.selfattn.key.bias\n",
            "encoder.layer.3.attention.selfattn.value.weight\n",
            "encoder.layer.3.attention.selfattn.value.bias\n",
            "encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "encoder.layer.3.attention.output.LayerNorm.beta\n",
            "encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias\n",
            "encoder.layer.3.output.LayerNorm.gamma\n",
            "encoder.layer.3.output.LayerNorm.beta\n",
            "encoder.layer.4.attention.selfattn.query.weight\n",
            "encoder.layer.4.attention.selfattn.query.bias\n",
            "encoder.layer.4.attention.selfattn.key.weight\n",
            "encoder.layer.4.attention.selfattn.key.bias\n",
            "encoder.layer.4.attention.selfattn.value.weight\n",
            "encoder.layer.4.attention.selfattn.value.bias\n",
            "encoder.layer.4.attention.output.dense.weight\n",
            "encoder.layer.4.attention.output.dense.bias\n",
            "encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "encoder.layer.4.attention.output.LayerNorm.beta\n",
            "encoder.layer.4.intermediate.dense.weight\n",
            "encoder.layer.4.intermediate.dense.bias\n",
            "encoder.layer.4.output.dense.weight\n",
            "encoder.layer.4.output.dense.bias\n",
            "encoder.layer.4.output.LayerNorm.gamma\n",
            "encoder.layer.4.output.LayerNorm.beta\n",
            "encoder.layer.5.attention.selfattn.query.weight\n",
            "encoder.layer.5.attention.selfattn.query.bias\n",
            "encoder.layer.5.attention.selfattn.key.weight\n",
            "encoder.layer.5.attention.selfattn.key.bias\n",
            "encoder.layer.5.attention.selfattn.value.weight\n",
            "encoder.layer.5.attention.selfattn.value.bias\n",
            "encoder.layer.5.attention.output.dense.weight\n",
            "encoder.layer.5.attention.output.dense.bias\n",
            "encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "encoder.layer.5.attention.output.LayerNorm.beta\n",
            "encoder.layer.5.intermediate.dense.weight\n",
            "encoder.layer.5.intermediate.dense.bias\n",
            "encoder.layer.5.output.dense.weight\n",
            "encoder.layer.5.output.dense.bias\n",
            "encoder.layer.5.output.LayerNorm.gamma\n",
            "encoder.layer.5.output.LayerNorm.beta\n",
            "encoder.layer.6.attention.selfattn.query.weight\n",
            "encoder.layer.6.attention.selfattn.query.bias\n",
            "encoder.layer.6.attention.selfattn.key.weight\n",
            "encoder.layer.6.attention.selfattn.key.bias\n",
            "encoder.layer.6.attention.selfattn.value.weight\n",
            "encoder.layer.6.attention.selfattn.value.bias\n",
            "encoder.layer.6.attention.output.dense.weight\n",
            "encoder.layer.6.attention.output.dense.bias\n",
            "encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "encoder.layer.6.attention.output.LayerNorm.beta\n",
            "encoder.layer.6.intermediate.dense.weight\n",
            "encoder.layer.6.intermediate.dense.bias\n",
            "encoder.layer.6.output.dense.weight\n",
            "encoder.layer.6.output.dense.bias\n",
            "encoder.layer.6.output.LayerNorm.gamma\n",
            "encoder.layer.6.output.LayerNorm.beta\n",
            "encoder.layer.7.attention.selfattn.query.weight\n",
            "encoder.layer.7.attention.selfattn.query.bias\n",
            "encoder.layer.7.attention.selfattn.key.weight\n",
            "encoder.layer.7.attention.selfattn.key.bias\n",
            "encoder.layer.7.attention.selfattn.value.weight\n",
            "encoder.layer.7.attention.selfattn.value.bias\n",
            "encoder.layer.7.attention.output.dense.weight\n",
            "encoder.layer.7.attention.output.dense.bias\n",
            "encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "encoder.layer.7.attention.output.LayerNorm.beta\n",
            "encoder.layer.7.intermediate.dense.weight\n",
            "encoder.layer.7.intermediate.dense.bias\n",
            "encoder.layer.7.output.dense.weight\n",
            "encoder.layer.7.output.dense.bias\n",
            "encoder.layer.7.output.LayerNorm.gamma\n",
            "encoder.layer.7.output.LayerNorm.beta\n",
            "encoder.layer.8.attention.selfattn.query.weight\n",
            "encoder.layer.8.attention.selfattn.query.bias\n",
            "encoder.layer.8.attention.selfattn.key.weight\n",
            "encoder.layer.8.attention.selfattn.key.bias\n",
            "encoder.layer.8.attention.selfattn.value.weight\n",
            "encoder.layer.8.attention.selfattn.value.bias\n",
            "encoder.layer.8.attention.output.dense.weight\n",
            "encoder.layer.8.attention.output.dense.bias\n",
            "encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "encoder.layer.8.attention.output.LayerNorm.beta\n",
            "encoder.layer.8.intermediate.dense.weight\n",
            "encoder.layer.8.intermediate.dense.bias\n",
            "encoder.layer.8.output.dense.weight\n",
            "encoder.layer.8.output.dense.bias\n",
            "encoder.layer.8.output.LayerNorm.gamma\n",
            "encoder.layer.8.output.LayerNorm.beta\n",
            "encoder.layer.9.attention.selfattn.query.weight\n",
            "encoder.layer.9.attention.selfattn.query.bias\n",
            "encoder.layer.9.attention.selfattn.key.weight\n",
            "encoder.layer.9.attention.selfattn.key.bias\n",
            "encoder.layer.9.attention.selfattn.value.weight\n",
            "encoder.layer.9.attention.selfattn.value.bias\n",
            "encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "encoder.layer.9.attention.output.LayerNorm.beta\n",
            "encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias\n",
            "encoder.layer.9.output.LayerNorm.gamma\n",
            "encoder.layer.9.output.LayerNorm.beta\n",
            "encoder.layer.10.attention.selfattn.query.weight\n",
            "encoder.layer.10.attention.selfattn.query.bias\n",
            "encoder.layer.10.attention.selfattn.key.weight\n",
            "encoder.layer.10.attention.selfattn.key.bias\n",
            "encoder.layer.10.attention.selfattn.value.weight\n",
            "encoder.layer.10.attention.selfattn.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "encoder.layer.10.attention.output.LayerNorm.beta\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.gamma\n",
            "encoder.layer.10.output.LayerNorm.beta\n",
            "encoder.layer.11.attention.selfattn.query.weight\n",
            "encoder.layer.11.attention.selfattn.query.bias\n",
            "encoder.layer.11.attention.selfattn.key.weight\n",
            "encoder.layer.11.attention.selfattn.key.bias\n",
            "encoder.layer.11.attention.selfattn.value.weight\n",
            "encoder.layer.11.attention.selfattn.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "encoder.layer.11.attention.output.LayerNorm.beta\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.gamma\n",
            "encoder.layer.11.output.LayerNorm.beta\n",
            "pooler.dense.weight\n",
            "pooler.dense.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCgdJCVoVc3I",
        "outputId": "ae03ad7e-4fd4-402f-c9b2-862d1c805bf1"
      },
      "source": [
        "new_state_dict = net_bert.state_dict().copy()\n",
        "\n",
        "for index, (key_name, value) in enumerate(loaded_state_dict.items()):\n",
        "  name = param_names[index]\n",
        "  new_state_dict[name] = value\n",
        "  print(str(key_name)+\" => \"+ str(name))\n",
        "\n",
        "  if index+1 >= len(param_names):\n",
        "    break\n",
        "\n",
        "net_bert.load_state_dict(new_state_dict)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight => embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight => embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight => embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma => embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta => embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight => encoder.layer.0.attention.selfattn.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias => encoder.layer.0.attention.selfattn.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight => encoder.layer.0.attention.selfattn.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias => encoder.layer.0.attention.selfattn.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight => encoder.layer.0.attention.selfattn.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias => encoder.layer.0.attention.selfattn.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight => encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias => encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma => encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta => encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight => encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias => encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight => encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias => encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma => encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta => encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight => encoder.layer.1.attention.selfattn.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias => encoder.layer.1.attention.selfattn.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight => encoder.layer.1.attention.selfattn.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias => encoder.layer.1.attention.selfattn.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight => encoder.layer.1.attention.selfattn.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias => encoder.layer.1.attention.selfattn.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight => encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias => encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma => encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta => encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight => encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias => encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight => encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias => encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma => encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta => encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight => encoder.layer.2.attention.selfattn.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias => encoder.layer.2.attention.selfattn.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight => encoder.layer.2.attention.selfattn.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias => encoder.layer.2.attention.selfattn.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight => encoder.layer.2.attention.selfattn.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias => encoder.layer.2.attention.selfattn.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight => encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias => encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma => encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta => encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight => encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias => encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight => encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias => encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma => encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta => encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight => encoder.layer.3.attention.selfattn.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias => encoder.layer.3.attention.selfattn.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight => encoder.layer.3.attention.selfattn.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias => encoder.layer.3.attention.selfattn.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight => encoder.layer.3.attention.selfattn.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias => encoder.layer.3.attention.selfattn.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight => encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias => encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma => encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta => encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight => encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias => encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight => encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias => encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma => encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta => encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight => encoder.layer.4.attention.selfattn.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias => encoder.layer.4.attention.selfattn.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight => encoder.layer.4.attention.selfattn.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias => encoder.layer.4.attention.selfattn.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight => encoder.layer.4.attention.selfattn.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias => encoder.layer.4.attention.selfattn.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight => encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias => encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma => encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta => encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight => encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias => encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight => encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias => encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma => encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta => encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight => encoder.layer.5.attention.selfattn.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias => encoder.layer.5.attention.selfattn.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight => encoder.layer.5.attention.selfattn.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias => encoder.layer.5.attention.selfattn.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight => encoder.layer.5.attention.selfattn.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias => encoder.layer.5.attention.selfattn.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight => encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias => encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma => encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta => encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight => encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias => encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight => encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias => encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma => encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta => encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight => encoder.layer.6.attention.selfattn.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias => encoder.layer.6.attention.selfattn.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight => encoder.layer.6.attention.selfattn.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias => encoder.layer.6.attention.selfattn.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight => encoder.layer.6.attention.selfattn.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias => encoder.layer.6.attention.selfattn.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight => encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias => encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma => encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta => encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight => encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias => encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight => encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias => encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma => encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta => encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight => encoder.layer.7.attention.selfattn.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias => encoder.layer.7.attention.selfattn.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight => encoder.layer.7.attention.selfattn.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias => encoder.layer.7.attention.selfattn.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight => encoder.layer.7.attention.selfattn.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias => encoder.layer.7.attention.selfattn.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight => encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias => encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma => encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta => encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight => encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias => encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight => encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias => encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma => encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta => encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight => encoder.layer.8.attention.selfattn.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias => encoder.layer.8.attention.selfattn.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight => encoder.layer.8.attention.selfattn.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias => encoder.layer.8.attention.selfattn.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight => encoder.layer.8.attention.selfattn.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias => encoder.layer.8.attention.selfattn.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight => encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias => encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma => encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta => encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight => encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias => encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight => encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias => encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma => encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta => encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight => encoder.layer.9.attention.selfattn.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias => encoder.layer.9.attention.selfattn.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight => encoder.layer.9.attention.selfattn.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias => encoder.layer.9.attention.selfattn.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight => encoder.layer.9.attention.selfattn.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias => encoder.layer.9.attention.selfattn.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight => encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias => encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma => encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta => encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight => encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias => encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight => encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias => encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma => encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta => encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight => encoder.layer.10.attention.selfattn.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias => encoder.layer.10.attention.selfattn.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight => encoder.layer.10.attention.selfattn.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias => encoder.layer.10.attention.selfattn.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight => encoder.layer.10.attention.selfattn.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias => encoder.layer.10.attention.selfattn.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight => encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias => encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma => encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta => encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight => encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias => encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight => encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias => encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma => encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta => encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight => encoder.layer.11.attention.selfattn.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias => encoder.layer.11.attention.selfattn.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight => encoder.layer.11.attention.selfattn.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias => encoder.layer.11.attention.selfattn.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight => encoder.layer.11.attention.selfattn.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias => encoder.layer.11.attention.selfattn.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight => encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias => encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma => encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta => encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight => encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias => encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight => encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias => encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma => encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta => encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight => pooler.dense.weight\n",
            "bert.pooler.dense.bias => pooler.dense.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9NPI-4YWP83"
      },
      "source": [
        "import collections\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "  vocab = collections.OrderedDict()\n",
        "\n",
        "  ids_to_tokens = collections.OrderedDict()\n",
        "  index = 0\n",
        "\n",
        "  with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
        "    while True:\n",
        "      token = reader.readline()\n",
        "      if not token:\n",
        "        break\n",
        "      token = token.strip()\n",
        "\n",
        "      vocab[token] = index\n",
        "      ids_to_tokens[index] = token\n",
        "      index += 1\n",
        "\n",
        "  return vocab, ids_to_tokens\n",
        "\n",
        "vocab_file = \"./vocab/bert-base-uncased-vocab.txt\"\n",
        "vocab, ids_to_tokens = load_vocab(vocab_file)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DJtCNxCt3m2",
        "outputId": "00fdd774-c941-46f8-ebe4-3f8c460b6315"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('[PAD]', 0),\n",
              "             ('[unused0]', 1),\n",
              "             ('[unused1]', 2),\n",
              "             ('[unused2]', 3),\n",
              "             ('[unused3]', 4),\n",
              "             ('[unused4]', 5),\n",
              "             ('[unused5]', 6),\n",
              "             ('[unused6]', 7),\n",
              "             ('[unused7]', 8),\n",
              "             ('[unused8]', 9),\n",
              "             ('[unused9]', 10),\n",
              "             ('[unused10]', 11),\n",
              "             ('[unused11]', 12),\n",
              "             ('[unused12]', 13),\n",
              "             ('[unused13]', 14),\n",
              "             ('[unused14]', 15),\n",
              "             ('[unused15]', 16),\n",
              "             ('[unused16]', 17),\n",
              "             ('[unused17]', 18),\n",
              "             ('[unused18]', 19),\n",
              "             ('[unused19]', 20),\n",
              "             ('[unused20]', 21),\n",
              "             ('[unused21]', 22),\n",
              "             ('[unused22]', 23),\n",
              "             ('[unused23]', 24),\n",
              "             ('[unused24]', 25),\n",
              "             ('[unused25]', 26),\n",
              "             ('[unused26]', 27),\n",
              "             ('[unused27]', 28),\n",
              "             ('[unused28]', 29),\n",
              "             ('[unused29]', 30),\n",
              "             ('[unused30]', 31),\n",
              "             ('[unused31]', 32),\n",
              "             ('[unused32]', 33),\n",
              "             ('[unused33]', 34),\n",
              "             ('[unused34]', 35),\n",
              "             ('[unused35]', 36),\n",
              "             ('[unused36]', 37),\n",
              "             ('[unused37]', 38),\n",
              "             ('[unused38]', 39),\n",
              "             ('[unused39]', 40),\n",
              "             ('[unused40]', 41),\n",
              "             ('[unused41]', 42),\n",
              "             ('[unused42]', 43),\n",
              "             ('[unused43]', 44),\n",
              "             ('[unused44]', 45),\n",
              "             ('[unused45]', 46),\n",
              "             ('[unused46]', 47),\n",
              "             ('[unused47]', 48),\n",
              "             ('[unused48]', 49),\n",
              "             ('[unused49]', 50),\n",
              "             ('[unused50]', 51),\n",
              "             ('[unused51]', 52),\n",
              "             ('[unused52]', 53),\n",
              "             ('[unused53]', 54),\n",
              "             ('[unused54]', 55),\n",
              "             ('[unused55]', 56),\n",
              "             ('[unused56]', 57),\n",
              "             ('[unused57]', 58),\n",
              "             ('[unused58]', 59),\n",
              "             ('[unused59]', 60),\n",
              "             ('[unused60]', 61),\n",
              "             ('[unused61]', 62),\n",
              "             ('[unused62]', 63),\n",
              "             ('[unused63]', 64),\n",
              "             ('[unused64]', 65),\n",
              "             ('[unused65]', 66),\n",
              "             ('[unused66]', 67),\n",
              "             ('[unused67]', 68),\n",
              "             ('[unused68]', 69),\n",
              "             ('[unused69]', 70),\n",
              "             ('[unused70]', 71),\n",
              "             ('[unused71]', 72),\n",
              "             ('[unused72]', 73),\n",
              "             ('[unused73]', 74),\n",
              "             ('[unused74]', 75),\n",
              "             ('[unused75]', 76),\n",
              "             ('[unused76]', 77),\n",
              "             ('[unused77]', 78),\n",
              "             ('[unused78]', 79),\n",
              "             ('[unused79]', 80),\n",
              "             ('[unused80]', 81),\n",
              "             ('[unused81]', 82),\n",
              "             ('[unused82]', 83),\n",
              "             ('[unused83]', 84),\n",
              "             ('[unused84]', 85),\n",
              "             ('[unused85]', 86),\n",
              "             ('[unused86]', 87),\n",
              "             ('[unused87]', 88),\n",
              "             ('[unused88]', 89),\n",
              "             ('[unused89]', 90),\n",
              "             ('[unused90]', 91),\n",
              "             ('[unused91]', 92),\n",
              "             ('[unused92]', 93),\n",
              "             ('[unused93]', 94),\n",
              "             ('[unused94]', 95),\n",
              "             ('[unused95]', 96),\n",
              "             ('[unused96]', 97),\n",
              "             ('[unused97]', 98),\n",
              "             ('[unused98]', 99),\n",
              "             ('[UNK]', 100),\n",
              "             ('[CLS]', 101),\n",
              "             ('[SEP]', 102),\n",
              "             ('[MASK]', 103),\n",
              "             ('[unused99]', 104),\n",
              "             ('[unused100]', 105),\n",
              "             ('[unused101]', 106),\n",
              "             ('[unused102]', 107),\n",
              "             ('[unused103]', 108),\n",
              "             ('[unused104]', 109),\n",
              "             ('[unused105]', 110),\n",
              "             ('[unused106]', 111),\n",
              "             ('[unused107]', 112),\n",
              "             ('[unused108]', 113),\n",
              "             ('[unused109]', 114),\n",
              "             ('[unused110]', 115),\n",
              "             ('[unused111]', 116),\n",
              "             ('[unused112]', 117),\n",
              "             ('[unused113]', 118),\n",
              "             ('[unused114]', 119),\n",
              "             ('[unused115]', 120),\n",
              "             ('[unused116]', 121),\n",
              "             ('[unused117]', 122),\n",
              "             ('[unused118]', 123),\n",
              "             ('[unused119]', 124),\n",
              "             ('[unused120]', 125),\n",
              "             ('[unused121]', 126),\n",
              "             ('[unused122]', 127),\n",
              "             ('[unused123]', 128),\n",
              "             ('[unused124]', 129),\n",
              "             ('[unused125]', 130),\n",
              "             ('[unused126]', 131),\n",
              "             ('[unused127]', 132),\n",
              "             ('[unused128]', 133),\n",
              "             ('[unused129]', 134),\n",
              "             ('[unused130]', 135),\n",
              "             ('[unused131]', 136),\n",
              "             ('[unused132]', 137),\n",
              "             ('[unused133]', 138),\n",
              "             ('[unused134]', 139),\n",
              "             ('[unused135]', 140),\n",
              "             ('[unused136]', 141),\n",
              "             ('[unused137]', 142),\n",
              "             ('[unused138]', 143),\n",
              "             ('[unused139]', 144),\n",
              "             ('[unused140]', 145),\n",
              "             ('[unused141]', 146),\n",
              "             ('[unused142]', 147),\n",
              "             ('[unused143]', 148),\n",
              "             ('[unused144]', 149),\n",
              "             ('[unused145]', 150),\n",
              "             ('[unused146]', 151),\n",
              "             ('[unused147]', 152),\n",
              "             ('[unused148]', 153),\n",
              "             ('[unused149]', 154),\n",
              "             ('[unused150]', 155),\n",
              "             ('[unused151]', 156),\n",
              "             ('[unused152]', 157),\n",
              "             ('[unused153]', 158),\n",
              "             ('[unused154]', 159),\n",
              "             ('[unused155]', 160),\n",
              "             ('[unused156]', 161),\n",
              "             ('[unused157]', 162),\n",
              "             ('[unused158]', 163),\n",
              "             ('[unused159]', 164),\n",
              "             ('[unused160]', 165),\n",
              "             ('[unused161]', 166),\n",
              "             ('[unused162]', 167),\n",
              "             ('[unused163]', 168),\n",
              "             ('[unused164]', 169),\n",
              "             ('[unused165]', 170),\n",
              "             ('[unused166]', 171),\n",
              "             ('[unused167]', 172),\n",
              "             ('[unused168]', 173),\n",
              "             ('[unused169]', 174),\n",
              "             ('[unused170]', 175),\n",
              "             ('[unused171]', 176),\n",
              "             ('[unused172]', 177),\n",
              "             ('[unused173]', 178),\n",
              "             ('[unused174]', 179),\n",
              "             ('[unused175]', 180),\n",
              "             ('[unused176]', 181),\n",
              "             ('[unused177]', 182),\n",
              "             ('[unused178]', 183),\n",
              "             ('[unused179]', 184),\n",
              "             ('[unused180]', 185),\n",
              "             ('[unused181]', 186),\n",
              "             ('[unused182]', 187),\n",
              "             ('[unused183]', 188),\n",
              "             ('[unused184]', 189),\n",
              "             ('[unused185]', 190),\n",
              "             ('[unused186]', 191),\n",
              "             ('[unused187]', 192),\n",
              "             ('[unused188]', 193),\n",
              "             ('[unused189]', 194),\n",
              "             ('[unused190]', 195),\n",
              "             ('[unused191]', 196),\n",
              "             ('[unused192]', 197),\n",
              "             ('[unused193]', 198),\n",
              "             ('[unused194]', 199),\n",
              "             ('[unused195]', 200),\n",
              "             ('[unused196]', 201),\n",
              "             ('[unused197]', 202),\n",
              "             ('[unused198]', 203),\n",
              "             ('[unused199]', 204),\n",
              "             ('[unused200]', 205),\n",
              "             ('[unused201]', 206),\n",
              "             ('[unused202]', 207),\n",
              "             ('[unused203]', 208),\n",
              "             ('[unused204]', 209),\n",
              "             ('[unused205]', 210),\n",
              "             ('[unused206]', 211),\n",
              "             ('[unused207]', 212),\n",
              "             ('[unused208]', 213),\n",
              "             ('[unused209]', 214),\n",
              "             ('[unused210]', 215),\n",
              "             ('[unused211]', 216),\n",
              "             ('[unused212]', 217),\n",
              "             ('[unused213]', 218),\n",
              "             ('[unused214]', 219),\n",
              "             ('[unused215]', 220),\n",
              "             ('[unused216]', 221),\n",
              "             ('[unused217]', 222),\n",
              "             ('[unused218]', 223),\n",
              "             ('[unused219]', 224),\n",
              "             ('[unused220]', 225),\n",
              "             ('[unused221]', 226),\n",
              "             ('[unused222]', 227),\n",
              "             ('[unused223]', 228),\n",
              "             ('[unused224]', 229),\n",
              "             ('[unused225]', 230),\n",
              "             ('[unused226]', 231),\n",
              "             ('[unused227]', 232),\n",
              "             ('[unused228]', 233),\n",
              "             ('[unused229]', 234),\n",
              "             ('[unused230]', 235),\n",
              "             ('[unused231]', 236),\n",
              "             ('[unused232]', 237),\n",
              "             ('[unused233]', 238),\n",
              "             ('[unused234]', 239),\n",
              "             ('[unused235]', 240),\n",
              "             ('[unused236]', 241),\n",
              "             ('[unused237]', 242),\n",
              "             ('[unused238]', 243),\n",
              "             ('[unused239]', 244),\n",
              "             ('[unused240]', 245),\n",
              "             ('[unused241]', 246),\n",
              "             ('[unused242]', 247),\n",
              "             ('[unused243]', 248),\n",
              "             ('[unused244]', 249),\n",
              "             ('[unused245]', 250),\n",
              "             ('[unused246]', 251),\n",
              "             ('[unused247]', 252),\n",
              "             ('[unused248]', 253),\n",
              "             ('[unused249]', 254),\n",
              "             ('[unused250]', 255),\n",
              "             ('[unused251]', 256),\n",
              "             ('[unused252]', 257),\n",
              "             ('[unused253]', 258),\n",
              "             ('[unused254]', 259),\n",
              "             ('[unused255]', 260),\n",
              "             ('[unused256]', 261),\n",
              "             ('[unused257]', 262),\n",
              "             ('[unused258]', 263),\n",
              "             ('[unused259]', 264),\n",
              "             ('[unused260]', 265),\n",
              "             ('[unused261]', 266),\n",
              "             ('[unused262]', 267),\n",
              "             ('[unused263]', 268),\n",
              "             ('[unused264]', 269),\n",
              "             ('[unused265]', 270),\n",
              "             ('[unused266]', 271),\n",
              "             ('[unused267]', 272),\n",
              "             ('[unused268]', 273),\n",
              "             ('[unused269]', 274),\n",
              "             ('[unused270]', 275),\n",
              "             ('[unused271]', 276),\n",
              "             ('[unused272]', 277),\n",
              "             ('[unused273]', 278),\n",
              "             ('[unused274]', 279),\n",
              "             ('[unused275]', 280),\n",
              "             ('[unused276]', 281),\n",
              "             ('[unused277]', 282),\n",
              "             ('[unused278]', 283),\n",
              "             ('[unused279]', 284),\n",
              "             ('[unused280]', 285),\n",
              "             ('[unused281]', 286),\n",
              "             ('[unused282]', 287),\n",
              "             ('[unused283]', 288),\n",
              "             ('[unused284]', 289),\n",
              "             ('[unused285]', 290),\n",
              "             ('[unused286]', 291),\n",
              "             ('[unused287]', 292),\n",
              "             ('[unused288]', 293),\n",
              "             ('[unused289]', 294),\n",
              "             ('[unused290]', 295),\n",
              "             ('[unused291]', 296),\n",
              "             ('[unused292]', 297),\n",
              "             ('[unused293]', 298),\n",
              "             ('[unused294]', 299),\n",
              "             ('[unused295]', 300),\n",
              "             ('[unused296]', 301),\n",
              "             ('[unused297]', 302),\n",
              "             ('[unused298]', 303),\n",
              "             ('[unused299]', 304),\n",
              "             ('[unused300]', 305),\n",
              "             ('[unused301]', 306),\n",
              "             ('[unused302]', 307),\n",
              "             ('[unused303]', 308),\n",
              "             ('[unused304]', 309),\n",
              "             ('[unused305]', 310),\n",
              "             ('[unused306]', 311),\n",
              "             ('[unused307]', 312),\n",
              "             ('[unused308]', 313),\n",
              "             ('[unused309]', 314),\n",
              "             ('[unused310]', 315),\n",
              "             ('[unused311]', 316),\n",
              "             ('[unused312]', 317),\n",
              "             ('[unused313]', 318),\n",
              "             ('[unused314]', 319),\n",
              "             ('[unused315]', 320),\n",
              "             ('[unused316]', 321),\n",
              "             ('[unused317]', 322),\n",
              "             ('[unused318]', 323),\n",
              "             ('[unused319]', 324),\n",
              "             ('[unused320]', 325),\n",
              "             ('[unused321]', 326),\n",
              "             ('[unused322]', 327),\n",
              "             ('[unused323]', 328),\n",
              "             ('[unused324]', 329),\n",
              "             ('[unused325]', 330),\n",
              "             ('[unused326]', 331),\n",
              "             ('[unused327]', 332),\n",
              "             ('[unused328]', 333),\n",
              "             ('[unused329]', 334),\n",
              "             ('[unused330]', 335),\n",
              "             ('[unused331]', 336),\n",
              "             ('[unused332]', 337),\n",
              "             ('[unused333]', 338),\n",
              "             ('[unused334]', 339),\n",
              "             ('[unused335]', 340),\n",
              "             ('[unused336]', 341),\n",
              "             ('[unused337]', 342),\n",
              "             ('[unused338]', 343),\n",
              "             ('[unused339]', 344),\n",
              "             ('[unused340]', 345),\n",
              "             ('[unused341]', 346),\n",
              "             ('[unused342]', 347),\n",
              "             ('[unused343]', 348),\n",
              "             ('[unused344]', 349),\n",
              "             ('[unused345]', 350),\n",
              "             ('[unused346]', 351),\n",
              "             ('[unused347]', 352),\n",
              "             ('[unused348]', 353),\n",
              "             ('[unused349]', 354),\n",
              "             ('[unused350]', 355),\n",
              "             ('[unused351]', 356),\n",
              "             ('[unused352]', 357),\n",
              "             ('[unused353]', 358),\n",
              "             ('[unused354]', 359),\n",
              "             ('[unused355]', 360),\n",
              "             ('[unused356]', 361),\n",
              "             ('[unused357]', 362),\n",
              "             ('[unused358]', 363),\n",
              "             ('[unused359]', 364),\n",
              "             ('[unused360]', 365),\n",
              "             ('[unused361]', 366),\n",
              "             ('[unused362]', 367),\n",
              "             ('[unused363]', 368),\n",
              "             ('[unused364]', 369),\n",
              "             ('[unused365]', 370),\n",
              "             ('[unused366]', 371),\n",
              "             ('[unused367]', 372),\n",
              "             ('[unused368]', 373),\n",
              "             ('[unused369]', 374),\n",
              "             ('[unused370]', 375),\n",
              "             ('[unused371]', 376),\n",
              "             ('[unused372]', 377),\n",
              "             ('[unused373]', 378),\n",
              "             ('[unused374]', 379),\n",
              "             ('[unused375]', 380),\n",
              "             ('[unused376]', 381),\n",
              "             ('[unused377]', 382),\n",
              "             ('[unused378]', 383),\n",
              "             ('[unused379]', 384),\n",
              "             ('[unused380]', 385),\n",
              "             ('[unused381]', 386),\n",
              "             ('[unused382]', 387),\n",
              "             ('[unused383]', 388),\n",
              "             ('[unused384]', 389),\n",
              "             ('[unused385]', 390),\n",
              "             ('[unused386]', 391),\n",
              "             ('[unused387]', 392),\n",
              "             ('[unused388]', 393),\n",
              "             ('[unused389]', 394),\n",
              "             ('[unused390]', 395),\n",
              "             ('[unused391]', 396),\n",
              "             ('[unused392]', 397),\n",
              "             ('[unused393]', 398),\n",
              "             ('[unused394]', 399),\n",
              "             ('[unused395]', 400),\n",
              "             ('[unused396]', 401),\n",
              "             ('[unused397]', 402),\n",
              "             ('[unused398]', 403),\n",
              "             ('[unused399]', 404),\n",
              "             ('[unused400]', 405),\n",
              "             ('[unused401]', 406),\n",
              "             ('[unused402]', 407),\n",
              "             ('[unused403]', 408),\n",
              "             ('[unused404]', 409),\n",
              "             ('[unused405]', 410),\n",
              "             ('[unused406]', 411),\n",
              "             ('[unused407]', 412),\n",
              "             ('[unused408]', 413),\n",
              "             ('[unused409]', 414),\n",
              "             ('[unused410]', 415),\n",
              "             ('[unused411]', 416),\n",
              "             ('[unused412]', 417),\n",
              "             ('[unused413]', 418),\n",
              "             ('[unused414]', 419),\n",
              "             ('[unused415]', 420),\n",
              "             ('[unused416]', 421),\n",
              "             ('[unused417]', 422),\n",
              "             ('[unused418]', 423),\n",
              "             ('[unused419]', 424),\n",
              "             ('[unused420]', 425),\n",
              "             ('[unused421]', 426),\n",
              "             ('[unused422]', 427),\n",
              "             ('[unused423]', 428),\n",
              "             ('[unused424]', 429),\n",
              "             ('[unused425]', 430),\n",
              "             ('[unused426]', 431),\n",
              "             ('[unused427]', 432),\n",
              "             ('[unused428]', 433),\n",
              "             ('[unused429]', 434),\n",
              "             ('[unused430]', 435),\n",
              "             ('[unused431]', 436),\n",
              "             ('[unused432]', 437),\n",
              "             ('[unused433]', 438),\n",
              "             ('[unused434]', 439),\n",
              "             ('[unused435]', 440),\n",
              "             ('[unused436]', 441),\n",
              "             ('[unused437]', 442),\n",
              "             ('[unused438]', 443),\n",
              "             ('[unused439]', 444),\n",
              "             ('[unused440]', 445),\n",
              "             ('[unused441]', 446),\n",
              "             ('[unused442]', 447),\n",
              "             ('[unused443]', 448),\n",
              "             ('[unused444]', 449),\n",
              "             ('[unused445]', 450),\n",
              "             ('[unused446]', 451),\n",
              "             ('[unused447]', 452),\n",
              "             ('[unused448]', 453),\n",
              "             ('[unused449]', 454),\n",
              "             ('[unused450]', 455),\n",
              "             ('[unused451]', 456),\n",
              "             ('[unused452]', 457),\n",
              "             ('[unused453]', 458),\n",
              "             ('[unused454]', 459),\n",
              "             ('[unused455]', 460),\n",
              "             ('[unused456]', 461),\n",
              "             ('[unused457]', 462),\n",
              "             ('[unused458]', 463),\n",
              "             ('[unused459]', 464),\n",
              "             ('[unused460]', 465),\n",
              "             ('[unused461]', 466),\n",
              "             ('[unused462]', 467),\n",
              "             ('[unused463]', 468),\n",
              "             ('[unused464]', 469),\n",
              "             ('[unused465]', 470),\n",
              "             ('[unused466]', 471),\n",
              "             ('[unused467]', 472),\n",
              "             ('[unused468]', 473),\n",
              "             ('[unused469]', 474),\n",
              "             ('[unused470]', 475),\n",
              "             ('[unused471]', 476),\n",
              "             ('[unused472]', 477),\n",
              "             ('[unused473]', 478),\n",
              "             ('[unused474]', 479),\n",
              "             ('[unused475]', 480),\n",
              "             ('[unused476]', 481),\n",
              "             ('[unused477]', 482),\n",
              "             ('[unused478]', 483),\n",
              "             ('[unused479]', 484),\n",
              "             ('[unused480]', 485),\n",
              "             ('[unused481]', 486),\n",
              "             ('[unused482]', 487),\n",
              "             ('[unused483]', 488),\n",
              "             ('[unused484]', 489),\n",
              "             ('[unused485]', 490),\n",
              "             ('[unused486]', 491),\n",
              "             ('[unused487]', 492),\n",
              "             ('[unused488]', 493),\n",
              "             ('[unused489]', 494),\n",
              "             ('[unused490]', 495),\n",
              "             ('[unused491]', 496),\n",
              "             ('[unused492]', 497),\n",
              "             ('[unused493]', 498),\n",
              "             ('[unused494]', 499),\n",
              "             ('[unused495]', 500),\n",
              "             ('[unused496]', 501),\n",
              "             ('[unused497]', 502),\n",
              "             ('[unused498]', 503),\n",
              "             ('[unused499]', 504),\n",
              "             ('[unused500]', 505),\n",
              "             ('[unused501]', 506),\n",
              "             ('[unused502]', 507),\n",
              "             ('[unused503]', 508),\n",
              "             ('[unused504]', 509),\n",
              "             ('[unused505]', 510),\n",
              "             ('[unused506]', 511),\n",
              "             ('[unused507]', 512),\n",
              "             ('[unused508]', 513),\n",
              "             ('[unused509]', 514),\n",
              "             ('[unused510]', 515),\n",
              "             ('[unused511]', 516),\n",
              "             ('[unused512]', 517),\n",
              "             ('[unused513]', 518),\n",
              "             ('[unused514]', 519),\n",
              "             ('[unused515]', 520),\n",
              "             ('[unused516]', 521),\n",
              "             ('[unused517]', 522),\n",
              "             ('[unused518]', 523),\n",
              "             ('[unused519]', 524),\n",
              "             ('[unused520]', 525),\n",
              "             ('[unused521]', 526),\n",
              "             ('[unused522]', 527),\n",
              "             ('[unused523]', 528),\n",
              "             ('[unused524]', 529),\n",
              "             ('[unused525]', 530),\n",
              "             ('[unused526]', 531),\n",
              "             ('[unused527]', 532),\n",
              "             ('[unused528]', 533),\n",
              "             ('[unused529]', 534),\n",
              "             ('[unused530]', 535),\n",
              "             ('[unused531]', 536),\n",
              "             ('[unused532]', 537),\n",
              "             ('[unused533]', 538),\n",
              "             ('[unused534]', 539),\n",
              "             ('[unused535]', 540),\n",
              "             ('[unused536]', 541),\n",
              "             ('[unused537]', 542),\n",
              "             ('[unused538]', 543),\n",
              "             ('[unused539]', 544),\n",
              "             ('[unused540]', 545),\n",
              "             ('[unused541]', 546),\n",
              "             ('[unused542]', 547),\n",
              "             ('[unused543]', 548),\n",
              "             ('[unused544]', 549),\n",
              "             ('[unused545]', 550),\n",
              "             ('[unused546]', 551),\n",
              "             ('[unused547]', 552),\n",
              "             ('[unused548]', 553),\n",
              "             ('[unused549]', 554),\n",
              "             ('[unused550]', 555),\n",
              "             ('[unused551]', 556),\n",
              "             ('[unused552]', 557),\n",
              "             ('[unused553]', 558),\n",
              "             ('[unused554]', 559),\n",
              "             ('[unused555]', 560),\n",
              "             ('[unused556]', 561),\n",
              "             ('[unused557]', 562),\n",
              "             ('[unused558]', 563),\n",
              "             ('[unused559]', 564),\n",
              "             ('[unused560]', 565),\n",
              "             ('[unused561]', 566),\n",
              "             ('[unused562]', 567),\n",
              "             ('[unused563]', 568),\n",
              "             ('[unused564]', 569),\n",
              "             ('[unused565]', 570),\n",
              "             ('[unused566]', 571),\n",
              "             ('[unused567]', 572),\n",
              "             ('[unused568]', 573),\n",
              "             ('[unused569]', 574),\n",
              "             ('[unused570]', 575),\n",
              "             ('[unused571]', 576),\n",
              "             ('[unused572]', 577),\n",
              "             ('[unused573]', 578),\n",
              "             ('[unused574]', 579),\n",
              "             ('[unused575]', 580),\n",
              "             ('[unused576]', 581),\n",
              "             ('[unused577]', 582),\n",
              "             ('[unused578]', 583),\n",
              "             ('[unused579]', 584),\n",
              "             ('[unused580]', 585),\n",
              "             ('[unused581]', 586),\n",
              "             ('[unused582]', 587),\n",
              "             ('[unused583]', 588),\n",
              "             ('[unused584]', 589),\n",
              "             ('[unused585]', 590),\n",
              "             ('[unused586]', 591),\n",
              "             ('[unused587]', 592),\n",
              "             ('[unused588]', 593),\n",
              "             ('[unused589]', 594),\n",
              "             ('[unused590]', 595),\n",
              "             ('[unused591]', 596),\n",
              "             ('[unused592]', 597),\n",
              "             ('[unused593]', 598),\n",
              "             ('[unused594]', 599),\n",
              "             ('[unused595]', 600),\n",
              "             ('[unused596]', 601),\n",
              "             ('[unused597]', 602),\n",
              "             ('[unused598]', 603),\n",
              "             ('[unused599]', 604),\n",
              "             ('[unused600]', 605),\n",
              "             ('[unused601]', 606),\n",
              "             ('[unused602]', 607),\n",
              "             ('[unused603]', 608),\n",
              "             ('[unused604]', 609),\n",
              "             ('[unused605]', 610),\n",
              "             ('[unused606]', 611),\n",
              "             ('[unused607]', 612),\n",
              "             ('[unused608]', 613),\n",
              "             ('[unused609]', 614),\n",
              "             ('[unused610]', 615),\n",
              "             ('[unused611]', 616),\n",
              "             ('[unused612]', 617),\n",
              "             ('[unused613]', 618),\n",
              "             ('[unused614]', 619),\n",
              "             ('[unused615]', 620),\n",
              "             ('[unused616]', 621),\n",
              "             ('[unused617]', 622),\n",
              "             ('[unused618]', 623),\n",
              "             ('[unused619]', 624),\n",
              "             ('[unused620]', 625),\n",
              "             ('[unused621]', 626),\n",
              "             ('[unused622]', 627),\n",
              "             ('[unused623]', 628),\n",
              "             ('[unused624]', 629),\n",
              "             ('[unused625]', 630),\n",
              "             ('[unused626]', 631),\n",
              "             ('[unused627]', 632),\n",
              "             ('[unused628]', 633),\n",
              "             ('[unused629]', 634),\n",
              "             ('[unused630]', 635),\n",
              "             ('[unused631]', 636),\n",
              "             ('[unused632]', 637),\n",
              "             ('[unused633]', 638),\n",
              "             ('[unused634]', 639),\n",
              "             ('[unused635]', 640),\n",
              "             ('[unused636]', 641),\n",
              "             ('[unused637]', 642),\n",
              "             ('[unused638]', 643),\n",
              "             ('[unused639]', 644),\n",
              "             ('[unused640]', 645),\n",
              "             ('[unused641]', 646),\n",
              "             ('[unused642]', 647),\n",
              "             ('[unused643]', 648),\n",
              "             ('[unused644]', 649),\n",
              "             ('[unused645]', 650),\n",
              "             ('[unused646]', 651),\n",
              "             ('[unused647]', 652),\n",
              "             ('[unused648]', 653),\n",
              "             ('[unused649]', 654),\n",
              "             ('[unused650]', 655),\n",
              "             ('[unused651]', 656),\n",
              "             ('[unused652]', 657),\n",
              "             ('[unused653]', 658),\n",
              "             ('[unused654]', 659),\n",
              "             ('[unused655]', 660),\n",
              "             ('[unused656]', 661),\n",
              "             ('[unused657]', 662),\n",
              "             ('[unused658]', 663),\n",
              "             ('[unused659]', 664),\n",
              "             ('[unused660]', 665),\n",
              "             ('[unused661]', 666),\n",
              "             ('[unused662]', 667),\n",
              "             ('[unused663]', 668),\n",
              "             ('[unused664]', 669),\n",
              "             ('[unused665]', 670),\n",
              "             ('[unused666]', 671),\n",
              "             ('[unused667]', 672),\n",
              "             ('[unused668]', 673),\n",
              "             ('[unused669]', 674),\n",
              "             ('[unused670]', 675),\n",
              "             ('[unused671]', 676),\n",
              "             ('[unused672]', 677),\n",
              "             ('[unused673]', 678),\n",
              "             ('[unused674]', 679),\n",
              "             ('[unused675]', 680),\n",
              "             ('[unused676]', 681),\n",
              "             ('[unused677]', 682),\n",
              "             ('[unused678]', 683),\n",
              "             ('[unused679]', 684),\n",
              "             ('[unused680]', 685),\n",
              "             ('[unused681]', 686),\n",
              "             ('[unused682]', 687),\n",
              "             ('[unused683]', 688),\n",
              "             ('[unused684]', 689),\n",
              "             ('[unused685]', 690),\n",
              "             ('[unused686]', 691),\n",
              "             ('[unused687]', 692),\n",
              "             ('[unused688]', 693),\n",
              "             ('[unused689]', 694),\n",
              "             ('[unused690]', 695),\n",
              "             ('[unused691]', 696),\n",
              "             ('[unused692]', 697),\n",
              "             ('[unused693]', 698),\n",
              "             ('[unused694]', 699),\n",
              "             ('[unused695]', 700),\n",
              "             ('[unused696]', 701),\n",
              "             ('[unused697]', 702),\n",
              "             ('[unused698]', 703),\n",
              "             ('[unused699]', 704),\n",
              "             ('[unused700]', 705),\n",
              "             ('[unused701]', 706),\n",
              "             ('[unused702]', 707),\n",
              "             ('[unused703]', 708),\n",
              "             ('[unused704]', 709),\n",
              "             ('[unused705]', 710),\n",
              "             ('[unused706]', 711),\n",
              "             ('[unused707]', 712),\n",
              "             ('[unused708]', 713),\n",
              "             ('[unused709]', 714),\n",
              "             ('[unused710]', 715),\n",
              "             ('[unused711]', 716),\n",
              "             ('[unused712]', 717),\n",
              "             ('[unused713]', 718),\n",
              "             ('[unused714]', 719),\n",
              "             ('[unused715]', 720),\n",
              "             ('[unused716]', 721),\n",
              "             ('[unused717]', 722),\n",
              "             ('[unused718]', 723),\n",
              "             ('[unused719]', 724),\n",
              "             ('[unused720]', 725),\n",
              "             ('[unused721]', 726),\n",
              "             ('[unused722]', 727),\n",
              "             ('[unused723]', 728),\n",
              "             ('[unused724]', 729),\n",
              "             ('[unused725]', 730),\n",
              "             ('[unused726]', 731),\n",
              "             ('[unused727]', 732),\n",
              "             ('[unused728]', 733),\n",
              "             ('[unused729]', 734),\n",
              "             ('[unused730]', 735),\n",
              "             ('[unused731]', 736),\n",
              "             ('[unused732]', 737),\n",
              "             ('[unused733]', 738),\n",
              "             ('[unused734]', 739),\n",
              "             ('[unused735]', 740),\n",
              "             ('[unused736]', 741),\n",
              "             ('[unused737]', 742),\n",
              "             ('[unused738]', 743),\n",
              "             ('[unused739]', 744),\n",
              "             ('[unused740]', 745),\n",
              "             ('[unused741]', 746),\n",
              "             ('[unused742]', 747),\n",
              "             ('[unused743]', 748),\n",
              "             ('[unused744]', 749),\n",
              "             ('[unused745]', 750),\n",
              "             ('[unused746]', 751),\n",
              "             ('[unused747]', 752),\n",
              "             ('[unused748]', 753),\n",
              "             ('[unused749]', 754),\n",
              "             ('[unused750]', 755),\n",
              "             ('[unused751]', 756),\n",
              "             ('[unused752]', 757),\n",
              "             ('[unused753]', 758),\n",
              "             ('[unused754]', 759),\n",
              "             ('[unused755]', 760),\n",
              "             ('[unused756]', 761),\n",
              "             ('[unused757]', 762),\n",
              "             ('[unused758]', 763),\n",
              "             ('[unused759]', 764),\n",
              "             ('[unused760]', 765),\n",
              "             ('[unused761]', 766),\n",
              "             ('[unused762]', 767),\n",
              "             ('[unused763]', 768),\n",
              "             ('[unused764]', 769),\n",
              "             ('[unused765]', 770),\n",
              "             ('[unused766]', 771),\n",
              "             ('[unused767]', 772),\n",
              "             ('[unused768]', 773),\n",
              "             ('[unused769]', 774),\n",
              "             ('[unused770]', 775),\n",
              "             ('[unused771]', 776),\n",
              "             ('[unused772]', 777),\n",
              "             ('[unused773]', 778),\n",
              "             ('[unused774]', 779),\n",
              "             ('[unused775]', 780),\n",
              "             ('[unused776]', 781),\n",
              "             ('[unused777]', 782),\n",
              "             ('[unused778]', 783),\n",
              "             ('[unused779]', 784),\n",
              "             ('[unused780]', 785),\n",
              "             ('[unused781]', 786),\n",
              "             ('[unused782]', 787),\n",
              "             ('[unused783]', 788),\n",
              "             ('[unused784]', 789),\n",
              "             ('[unused785]', 790),\n",
              "             ('[unused786]', 791),\n",
              "             ('[unused787]', 792),\n",
              "             ('[unused788]', 793),\n",
              "             ('[unused789]', 794),\n",
              "             ('[unused790]', 795),\n",
              "             ('[unused791]', 796),\n",
              "             ('[unused792]', 797),\n",
              "             ('[unused793]', 798),\n",
              "             ('[unused794]', 799),\n",
              "             ('[unused795]', 800),\n",
              "             ('[unused796]', 801),\n",
              "             ('[unused797]', 802),\n",
              "             ('[unused798]', 803),\n",
              "             ('[unused799]', 804),\n",
              "             ('[unused800]', 805),\n",
              "             ('[unused801]', 806),\n",
              "             ('[unused802]', 807),\n",
              "             ('[unused803]', 808),\n",
              "             ('[unused804]', 809),\n",
              "             ('[unused805]', 810),\n",
              "             ('[unused806]', 811),\n",
              "             ('[unused807]', 812),\n",
              "             ('[unused808]', 813),\n",
              "             ('[unused809]', 814),\n",
              "             ('[unused810]', 815),\n",
              "             ('[unused811]', 816),\n",
              "             ('[unused812]', 817),\n",
              "             ('[unused813]', 818),\n",
              "             ('[unused814]', 819),\n",
              "             ('[unused815]', 820),\n",
              "             ('[unused816]', 821),\n",
              "             ('[unused817]', 822),\n",
              "             ('[unused818]', 823),\n",
              "             ('[unused819]', 824),\n",
              "             ('[unused820]', 825),\n",
              "             ('[unused821]', 826),\n",
              "             ('[unused822]', 827),\n",
              "             ('[unused823]', 828),\n",
              "             ('[unused824]', 829),\n",
              "             ('[unused825]', 830),\n",
              "             ('[unused826]', 831),\n",
              "             ('[unused827]', 832),\n",
              "             ('[unused828]', 833),\n",
              "             ('[unused829]', 834),\n",
              "             ('[unused830]', 835),\n",
              "             ('[unused831]', 836),\n",
              "             ('[unused832]', 837),\n",
              "             ('[unused833]', 838),\n",
              "             ('[unused834]', 839),\n",
              "             ('[unused835]', 840),\n",
              "             ('[unused836]', 841),\n",
              "             ('[unused837]', 842),\n",
              "             ('[unused838]', 843),\n",
              "             ('[unused839]', 844),\n",
              "             ('[unused840]', 845),\n",
              "             ('[unused841]', 846),\n",
              "             ('[unused842]', 847),\n",
              "             ('[unused843]', 848),\n",
              "             ('[unused844]', 849),\n",
              "             ('[unused845]', 850),\n",
              "             ('[unused846]', 851),\n",
              "             ('[unused847]', 852),\n",
              "             ('[unused848]', 853),\n",
              "             ('[unused849]', 854),\n",
              "             ('[unused850]', 855),\n",
              "             ('[unused851]', 856),\n",
              "             ('[unused852]', 857),\n",
              "             ('[unused853]', 858),\n",
              "             ('[unused854]', 859),\n",
              "             ('[unused855]', 860),\n",
              "             ('[unused856]', 861),\n",
              "             ('[unused857]', 862),\n",
              "             ('[unused858]', 863),\n",
              "             ('[unused859]', 864),\n",
              "             ('[unused860]', 865),\n",
              "             ('[unused861]', 866),\n",
              "             ('[unused862]', 867),\n",
              "             ('[unused863]', 868),\n",
              "             ('[unused864]', 869),\n",
              "             ('[unused865]', 870),\n",
              "             ('[unused866]', 871),\n",
              "             ('[unused867]', 872),\n",
              "             ('[unused868]', 873),\n",
              "             ('[unused869]', 874),\n",
              "             ('[unused870]', 875),\n",
              "             ('[unused871]', 876),\n",
              "             ('[unused872]', 877),\n",
              "             ('[unused873]', 878),\n",
              "             ('[unused874]', 879),\n",
              "             ('[unused875]', 880),\n",
              "             ('[unused876]', 881),\n",
              "             ('[unused877]', 882),\n",
              "             ('[unused878]', 883),\n",
              "             ('[unused879]', 884),\n",
              "             ('[unused880]', 885),\n",
              "             ('[unused881]', 886),\n",
              "             ('[unused882]', 887),\n",
              "             ('[unused883]', 888),\n",
              "             ('[unused884]', 889),\n",
              "             ('[unused885]', 890),\n",
              "             ('[unused886]', 891),\n",
              "             ('[unused887]', 892),\n",
              "             ('[unused888]', 893),\n",
              "             ('[unused889]', 894),\n",
              "             ('[unused890]', 895),\n",
              "             ('[unused891]', 896),\n",
              "             ('[unused892]', 897),\n",
              "             ('[unused893]', 898),\n",
              "             ('[unused894]', 899),\n",
              "             ('[unused895]', 900),\n",
              "             ('[unused896]', 901),\n",
              "             ('[unused897]', 902),\n",
              "             ('[unused898]', 903),\n",
              "             ('[unused899]', 904),\n",
              "             ('[unused900]', 905),\n",
              "             ('[unused901]', 906),\n",
              "             ('[unused902]', 907),\n",
              "             ('[unused903]', 908),\n",
              "             ('[unused904]', 909),\n",
              "             ('[unused905]', 910),\n",
              "             ('[unused906]', 911),\n",
              "             ('[unused907]', 912),\n",
              "             ('[unused908]', 913),\n",
              "             ('[unused909]', 914),\n",
              "             ('[unused910]', 915),\n",
              "             ('[unused911]', 916),\n",
              "             ('[unused912]', 917),\n",
              "             ('[unused913]', 918),\n",
              "             ('[unused914]', 919),\n",
              "             ('[unused915]', 920),\n",
              "             ('[unused916]', 921),\n",
              "             ('[unused917]', 922),\n",
              "             ('[unused918]', 923),\n",
              "             ('[unused919]', 924),\n",
              "             ('[unused920]', 925),\n",
              "             ('[unused921]', 926),\n",
              "             ('[unused922]', 927),\n",
              "             ('[unused923]', 928),\n",
              "             ('[unused924]', 929),\n",
              "             ('[unused925]', 930),\n",
              "             ('[unused926]', 931),\n",
              "             ('[unused927]', 932),\n",
              "             ('[unused928]', 933),\n",
              "             ('[unused929]', 934),\n",
              "             ('[unused930]', 935),\n",
              "             ('[unused931]', 936),\n",
              "             ('[unused932]', 937),\n",
              "             ('[unused933]', 938),\n",
              "             ('[unused934]', 939),\n",
              "             ('[unused935]', 940),\n",
              "             ('[unused936]', 941),\n",
              "             ('[unused937]', 942),\n",
              "             ('[unused938]', 943),\n",
              "             ('[unused939]', 944),\n",
              "             ('[unused940]', 945),\n",
              "             ('[unused941]', 946),\n",
              "             ('[unused942]', 947),\n",
              "             ('[unused943]', 948),\n",
              "             ('[unused944]', 949),\n",
              "             ('[unused945]', 950),\n",
              "             ('[unused946]', 951),\n",
              "             ('[unused947]', 952),\n",
              "             ('[unused948]', 953),\n",
              "             ('[unused949]', 954),\n",
              "             ('[unused950]', 955),\n",
              "             ('[unused951]', 956),\n",
              "             ('[unused952]', 957),\n",
              "             ('[unused953]', 958),\n",
              "             ('[unused954]', 959),\n",
              "             ('[unused955]', 960),\n",
              "             ('[unused956]', 961),\n",
              "             ('[unused957]', 962),\n",
              "             ('[unused958]', 963),\n",
              "             ('[unused959]', 964),\n",
              "             ('[unused960]', 965),\n",
              "             ('[unused961]', 966),\n",
              "             ('[unused962]', 967),\n",
              "             ('[unused963]', 968),\n",
              "             ('[unused964]', 969),\n",
              "             ('[unused965]', 970),\n",
              "             ('[unused966]', 971),\n",
              "             ('[unused967]', 972),\n",
              "             ('[unused968]', 973),\n",
              "             ('[unused969]', 974),\n",
              "             ('[unused970]', 975),\n",
              "             ('[unused971]', 976),\n",
              "             ('[unused972]', 977),\n",
              "             ('[unused973]', 978),\n",
              "             ('[unused974]', 979),\n",
              "             ('[unused975]', 980),\n",
              "             ('[unused976]', 981),\n",
              "             ('[unused977]', 982),\n",
              "             ('[unused978]', 983),\n",
              "             ('[unused979]', 984),\n",
              "             ('[unused980]', 985),\n",
              "             ('[unused981]', 986),\n",
              "             ('[unused982]', 987),\n",
              "             ('[unused983]', 988),\n",
              "             ('[unused984]', 989),\n",
              "             ('[unused985]', 990),\n",
              "             ('[unused986]', 991),\n",
              "             ('[unused987]', 992),\n",
              "             ('[unused988]', 993),\n",
              "             ('[unused989]', 994),\n",
              "             ('[unused990]', 995),\n",
              "             ('[unused991]', 996),\n",
              "             ('[unused992]', 997),\n",
              "             ('[unused993]', 998),\n",
              "             ('!', 999),\n",
              "             ...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suPL9s1lt5zV"
      },
      "source": [
        "from utils.tokenizer import BasicTokenizer, WordpieceTokenizer\n",
        "\n",
        "class BertTokenizer(object):\n",
        "  def __init__(self, vocab_file, do_lower_case=True):\n",
        "    self.vocab, self.ids_to_tokens = load_vocab(vocab_file)\n",
        "\n",
        "    never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")\n",
        "\n",
        "    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case, never_split=never_split)\n",
        "    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    split_tokens = []\n",
        "    for token in self.basic_tokenizer.tokenize(text):\n",
        "      for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "        split_tokens.append(sub_token)\n",
        "    return split_tokens\n",
        "\n",
        "  def convert_tokens_to_ids(self, tokens):\n",
        "    ids = []\n",
        "    for token in tokens:\n",
        "      ids.append(self.vocab[token])\n",
        "    return ids\n",
        "\n",
        "  def convert_ids_to_tokens(self, ids):\n",
        "    tokens = []\n",
        "    for i in ids:\n",
        "      tokens.append(self.ids_to_tokens[i])\n",
        "    return tokens"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVWbhFL_wCn8",
        "outputId": "93a6ab2a-bb87-4b94-c785-0309e33537fa"
      },
      "source": [
        "text_1 = \"[CLS] I accessed the bank account. [SEP]\"\n",
        "text_2 = \"[CLS] He transferred the deposit money into the bank account. [SEP]\"\n",
        "text_3 = \"[CLS] We play soccer at the bank of the river. [SEP]\"\n",
        "\n",
        "tokenizer = BertTokenizer(vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "tokenized_text_1 = tokenizer.tokenize(text_1)\n",
        "tokenized_text_2 = tokenizer.tokenize(text_2)\n",
        "tokenized_text_3 = tokenizer.tokenize(text_3)\n",
        "\n",
        "print(tokenized_text_1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'i', 'accessed', 'the', 'bank', 'account', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOc41iFUwZ35",
        "outputId": "47be4e89-2322-4301-d357-e0efb85f01d4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokenized_text_1)\n",
        "indexed_tokens_2 = tokenizer.convert_tokens_to_ids(tokenized_text_2)\n",
        "indexed_tokens_3 = tokenizer.convert_tokens_to_ids(tokenized_text_3)\n",
        "\n",
        "bank_posi_1 = np.where(np.array(tokenized_text_1) == \"bank\")[0][0]\n",
        "bank_posi_2 = np.where(np.array(tokenized_text_2) == \"bank\")[0][0]\n",
        "bank_posi_3 = np.where(np.array(tokenized_text_3) == \"bank\")[0][0]\n",
        "\n",
        "print(np.where(np.array(tokenized_text_1) == \"bank\"))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([4]),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D2ED80pzpVv",
        "outputId": "e5df2597-cee6-4a09-9883-79f07eb7dec0"
      },
      "source": [
        "print(indexed_tokens_1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1045, 11570, 1996, 2924, 4070, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75p5uq5zyyto",
        "outputId": "8149f213-1c6a-400a-965b-474bc0d34b32"
      },
      "source": [
        "tokens_tensor_1 = torch.tensor([indexed_tokens_1])\n",
        "tokens_tensor_2 = torch.tensor([indexed_tokens_2])\n",
        "tokens_tensor_3 = torch.tensor([indexed_tokens_3])\n",
        "\n",
        "bank_word_id = tokenizer.convert_tokens_to_ids([\"bank\"])[0]\n",
        "\n",
        "print(tokens_tensor_1)\n",
        "print(bank_word_id)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  1045, 11570,  1996,  2924,  4070,  1012,   102]])\n",
            "2924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdDSCLLRzhgo"
      },
      "source": [
        "with torch.no_grad():\n",
        "  encoded_layers_1, _ = net(tokens_tensor_1, output_all_encoded_layers=True)\n",
        "  encoded_layers_2, _ = net(tokens_tensor_2, output_all_encoded_layers=True)\n",
        "  encoded_layers_3, _ = net(tokens_tensor_3, output_all_encoded_layers=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1a5vOkB0aJ-"
      },
      "source": [
        "bank_vector_0 = net.embeddings.word_embeddings.weight[bank_word_id]\n",
        "\n",
        "bank_vector_1_1 = encoded_layers_1[0][0, bank_posi_1]\n",
        "bank_vector_1_12 = encoded_layers_1[11][0, bank_posi_1]\n",
        "\n",
        "bank_vector_2_1 = encoded_layers_2[0][0, bank_posi_2]\n",
        "bank_vector_2_12 = encoded_layers_2[11][0, bank_posi_2]\n",
        "\n",
        "bank_vector_3_1 = encoded_layers_3[0][0, bank_posi_3]\n",
        "bank_vector_3_12 = encoded_layers_3[11][0, bank_posi_3]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdYBNcRt1GZW",
        "outputId": "4d991f13-167f-498f-80b2-5d7f007eb7b8"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"similarity of first vector and first sentence 1 : \", F.cosine_similarity(bank_vector_0, bank_vector_1_1, dim=0))\n",
        "print(\"similarity of first vector and 12th sentence 1 : \", F.cosine_similarity(bank_vector_0, bank_vector_1_12, dim=0))\n",
        "\n",
        "print(\"similarity of 1st sentence 1 and 1st sentence 2 : \", F.cosine_similarity(bank_vector_1_1, bank_vector_2_1, dim=0))\n",
        "print(\"similarity of 1st sentence 1 and 1st sentence 3 : \", F.cosine_similarity(bank_vector_1_1, bank_vector_3_1, dim=0))\n",
        "\n",
        "print(\"similarity of 12th sentence 1 and 12th sentence 2 : \", F.cosine_similarity(bank_vector_1_12, bank_vector_2_12, dim=0))\n",
        "print(\"similarity of 12th sentence 1 and 12th sentence 3 : \", F.cosine_similarity(bank_vector_1_12, bank_vector_3_12, dim=0))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similarity of first vector and first sentence 1 :  tensor(0.6814, grad_fn=<DivBackward0>)\n",
            "similarity of first vector and 12th sentence 1 :  tensor(0.2276, grad_fn=<DivBackward0>)\n",
            "similarity of 1st sentence 1 and 1st sentence 2 :  tensor(0.8968)\n",
            "similarity of 1st sentence 1 and 1st sentence 3 :  tensor(0.7584)\n",
            "similarity of 12th sentence 1 and 12th sentence 2 :  tensor(0.8796)\n",
            "similarity of 12th sentence 1 and 12th sentence 3 :  tensor(0.4814)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca2p8rg72F9I"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocessing_text(text):\n",
        "  text = re.sub('<br />', '', text)\n",
        "\n",
        "  for p in string.punctuation:\n",
        "    if (p == \".\") or (p == \",\"):\n",
        "      continue\n",
        "    else:\n",
        "      text = text.replace(p, \" \")\n",
        "\n",
        "  text = text.replace(\".\", \" . \")\n",
        "  text = text.replace(\",\", \" , \")\n",
        "  return text\n",
        "\n",
        "tokenizer_bert = BertTokenizer(vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "def tokenizer_with_preprocessing(text, tokenizer=tokenizer_bert.tokenize):\n",
        "  text = preprocessing_text(text)\n",
        "  ret = tokenizer(text)\n",
        "  return ret"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOPM31zD3yqN"
      },
      "source": [
        "import torchtext\n",
        "\n",
        "max_length = 256\n",
        "\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                            lower=True, include_lengths=True, batch_first=True, \n",
        "                            fix_length=max_length, init_token=\"[CLS]\",\n",
        "                            eos_token=\"[SEP]\", pad_token=\"[PAD]\", unk_token=\"[UNK]\")\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3rrXEhW4kDi"
      },
      "source": [
        "import random\n",
        "\n",
        "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path=\"./data/\", train=\"IMDb_train.tsv\", test=\"IMDb_test.tsv\", format=\"tsv\",\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)]\n",
        ")\n",
        "\n",
        "train_ds, val_ds = train_val_ds.split(split_ratio=0.8, random_state=random.seed(1234))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oM5fobT5fDt"
      },
      "source": [
        "vocab_bert, ids_to_tokens_bert = load_vocab(vocab_file=\"./vocab/bert-base-uncased-vocab.txt\")\n",
        "\n",
        "TEXT.build_vocab(train_ds, min_freq=1)\n",
        "TEXT.vocab.stoi = vocab_bert"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykmNI236Kmz"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dl = torchtext.data.Iterator(train_ds, batch_size=batch_size, train=True)\n",
        "val_dl = torchtext.data.Iterator(val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "test_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iGoDx3K6vrl",
        "outputId": "a3462e8a-bc77-4df6-d0c5-c24fc8aa9966"
      },
      "source": [
        "batch = next(iter(val_dl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[  101,  2087,  1997,  ...,  2023,  3185,   102],\n",
            "        [  101, 10166,  2061,  ...,     0,     0,     0],\n",
            "        [  101,  6823, 13038,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2758,  5557,  ...,  2412,  2113,   102],\n",
            "        [  101,  2023,  2143,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2001,  ...,     0,     0,     0]]), tensor([256, 226, 199, 256, 209, 233, 144, 256, 256, 221, 225, 256, 128, 184,\n",
            "        127, 256, 256, 256,  74, 256, 215, 176,  71, 256, 188, 256, 132, 256,\n",
            "        256, 256, 135, 232]))\n",
            "tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
            "        0, 1, 1, 1, 0, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmouOAul65kp",
        "outputId": "53c8dee3-f438-40fc-b631-16ef5f80f160"
      },
      "source": [
        "text_minibatch_1 = (batch.Text[0][1]).numpy()\n",
        "\n",
        "text = tokenizer_bert.convert_ids_to_tokens(text_minibatch_1)\n",
        "\n",
        "print(text)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'wow', 'so', 'much', 'fun', 'probably', 'a', 'bit', 'much', 'for', 'normal', 'american', 'kids', ',', 'and', 'really', 'it', 's', 'a', 'stretch', 'to', 'call', 'this', 'a', 'kid', 's', 'film', ',', 'this', 'movie', 'reminded', 'me', 'a', 'quite', 'a', 'bit', 'of', 'time', 'bandits', 'very', 'terry', 'gill', '##iam', 'all', 'the', 'way', 'through', '.', 'while', 'the', 'overall', 'narrative', 'is', 'pretty', 'much', 'straight', 'forward', ',', 'mi', '##ike', 'still', 'throws', 'in', 'a', 'lot', 'of', 'surreal', 'and', 'bun', '##uel', 'esq', '##ui', '##re', 'moments', '.', 'the', 'whole', 'first', 'act', 'violently', 'ju', '##xt', '##ap', '##oses', 'from', 'scene', 'to', 'scene', 'the', 'normal', 'family', 'life', 'of', 'the', 'main', 'kid', 'hero', ',', 'with', 'the', 'spirit', 'world', 'and', 'the', 'evil', 'than', 'is', 'ensuing', 'there', '##in', '.', 'and', 'while', 'the', 'ending', 'does', 'have', 'a', 'bit', 'of', 'an', 'ambiguous', 'aspect', 'that', 'are', 'common', 'of', 'mi', '##ike', 's', 'work', ',', 'the', 'layers', 'of', 'meaning', 'and', 'metaphor', ',', 'particularly', 'the', 'anti', 'war', 'anti', 'revenge', 'message', 'of', 'human', 'folly', ',', 'is', 'pretty', 'damn', 'po', '##ignant', '.', 'as', 'mani', '##c', 'and', 'imaginative', '##ly', 'fun', 'as', 'other', 'great', 'mi', '##ike', 'films', ',', 'only', 'instead', 'of', 'over', 'the', 'top', 'torture', 'and', 'gore', ',', 'he', 'gives', 'us', 'an', 'endless', 'amount', 'of', 'monsters', 'and', 'yo', '##kai', 'from', 'japanese', 'folk', 'lore', 'creative', '##ly', 'conceived', 'via', 'c', '##g', 'and', 'puppet', '##ry', 'wrapped', 'into', 'an', 'imaginative', 'multi', 'face', '##ted', 'adventure', '.', 'f', 'n', 'ra', '##d', ',', 'and', 'one', 'of', 'mi', '##ike', 's', 'best', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6E_9gwA7NrR"
      },
      "source": [
        "class BertForIMDb(nn.Module):\n",
        "\n",
        "  def __init__(self, net_bert):\n",
        "    super(BertForIMDb, self).__init__()\n",
        "\n",
        "    self.bert = net_bert\n",
        "\n",
        "    self.cls = nn.Linear(in_features=768, out_features=2)\n",
        "\n",
        "    nn.init.normal_(self.cls.weight, std=0.02)\n",
        "    nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False):\n",
        "\n",
        "    if attention_show_flg == True:\n",
        "      encoded_layers, pooled_output, attention_probs = self.bert(\n",
        "          input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg\n",
        "      )\n",
        "    elif attention_show_flg == False:\n",
        "      encoded_layers, pooled_output = self.bert(\n",
        "          input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg\n",
        "      )\n",
        "\n",
        "    vec_0 = encoded_layers[:, 0, :]\n",
        "    vec_0 = vec_0.view(-1, 768)\n",
        "    out = self.cls(vec_0)\n",
        "\n",
        "    if attention_show_flg == True:\n",
        "      return out, attention_probs\n",
        "    elif attention_show_flg == False:\n",
        "      return out"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWAk4v8U9wIw",
        "outputId": "9a1046a6-6273-4d74-d431-d3d1eaf7943a"
      },
      "source": [
        "net = BertForIMDb(net_bert)\n",
        "\n",
        "net.train()\n",
        "\n",
        "print(\"network setting is completed.\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "network setting is completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L7kkylS95tk"
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "for name, param in net.cls.named_parameters():\n",
        "  param.requires_grad = True"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaEvsREp-1PK"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                        {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "                        {'params': net.cls.parameters(), 'lr': 5e-5}\n",
        "], betas=(0.9, 0.999))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd8ZO4DL_fjN"
      },
      "source": [
        "import time\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  print(\"Using device: \", device)\n",
        "  print(\"---------------start--------------------\")\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == \"train\":\n",
        "        net.train()\n",
        "      else:\n",
        "        net.eval()\n",
        "\n",
        "      epoch_loss = 0.0\n",
        "      epoch_corrects = 0\n",
        "      iteration = 1\n",
        "\n",
        "      t_epoch_start = time.time()\n",
        "      t_iter_start = time.time()\n",
        "\n",
        "      for batch in (dataloaders_dict[phase]):\n",
        "\n",
        "        inputs = batch.Text[0].to(device)\n",
        "        labels = batch.Label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = net(inputs, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (iteration % 10 == 0):\n",
        "              t_iter_finish = time.time()\n",
        "              duration = t_iter_finish - t_iter_start\n",
        "              acc = (torch.sum(preds == labels.data)).double()/batch_size\n",
        "              print('Iteration {} || Loss: {:.4f} || 10iter: {:.4f} sec. || accuracy in this iteration: {}'.format(iteration, loss.item(), duration, acc))\n",
        "              t_iter_start = time.time()\n",
        "\n",
        "          iteration += 1\n",
        "\n",
        "          epoch_loss += loss.item() * batch_size\n",
        "          epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      t_epoch_finish = time.time()\n",
        "      epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "      epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "      print('Epoch {}/{} | {:^5} | Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs, phase, epoch_loss, epoch_acc))\n",
        "\n",
        "      t_epoch_start = time.time()\n",
        "\n",
        "  return net"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHhy1iUUB1Jm",
        "outputId": "522ec676-410c-48bd-c3f5-4081d37fef8d"
      },
      "source": [
        "num_epochs = 2\n",
        "net_trained = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device:  cuda:0\n",
            "---------------start--------------------\n",
            "Iteration 10 || Loss: 0.6572 || 10iter: 1.7839 sec. || accuracy in this iteration: 0.6875\n",
            "Iteration 20 || Loss: 0.6754 || 10iter: 1.7485 sec. || accuracy in this iteration: 0.53125\n",
            "Iteration 30 || Loss: 0.6522 || 10iter: 1.7493 sec. || accuracy in this iteration: 0.6875\n",
            "Iteration 40 || Loss: 0.6055 || 10iter: 1.7521 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 50 || Loss: 0.5998 || 10iter: 1.7533 sec. || accuracy in this iteration: 0.65625\n",
            "Iteration 60 || Loss: 0.5424 || 10iter: 1.7547 sec. || accuracy in this iteration: 0.78125\n",
            "Iteration 70 || Loss: 0.6364 || 10iter: 1.7546 sec. || accuracy in this iteration: 0.65625\n",
            "Iteration 80 || Loss: 0.4751 || 10iter: 1.7524 sec. || accuracy in this iteration: 0.78125\n",
            "Iteration 90 || Loss: 0.4884 || 10iter: 1.7558 sec. || accuracy in this iteration: 0.75\n",
            "Iteration 100 || Loss: 0.3799 || 10iter: 1.7572 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 110 || Loss: 0.3705 || 10iter: 1.7551 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 120 || Loss: 0.3157 || 10iter: 1.7554 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 130 || Loss: 0.2819 || 10iter: 1.7537 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 140 || Loss: 0.3483 || 10iter: 1.7572 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 150 || Loss: 0.3304 || 10iter: 1.7552 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 160 || Loss: 0.2509 || 10iter: 1.7553 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 170 || Loss: 0.2496 || 10iter: 1.7542 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 180 || Loss: 0.2921 || 10iter: 1.7573 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 190 || Loss: 0.2397 || 10iter: 1.7561 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 200 || Loss: 0.4915 || 10iter: 1.7562 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 210 || Loss: 0.2653 || 10iter: 1.7564 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 220 || Loss: 0.5325 || 10iter: 1.7568 sec. || accuracy in this iteration: 0.75\n",
            "Iteration 230 || Loss: 0.2383 || 10iter: 1.7573 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 240 || Loss: 0.2305 || 10iter: 1.7544 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 250 || Loss: 0.2703 || 10iter: 1.7576 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 260 || Loss: 0.3505 || 10iter: 1.7569 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 270 || Loss: 0.2172 || 10iter: 1.7579 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 280 || Loss: 0.2664 || 10iter: 1.7624 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 290 || Loss: 0.4325 || 10iter: 1.7595 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 300 || Loss: 0.3637 || 10iter: 1.7618 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 310 || Loss: 0.2828 || 10iter: 1.7575 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 320 || Loss: 0.3884 || 10iter: 1.7607 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 330 || Loss: 0.3271 || 10iter: 1.7626 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 340 || Loss: 0.2420 || 10iter: 1.7614 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 350 || Loss: 0.1956 || 10iter: 1.7618 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 360 || Loss: 0.3040 || 10iter: 1.7585 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 370 || Loss: 0.1443 || 10iter: 1.7620 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 380 || Loss: 0.3974 || 10iter: 1.7554 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 390 || Loss: 0.1640 || 10iter: 1.7610 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 400 || Loss: 0.1986 || 10iter: 1.7603 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 410 || Loss: 0.2911 || 10iter: 1.7697 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 420 || Loss: 0.3165 || 10iter: 1.7620 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 430 || Loss: 0.2745 || 10iter: 1.7630 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 440 || Loss: 0.3510 || 10iter: 1.7616 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 450 || Loss: 0.3119 || 10iter: 1.7624 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 460 || Loss: 0.0764 || 10iter: 1.7595 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 470 || Loss: 0.3120 || 10iter: 1.7608 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 480 || Loss: 0.3306 || 10iter: 1.7573 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 490 || Loss: 0.1836 || 10iter: 1.7629 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 500 || Loss: 0.2646 || 10iter: 1.7605 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 510 || Loss: 0.1876 || 10iter: 1.7596 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 520 || Loss: 0.3390 || 10iter: 1.7609 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 530 || Loss: 0.1609 || 10iter: 1.7674 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 540 || Loss: 0.1981 || 10iter: 1.7621 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 550 || Loss: 0.4162 || 10iter: 1.7640 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 560 || Loss: 0.3705 || 10iter: 1.7645 sec. || accuracy in this iteration: 0.78125\n",
            "Iteration 570 || Loss: 0.4066 || 10iter: 1.7632 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 580 || Loss: 0.3541 || 10iter: 1.7631 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 590 || Loss: 0.2106 || 10iter: 1.7624 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 600 || Loss: 0.2706 || 10iter: 1.7610 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 610 || Loss: 0.4622 || 10iter: 1.7611 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 620 || Loss: 0.3120 || 10iter: 1.7599 sec. || accuracy in this iteration: 0.875\n",
            "Epoch 1/2 | train | Loss: 0.3464 Acc: 0.8441\n",
            "Epoch 1/2 |  val  | Loss: 0.2576 Acc: 0.8976\n",
            "Iteration 10 || Loss: 0.3908 || 10iter: 1.7879 sec. || accuracy in this iteration: 0.71875\n",
            "Iteration 20 || Loss: 0.3630 || 10iter: 1.7631 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 30 || Loss: 0.3741 || 10iter: 1.7707 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 40 || Loss: 0.4171 || 10iter: 1.7624 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 50 || Loss: 0.4096 || 10iter: 1.7647 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 60 || Loss: 0.1982 || 10iter: 1.7650 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 70 || Loss: 0.5394 || 10iter: 1.7632 sec. || accuracy in this iteration: 0.75\n",
            "Iteration 80 || Loss: 0.3271 || 10iter: 1.7636 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 90 || Loss: 0.2206 || 10iter: 1.7643 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 100 || Loss: 0.2875 || 10iter: 1.7608 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 110 || Loss: 0.1996 || 10iter: 1.7689 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 120 || Loss: 0.2496 || 10iter: 1.7652 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 130 || Loss: 0.1828 || 10iter: 1.7633 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 140 || Loss: 0.3324 || 10iter: 1.7679 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 150 || Loss: 0.1919 || 10iter: 1.7671 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 160 || Loss: 0.2605 || 10iter: 1.7615 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 170 || Loss: 0.2790 || 10iter: 1.7656 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 180 || Loss: 0.3602 || 10iter: 1.7659 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 190 || Loss: 0.3324 || 10iter: 1.7641 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 200 || Loss: 0.1693 || 10iter: 1.7655 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 210 || Loss: 0.3096 || 10iter: 1.7612 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 220 || Loss: 0.1810 || 10iter: 1.7663 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 230 || Loss: 0.2475 || 10iter: 1.7624 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 240 || Loss: 0.2881 || 10iter: 1.7639 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 250 || Loss: 0.1992 || 10iter: 1.7721 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 260 || Loss: 0.2452 || 10iter: 1.7658 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 270 || Loss: 0.1616 || 10iter: 1.7598 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 280 || Loss: 0.1663 || 10iter: 1.7656 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 290 || Loss: 0.2180 || 10iter: 1.7620 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 300 || Loss: 0.3129 || 10iter: 1.7645 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 310 || Loss: 0.1923 || 10iter: 1.7625 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 320 || Loss: 0.4485 || 10iter: 1.7636 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 330 || Loss: 0.2208 || 10iter: 1.7649 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 340 || Loss: 0.1441 || 10iter: 1.7734 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 350 || Loss: 0.2616 || 10iter: 1.7672 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 360 || Loss: 0.2555 || 10iter: 1.7646 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 370 || Loss: 0.3427 || 10iter: 1.7636 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 380 || Loss: 0.0453 || 10iter: 1.7664 sec. || accuracy in this iteration: 1.0\n",
            "Iteration 390 || Loss: 0.3502 || 10iter: 1.7616 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 400 || Loss: 0.2055 || 10iter: 1.7635 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 410 || Loss: 0.2930 || 10iter: 1.7651 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 420 || Loss: 0.2115 || 10iter: 1.7633 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 430 || Loss: 0.4138 || 10iter: 1.7701 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 440 || Loss: 0.1805 || 10iter: 1.7641 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 450 || Loss: 0.1875 || 10iter: 1.7672 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 460 || Loss: 0.2469 || 10iter: 1.7616 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 470 || Loss: 0.1606 || 10iter: 1.7665 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 480 || Loss: 0.2401 || 10iter: 1.7632 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 490 || Loss: 0.4321 || 10iter: 1.7623 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 500 || Loss: 0.3052 || 10iter: 1.7634 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 510 || Loss: 0.3112 || 10iter: 1.7610 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 520 || Loss: 0.1375 || 10iter: 1.7632 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 530 || Loss: 0.2423 || 10iter: 1.7629 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 540 || Loss: 0.2203 || 10iter: 1.7620 sec. || accuracy in this iteration: 0.84375\n",
            "Iteration 550 || Loss: 0.1352 || 10iter: 1.7729 sec. || accuracy in this iteration: 0.96875\n",
            "Iteration 560 || Loss: 0.1523 || 10iter: 1.7647 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 570 || Loss: 0.2576 || 10iter: 1.7650 sec. || accuracy in this iteration: 0.875\n",
            "Iteration 580 || Loss: 0.2362 || 10iter: 1.7638 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 590 || Loss: 0.1700 || 10iter: 1.7677 sec. || accuracy in this iteration: 0.90625\n",
            "Iteration 600 || Loss: 0.2226 || 10iter: 1.7675 sec. || accuracy in this iteration: 0.9375\n",
            "Iteration 610 || Loss: 0.3727 || 10iter: 1.7662 sec. || accuracy in this iteration: 0.8125\n",
            "Iteration 620 || Loss: 0.1606 || 10iter: 1.7632 sec. || accuracy in this iteration: 0.90625\n",
            "Epoch 2/2 | train | Loss: 0.2605 Acc: 0.8912\n",
            "Epoch 2/2 |  val  | Loss: 0.2495 Acc: 0.9038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAJq3eMfDfPD",
        "outputId": "66fbcb33-78ee-41f2-8591-1ba3fb838414"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "save_path = './weights/bert_fine_tuning_IMDb.pth'\n",
        "torch.save(net_trained.state_dict(), save_path)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()\n",
        "net_trained.to(device)\n",
        "\n",
        "epoch_corrects = 0\n",
        "\n",
        "for batch in tqdm(test_dl):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  inputs = batch.Text[0].to(device)\n",
        "  labels = batch.Label.to(device)\n",
        "\n",
        "  with torch.set_grad_enabled(False):\n",
        "\n",
        "    outputs = net_trained(inputs, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False)\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
        "print('Test data {} accuracy : {:.4f} : '.format(len(test_dl.dataset), epoch_acc))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 782/782 [02:04<00:00,  6.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test data 25000 accuracy : 0.9018 : \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK4xHke6FpjP"
      },
      "source": [
        "batch_size = 64\n",
        "test_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K44Up4B2GW_Z"
      },
      "source": [
        "batch = next(iter(test_dl))\n",
        "\n",
        "inputs = batch.Text[0].to(device)\n",
        "labels = batch.Label.to(device)\n",
        "\n",
        "outputs, attention_probs = net_trained(inputs, token_type_ids=None,\n",
        "                                       attention_mask=None, output_all_encoded_layers=False, \n",
        "                                       attention_show_flg=True)\n",
        "\n",
        "_, preds = torch.max(outputs, 1)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuged2sVHlVE"
      },
      "source": [
        "def highlight(word, attn):\n",
        "  html_color = '#%02X%02X%02X' % (255, int(255*(1- attn)), int(255*(1-attn)))\n",
        "  return '<span style=\"background-color: {}\"> {} </span>'.format(html_color, word)\n",
        "\n",
        "def mk_html(index, batch, preds, normalized_weights, TEXT):\n",
        "\n",
        "  sentence = batch.Text[0][index]\n",
        "  label = batch.Label[index]\n",
        "  pred = preds[index]\n",
        "\n",
        "  if label == 0:\n",
        "    label_str = \"Negative\"\n",
        "  else:\n",
        "    label_str = \"Positive\"\n",
        "\n",
        "  if pred == 0:\n",
        "    pred_str = \"Negative\"\n",
        "  else:\n",
        "    pred_str = \"Positive\"\n",
        "\n",
        "  html = 'True Label: {}<br> Prediction Label: {}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "  for i in range(12):\n",
        "    attens = normalized_weights[index, i, 0, :]\n",
        "    attens /= attens.max()\n",
        "\n",
        "    html += '[Visualize Attention of BERT_' + str(i+1) + ']<br>'\n",
        "    for word, attn in zip(sentence, attens):\n",
        "      if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "        break\n",
        "\n",
        "      html += highlight(tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "  all_attens = attens*0\n",
        "  for i in range(12):\n",
        "    attens += normalized_weights[index, i, 0, :]\n",
        "  attens /= attens.max()\n",
        "\n",
        "  html += '[Visualize Attention of BERT_ALL]<br>'\n",
        "  for word, attn in zip(sentence, attens):\n",
        "    if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "      break\n",
        "\n",
        "    html += highlight(tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0], attn)\n",
        "  html += \"<br><br>\"\n",
        "\n",
        "  return html"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZlKW-JgVK09l",
        "outputId": "6e7b7ed4-0d6f-4ae2-f661-a985f9949861"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "index = 3\n",
        "html_output = mk_html(index, batch, preds, attention_probs, TEXT)\n",
        "HTML(html_output)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "True Label: Positive<br> Prediction Label: Positive<br><br>[Visualize Attention of BERT_1]<br><span style=\"background-color: #FFD8D8\"> [CLS] </span><span style=\"background-color: #FFE7E7\"> this </span><span style=\"background-color: #FF1313\"> was </span><span style=\"background-color: #FFACAC\"> a </span><span style=\"background-color: #FFDBDB\"> great </span><span style=\"background-color: #FFF2F2\"> film </span><span style=\"background-color: #FFE5E5\"> in </span><span style=\"background-color: #FF7070\"> every </span><span style=\"background-color: #FFF2F2\"> sense </span><span style=\"background-color: #FFFAFA\"> of </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFFAFA\"> word </span><span style=\"background-color: #FF7A7A\"> . </span><span style=\"background-color: #FFF6F6\"> it </span><span style=\"background-color: #FF7F7F\"> tackles </span><span style=\"background-color: #FFF7F7\"> the </span><span style=\"background-color: #FFE3E3\"> subject </span><span style=\"background-color: #FFF6F6\"> of </span><span style=\"background-color: #FFFDFD\"> tri </span><span style=\"background-color: #FFF8F8\"> ##bad </span><span style=\"background-color: #FFF3F3\"> ##ism </span><span style=\"background-color: #FFF0F0\"> in </span><span style=\"background-color: #FFE6E6\"> a </span><span style=\"background-color: #FFE3E3\"> society </span><span style=\"background-color: #FFDCDC\"> that </span><span style=\"background-color: #FFECEC\"> is </span><span style=\"background-color: #FFEAEA\"> quite </span><span style=\"background-color: #FFFBFB\"> into </span><span style=\"background-color: #FFFCFC\"> ##ler </span><span style=\"background-color: #FFF8F8\"> ##ant </span><span style=\"background-color: #FFFBFB\"> of </span><span style=\"background-color: #FFE0E0\"> any </span><span style=\"background-color: #FFE7E7\"> deviation </span><span style=\"background-color: #FFFAFA\"> ##s </span><span style=\"background-color: #FFFCFC\"> from </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFBFB\"> norm </span><span style=\"background-color: #FF6D6D\"> . </span><span style=\"background-color: #FFEFEF\"> it </span><span style=\"background-color: #FFA0A0\"> critic </span><span style=\"background-color: #FF7474\"> ##ises </span><span style=\"background-color: #FFB8B8\"> a </span><span style=\"background-color: #FFF5F5\"> great </span><span style=\"background-color: #FFABAB\"> many </span><span style=\"background-color: #FFFAFA\"> indian </span><span style=\"background-color: #FFECEC\"> customs </span><span style=\"background-color: #FF8D8D\"> that </span><span style=\"background-color: #FFF6F6\"> many </span><span style=\"background-color: #FF6B6B\"> find </span><span style=\"background-color: #FFE9E9\"> oppressive </span><span style=\"background-color: #FFE5E5\"> such </span><span style=\"background-color: #FFF3F3\"> as </span><span style=\"background-color: #FFEDED\"> the </span><span style=\"background-color: #FFEDED\"> arranging </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFFAFA\"> marriages </span><span style=\"background-color: #FFF3F3\"> by </span><span style=\"background-color: #FFEEEE\"> others </span><span style=\"background-color: #FFCFCF\"> , </span><span style=\"background-color: #FFE9E9\"> the </span><span style=\"background-color: #FFE8E8\"> importance </span><span style=\"background-color: #FFF8F8\"> of </span><span style=\"background-color: #FFB7B7\"> status </span><span style=\"background-color: #FFF4F4\"> and </span><span style=\"background-color: #FFB6B6\"> face </span><span style=\"background-color: #FFE3E3\"> , </span><span style=\"background-color: #FFE9E9\"> religious </span><span style=\"background-color: #FFFAFA\"> h </span><span style=\"background-color: #FFF8F8\"> ##yp </span><span style=\"background-color: #FFF5F5\"> ##oc </span><span style=\"background-color: #FFEBEB\"> ##ris </span><span style=\"background-color: #FFF9F9\"> ##y </span><span style=\"background-color: #FFF6F6\"> , </span><span style=\"background-color: #FFF7F7\"> sex </span><span style=\"background-color: #FFF8F8\"> ##ism </span><span style=\"background-color: #FFE2E2\"> , </span><span style=\"background-color: #FFE5E5\"> the </span><span style=\"background-color: #FFDBDB\"> valuation </span><span style=\"background-color: #FFFBFB\"> of </span><span style=\"background-color: #FFF3F3\"> women </span><span style=\"background-color: #FFEFEF\"> in </span><span style=\"background-color: #FFEAEA\"> terms </span><span style=\"background-color: #FFF7F7\"> of </span><span style=\"background-color: #FFF3F3\"> their </span><span style=\"background-color: #FFE7E7\"> baby </span><span style=\"background-color: #FFF9F9\"> making </span><span style=\"background-color: #FFF8F8\"> capacity </span><span style=\"background-color: #FFDCDC\"> , </span><span style=\"background-color: #FFDFDF\"> the </span><span style=\"background-color: #FFF6F6\"> binding </span><span style=\"background-color: #FFDEDE\"> concepts </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFE8E8\"> duty </span><span style=\"background-color: #FFF7F7\"> and </span><span style=\"background-color: #FFC5C5\"> so </span><span style=\"background-color: #FFBBBB\"> on </span><span style=\"background-color: #FF6868\"> . </span><span style=\"background-color: #FF8080\"> at </span><span style=\"background-color: #FF8282\"> the </span><span style=\"background-color: #FF8B8B\"> heart </span><span style=\"background-color: #FFCACA\"> of </span><span style=\"background-color: #FFEDED\"> the </span><span style=\"background-color: #FFF3F3\"> film </span><span style=\"background-color: #FF6C6C\"> is </span><span style=\"background-color: #FFC5C5\"> a </span><span style=\"background-color: #FFEBEB\"> touching </span><span style=\"background-color: #FFF8F8\"> love </span><span style=\"background-color: #FFF0F0\"> story </span><span style=\"background-color: #FFBEBE\"> that </span><span style=\"background-color: #FFC7C7\"> goes </span><span style=\"background-color: #FFEFEF\"> beyond </span><span style=\"background-color: #FFDDDD\"> such </span><span style=\"background-color: #FFD5D5\"> limitations </span><span style=\"background-color: #FFFBFB\"> of </span><span style=\"background-color: #FFF6F6\"> the </span><span style=\"background-color: #FFD5D5\"> society </span><span style=\"background-color: #FFE7E7\"> which </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFF2F2\"> two </span><span style=\"background-color: #FFF8F8\"> protagonists </span><span style=\"background-color: #FFF7F7\"> find </span><span style=\"background-color: #FFFAFA\"> themselves </span><span style=\"background-color: #FF7070\"> . </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFF8F8\"> film </span><span style=\"background-color: #FFDCDC\"> is </span><span style=\"background-color: #FFEFEF\"> well </span><span style=\"background-color: #FFB7B7\"> acted </span><span style=\"background-color: #FFF0F0\"> and </span><span style=\"background-color: #FFEAEA\"> genuine </span><span style=\"background-color: #FFB4B4\"> , </span><span style=\"background-color: #FFC8C8\"> completely </span><span style=\"background-color: #FFBDBD\"> bel </span><span style=\"background-color: #FFFDFD\"> ##ie </span><span style=\"background-color: #FFE1E1\"> ##vable </span><span style=\"background-color: #FFD7D7\"> from </span><span style=\"background-color: #FFBABA\"> beginning </span><span style=\"background-color: #FFBEBE\"> to </span><span style=\"background-color: #FF9F9F\"> end </span><span style=\"background-color: #FFDBDB\"> , </span><span style=\"background-color: #FFFAFA\"> unlike </span><span style=\"background-color: #FFF5F5\"> most </span><span style=\"background-color: #FFF4F4\"> bollywood </span><span style=\"background-color: #FFF6F6\"> flick </span><span style=\"background-color: #FFF8F8\"> ##s </span><span style=\"background-color: #FF6D6D\"> . </span><span style=\"background-color: #FFE0E0\"> the </span><span style=\"background-color: #FFCDCD\"> main </span><span style=\"background-color: #FFCACA\"> faults </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFF8F8\"> film </span><span style=\"background-color: #FFECEC\"> as </span><span style=\"background-color: #FFE8E8\"> i </span><span style=\"background-color: #FF4646\"> saw </span><span style=\"background-color: #FFEDED\"> it </span><span style=\"background-color: #FFE3E3\"> was </span><span style=\"background-color: #FF9393\"> first </span><span style=\"background-color: #FFC7C7\"> , </span><span style=\"background-color: #FFCECE\"> that </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFAFA\"> two </span><span style=\"background-color: #FFFDFD\"> lovers </span><span style=\"background-color: #FFE4E4\"> seem </span><span style=\"background-color: #FFFEFE\"> drawn </span><span style=\"background-color: #FFF7F7\"> to </span><span style=\"background-color: #FFFCFC\"> one </span><span style=\"background-color: #FFF7F7\"> another </span><span style=\"background-color: #FFE7E7\"> not </span><span style=\"background-color: #FFF3F3\"> necessarily </span><span style=\"background-color: #FFF0F0\"> by </span><span style=\"background-color: #FFF9F9\"> a </span><span style=\"background-color: #FFF9F9\"> natural </span><span style=\"background-color: #FFEFEF\"> affinity </span><span style=\"background-color: #FFFAFA\"> for </span><span style=\"background-color: #FFFCFC\"> each </span><span style=\"background-color: #FFF9F9\"> other </span><span style=\"background-color: #FFEAEA\"> as </span><span style=\"background-color: #FFDBDB\"> much </span><span style=\"background-color: #FFE9E9\"> as </span><span style=\"background-color: #FFECEC\"> the </span><span style=\"background-color: #FF6060\"> fact </span><span style=\"background-color: #FF8F8F\"> that </span><span style=\"background-color: #FFF8F8\"> they </span><span style=\"background-color: #FFEAEA\"> are </span><span style=\"background-color: #FFA9A9\"> stuck </span><span style=\"background-color: #FFDCDC\"> in </span><span style=\"background-color: #FFEAEA\"> dead </span><span style=\"background-color: #FFF6F6\"> end </span><span style=\"background-color: #FFEFEF\"> marriages </span><span style=\"background-color: #FF9797\"> with </span><span style=\"background-color: #FFE9E9\"> no </span><span style=\"background-color: #FFD2D2\"> passion </span><span style=\"background-color: #FF5656\"> and </span><span style=\"background-color: #FFCDCD\"> no </span><span style=\"background-color: #FFBDBD\"> rewards </span><span style=\"background-color: #FF6868\"> . </span><span style=\"background-color: #FFE7E7\"> this </span><span style=\"background-color: #FFDADA\"> may </span><span style=\"background-color: #FF9E9E\"> play </span><span style=\"background-color: #FFD6D6\"> a </span><span style=\"background-color: #FFE6E6\"> part </span><span style=\"background-color: #FFD1D1\"> in </span><span style=\"background-color: #FF8686\"> the </span><span style=\"background-color: #FFFAFA\"> sexual </span><span style=\"background-color: #FF5050\"> awakening </span><span style=\"background-color: #FFE1E1\"> of </span><span style=\"background-color: #FFF1F1\"> the </span><span style=\"background-color: #FFDCDC\"> characters </span><span style=\"background-color: #FF7676\"> , </span><span style=\"background-color: #FFD6D6\"> but </span><span style=\"background-color: #FFC7C7\"> most </span><span style=\"background-color: #FFEAEA\"> people </span><span style=\"background-color: #FFE0E0\"> stuck </span><span style=\"background-color: #FFE2E2\"> in </span><span style=\"background-color: #FFF7F7\"> the </span><span style=\"background-color: #FFF1F1\"> same </span><span style=\"background-color: #FFBABA\"> situation </span><span style=\"background-color: #FFD1D1\"> will </span><span style=\"background-color: #FFC0C0\"> not </span><span style=\"background-color: #FF9C9C\"> turn </span><span style=\"background-color: #FFF1F1\"> homosexual </span><span style=\"background-color: #FF6A6A\"> . </span><span style=\"background-color: #FFF8F8\"> it </span><span style=\"background-color: #FF5959\"> seems </span><span style=\"background-color: #FFEAEA\"> clear </span><span style=\"background-color: #FF7C7C\"> from </span><span style=\"background-color: #FFEDED\"> the </span><span style=\"background-color: #FF0000\"> beginning </span><span style=\"background-color: #FFD6D6\"> of </span><span style=\"background-color: #FFF5F5\"> the </span><span style=\"background-color: #FFF4F4\"> film </span><span style=\"background-color: #FF7474\"> that </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFE2E2\"> two </span><span style=\"background-color: #FFE9E9\"> characters </span><span style=\"background-color: #FFEFEF\"> are </span><span style=\"background-color: #FFD6D6\"> quite </span><span style=\"background-color: #FFF7F7\"> heterosexual </span><span style=\"background-color: #FFCFCF\"> when </span><span style=\"background-color: #FFF7F7\"> radha </span><span style=\"background-color: #FFDFDF\"> does </span><span style=\"background-color: #FFEEEE\"> her </span><span style=\"background-color: #FFBFBF\"> scene </span><span style=\"background-color: #FFC7C7\"> at </span><span style=\"background-color: #FFF9F9\"> the </span><span style=\"background-color: #FF9393\"> end </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFF7F7\"> the </span><span style=\"background-color: #FFF5F5\"> movie </span><span style=\"background-color: #FFF6F6\"> with </span><span style=\"background-color: #FFFDFD\"> aa </span><span style=\"background-color: #FFFBFB\"> ##sho </span><span style=\"background-color: #FFFCFC\"> ##k </span><span style=\"background-color: #FFF2F2\"> , </span><br><br>[Visualize Attention of BERT_2]<br><span style=\"background-color: #FFF7F7\"> [CLS] </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> was </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFCFC\"> film </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFF3F3\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFCFC\"> subject </span><span style=\"background-color: #FFF7F7\"> of </span><span style=\"background-color: #FFE3E3\"> tri </span><span style=\"background-color: #FFF2F2\"> ##bad </span><span style=\"background-color: #FFF6F6\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFAFA\"> society </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFEFE\"> quite </span><span style=\"background-color: #FFFEFE\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFF1F1\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> critic </span><span style=\"background-color: #FFFEFE\"> ##ises </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFF3F3\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFDFD\"> that </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> oppressive </span><span style=\"background-color: #FFFBFB\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFF2F2\"> arranging </span><span style=\"background-color: #FFF2F2\"> of </span><span style=\"background-color: #FFF3F3\"> marriages </span><span style=\"background-color: #FFFBFB\"> by </span><span style=\"background-color: #FFF5F5\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> importance </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFF0F0\"> status </span><span style=\"background-color: #FFFBFB\"> and </span><span style=\"background-color: #FFF3F3\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFDFD\"> religious </span><span style=\"background-color: #FFFDFD\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFDFD\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFCFC\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFBFB\"> valuation </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFBFB\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFF6F6\"> baby </span><span style=\"background-color: #FFFCFC\"> making </span><span style=\"background-color: #FFFDFD\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFCFC\"> binding </span><span style=\"background-color: #FFFDFD\"> concepts </span><span style=\"background-color: #FFFCFC\"> of </span><span style=\"background-color: #FFFCFC\"> duty </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFCFC\"> so </span><span style=\"background-color: #FFFCFC\"> on </span><span style=\"background-color: #FFF0F0\"> . </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFF6F6\"> the </span><span style=\"background-color: #FFFEFE\"> heart </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFBFB\"> film </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> touching </span><span style=\"background-color: #FFFBFB\"> love </span><span style=\"background-color: #FFFEFE\"> story </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> goes </span><span style=\"background-color: #FFFEFE\"> beyond </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFF9F9\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFF1F1\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFBFB\"> film </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFEFE\"> well </span><span style=\"background-color: #FFFCFC\"> acted </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> genuine </span><span style=\"background-color: #FFFCFC\"> , </span><span style=\"background-color: #FFFEFE\"> completely </span><span style=\"background-color: #FFFEFE\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFFEFE\"> ##vable </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFCFC\"> , </span><span style=\"background-color: #FFFEFE\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFEEEE\"> bollywood </span><span style=\"background-color: #FFFAFA\"> flick </span><span style=\"background-color: #FFFCFC\"> ##s </span><span style=\"background-color: #FFF1F1\"> . </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFBFB\"> main </span><span style=\"background-color: #FFFEFE\"> faults </span><span style=\"background-color: #FFFBFB\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFF6F6\"> film </span><span style=\"background-color: #FFFAFA\"> as </span><span style=\"background-color: #FFFCFC\"> i </span><span style=\"background-color: #FFFCFC\"> saw </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFF9F9\"> was </span><span style=\"background-color: #FFF4F4\"> first </span><span style=\"background-color: #FFFAFA\"> , </span><span style=\"background-color: #FFFBFB\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFBFB\"> two </span><span style=\"background-color: #FFF9F9\"> lovers </span><span style=\"background-color: #FFFCFC\"> seem </span><span style=\"background-color: #FFF6F6\"> drawn </span><span style=\"background-color: #FFEBEB\"> to </span><span style=\"background-color: #FFFDFD\"> one </span><span style=\"background-color: #FFFDFD\"> another </span><span style=\"background-color: #FFECEC\"> not </span><span style=\"background-color: #FFFDFD\"> necessarily </span><span style=\"background-color: #FFFBFB\"> by </span><span style=\"background-color: #FFFCFC\"> a </span><span style=\"background-color: #FFF3F3\"> natural </span><span style=\"background-color: #FFEDED\"> affinity </span><span style=\"background-color: #FFF3F3\"> for </span><span style=\"background-color: #FFFDFD\"> each </span><span style=\"background-color: #FFFDFD\"> other </span><span style=\"background-color: #FFFCFC\"> as </span><span style=\"background-color: #FFF9F9\"> much </span><span style=\"background-color: #FFF3F3\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> fact </span><span style=\"background-color: #FFFBFB\"> that </span><span style=\"background-color: #FFFAFA\"> they </span><span style=\"background-color: #FFFCFC\"> are </span><span style=\"background-color: #FFDFDF\"> stuck </span><span style=\"background-color: #FFF1F1\"> in </span><span style=\"background-color: #FFEAEA\"> dead </span><span style=\"background-color: #FFD9D9\"> end </span><span style=\"background-color: #FF7676\"> marriages </span><span style=\"background-color: #FFE9E9\"> with </span><span style=\"background-color: #FFF5F5\"> no </span><span style=\"background-color: #FFB3B3\"> passion </span><span style=\"background-color: #FFD1D1\"> and </span><span style=\"background-color: #FFF3F3\"> no </span><span style=\"background-color: #FF0000\"> rewards </span><span style=\"background-color: #FFF0F0\"> . </span><span style=\"background-color: #FFF8F8\"> this </span><span style=\"background-color: #FFEBEB\"> may </span><span style=\"background-color: #FFFAFA\"> play </span><span style=\"background-color: #FFFBFB\"> a </span><span style=\"background-color: #FFFCFC\"> part </span><span style=\"background-color: #FFF8F8\"> in </span><span style=\"background-color: #FFEEEE\"> the </span><span style=\"background-color: #FFC7C7\"> sexual </span><span style=\"background-color: #FF9999\"> awakening </span><span style=\"background-color: #FFF6F6\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFDFD\"> characters </span><span style=\"background-color: #FFF2F2\"> , </span><span style=\"background-color: #FFF8F8\"> but </span><span style=\"background-color: #FFFAFA\"> most </span><span style=\"background-color: #FFD7D7\"> people </span><span style=\"background-color: #FFF1F1\"> stuck </span><span style=\"background-color: #FFFBFB\"> in </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFAFA\"> same </span><span style=\"background-color: #FFF4F4\"> situation </span><span style=\"background-color: #FFE9E9\"> will </span><span style=\"background-color: #FFE9E9\"> not </span><span style=\"background-color: #FFBDBD\"> turn </span><span style=\"background-color: #FFE1E1\"> homosexual </span><span style=\"background-color: #FFF0F0\"> . </span><span style=\"background-color: #FFFCFC\"> it </span><span style=\"background-color: #FFFDFD\"> seems </span><span style=\"background-color: #FFFDFD\"> clear </span><span style=\"background-color: #FFF5F5\"> from </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFDFD\"> beginning </span><span style=\"background-color: #FFFCFC\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFF7F7\"> film </span><span style=\"background-color: #FFF9F9\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFF9F9\"> two </span><span style=\"background-color: #FFFAFA\"> characters </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFCFC\"> quite </span><span style=\"background-color: #FFE8E8\"> heterosexual </span><span style=\"background-color: #FFF0F0\"> when </span><span style=\"background-color: #FF0000\"> radha </span><span style=\"background-color: #FFFCFC\"> does </span><span style=\"background-color: #FFF9F9\"> her </span><span style=\"background-color: #FFF5F5\"> scene </span><span style=\"background-color: #FFFDFD\"> at </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFCFC\"> end </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFF3F3\"> movie </span><span style=\"background-color: #FFF5F5\"> with </span><span style=\"background-color: #FFEEEE\"> aa </span><span style=\"background-color: #FFF4F4\"> ##sho </span><span style=\"background-color: #FFC7C7\"> ##k </span><span style=\"background-color: #FFE2E2\"> , </span><br><br>[Visualize Attention of BERT_3]<br><span style=\"background-color: #FFFBFB\"> [CLS] </span><span style=\"background-color: #FFF9F9\"> this </span><span style=\"background-color: #FFF9F9\"> was </span><span style=\"background-color: #FFFCFC\"> a </span><span style=\"background-color: #FFFCFC\"> great </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFFBFB\"> in </span><span style=\"background-color: #FFF5F5\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFAFA\"> it </span><span style=\"background-color: #FFD8D8\"> tackles </span><span style=\"background-color: #FFF5F5\"> the </span><span style=\"background-color: #FFFAFA\"> subject </span><span style=\"background-color: #FFFCFC\"> of </span><span style=\"background-color: #FFFEFE\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFF7F7\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFF7F7\"> that </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFCFC\"> quite </span><span style=\"background-color: #FFFEFE\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFAFA\"> it </span><span style=\"background-color: #FFDCDC\"> critic </span><span style=\"background-color: #FFFCFC\"> ##ises </span><span style=\"background-color: #FFFCFC\"> a </span><span style=\"background-color: #FFF7F7\"> great </span><span style=\"background-color: #FFF4F4\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFF9F9\"> that </span><span style=\"background-color: #FFFCFC\"> many </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> oppressive </span><span style=\"background-color: #FFFBFB\"> such </span><span style=\"background-color: #FFFBFB\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFBFB\"> , </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFDFD\"> importance </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFF5F5\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFF6F6\"> , </span><span style=\"background-color: #FFFEFE\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFEFE\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFF7F7\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFF7F7\"> , </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFDFD\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFBFB\"> , </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFDFD\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> duty </span><span style=\"background-color: #FFE0E0\"> and </span><span style=\"background-color: #FFFEFE\"> so </span><span style=\"background-color: #FFF9F9\"> on </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFEFEF\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFF0F0\"> heart </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFFAFA\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFF0F0\"> is </span><span style=\"background-color: #FFBFBF\"> a </span><span style=\"background-color: #FFE2E2\"> touching </span><span style=\"background-color: #FFFBFB\"> love </span><span style=\"background-color: #FFF9F9\"> story </span><span style=\"background-color: #FFAAAA\"> that </span><span style=\"background-color: #FFF2F2\"> goes </span><span style=\"background-color: #FFAFAF\"> beyond </span><span style=\"background-color: #FFF5F5\"> such </span><span style=\"background-color: #FFFBFB\"> limitations </span><span style=\"background-color: #FFF8F8\"> of </span><span style=\"background-color: #FFFAFA\"> the </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFCFC\"> which </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFCFC\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFBFB\"> find </span><span style=\"background-color: #FFFDFD\"> themselves </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFE0E0\"> is </span><span style=\"background-color: #FFFBFB\"> well </span><span style=\"background-color: #FFFCFC\"> acted </span><span style=\"background-color: #FFD0D0\"> and </span><span style=\"background-color: #FFFAFA\"> genuine </span><span style=\"background-color: #FFD1D1\"> , </span><span style=\"background-color: #FFE6E6\"> completely </span><span style=\"background-color: #FFFCFC\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFF8F8\"> ##vable </span><span style=\"background-color: #FFC8C8\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFE8E8\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFF5F5\"> , </span><span style=\"background-color: #FFFDFD\"> unlike </span><span style=\"background-color: #FFFDFD\"> most </span><span style=\"background-color: #FFFEFE\"> bollywood </span><span style=\"background-color: #FFFEFE\"> flick </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFE4E4\"> the </span><span style=\"background-color: #FFF8F8\"> main </span><span style=\"background-color: #FFF3F3\"> faults </span><span style=\"background-color: #FFD9D9\"> of </span><span style=\"background-color: #FFF9F9\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFAFA\"> as </span><span style=\"background-color: #FFF8F8\"> i </span><span style=\"background-color: #FFFDFD\"> saw </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFFAFA\"> was </span><span style=\"background-color: #FFE5E5\"> first </span><span style=\"background-color: #FFDDDD\"> , </span><span style=\"background-color: #FF0000\"> that </span><span style=\"background-color: #FFF0F0\"> the </span><span style=\"background-color: #FFFAFA\"> two </span><span style=\"background-color: #FFFDFD\"> lovers </span><span style=\"background-color: #FFE8E8\"> seem </span><span style=\"background-color: #FFFAFA\"> drawn </span><span style=\"background-color: #FFF9F9\"> to </span><span style=\"background-color: #FFFBFB\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFF3F3\"> not </span><span style=\"background-color: #FFF4F4\"> necessarily </span><span style=\"background-color: #FFF5F5\"> by </span><span style=\"background-color: #FFFBFB\"> a </span><span style=\"background-color: #FFFEFE\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFBFB\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFAFA\"> as </span><span style=\"background-color: #FFECEC\"> much </span><span style=\"background-color: #FFF1F1\"> as </span><span style=\"background-color: #FFD9D9\"> the </span><span style=\"background-color: #FFF8F8\"> fact </span><span style=\"background-color: #FFE0E0\"> that </span><span style=\"background-color: #FFFAFA\"> they </span><span style=\"background-color: #FFF9F9\"> are </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFF7F7\"> dead </span><span style=\"background-color: #FFFDFD\"> end </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFF6F6\"> with </span><span style=\"background-color: #FFFCFC\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFF8F8\"> and </span><span style=\"background-color: #FFFDFD\"> no </span><span style=\"background-color: #FFFEFE\"> rewards </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF4F4\"> this </span><span style=\"background-color: #FFFBFB\"> may </span><span style=\"background-color: #FFF5F5\"> play </span><span style=\"background-color: #FFF7F7\"> a </span><span style=\"background-color: #FFFDFD\"> part </span><span style=\"background-color: #FFFDFD\"> in </span><span style=\"background-color: #FFE4E4\"> the </span><span style=\"background-color: #FFFEFE\"> sexual </span><span style=\"background-color: #FFFBFB\"> awakening </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFDFD\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF8F8\"> but </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFBFB\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFF8F8\"> will </span><span style=\"background-color: #FFF9F9\"> not </span><span style=\"background-color: #FFF8F8\"> turn </span><span style=\"background-color: #FFFEFE\"> homosexual </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFBFB\"> it </span><span style=\"background-color: #FFFCFC\"> seems </span><span style=\"background-color: #FFFBFB\"> clear </span><span style=\"background-color: #FFF2F2\"> from </span><span style=\"background-color: #FFEBEB\"> the </span><span style=\"background-color: #FFFCFC\"> beginning </span><span style=\"background-color: #FFFCFC\"> of </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFF2F2\"> that </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFAFA\"> characters </span><span style=\"background-color: #FFFDFD\"> are </span><span style=\"background-color: #FFF9F9\"> quite </span><span style=\"background-color: #FFFEFE\"> heterosexual </span><span style=\"background-color: #FFFDFD\"> when </span><span style=\"background-color: #FFFEFE\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFEFE\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFEFE\"> movie </span><span style=\"background-color: #FFFDFD\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFDFD\"> , </span><br><br>[Visualize Attention of BERT_4]<br><span style=\"background-color: #FFFDFD\"> [CLS] </span><span style=\"background-color: #FFEFEF\"> this </span><span style=\"background-color: #FFEAEA\"> was </span><span style=\"background-color: #FFA3A3\"> a </span><span style=\"background-color: #FFF9F9\"> great </span><span style=\"background-color: #FFF4F4\"> film </span><span style=\"background-color: #FFFDFD\"> in </span><span style=\"background-color: #FFFEFE\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFCCCC\"> it </span><span style=\"background-color: #FFF5F5\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFDFD\"> quite </span><span style=\"background-color: #FFFEFE\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFE3E3\"> it </span><span style=\"background-color: #FFFCFC\"> critic </span><span style=\"background-color: #FFFDFD\"> ##ises </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> oppressive </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> importance </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFEFE\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> duty </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> so </span><span style=\"background-color: #FFFEFE\"> on </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFCFC\"> heart </span><span style=\"background-color: #FFD5D5\"> of </span><span style=\"background-color: #FFC7C7\"> the </span><span style=\"background-color: #FFF5F5\"> film </span><span style=\"background-color: #FFF4F4\"> is </span><span style=\"background-color: #FF6767\"> a </span><span style=\"background-color: #FFEEEE\"> touching </span><span style=\"background-color: #FFFAFA\"> love </span><span style=\"background-color: #FFF7F7\"> story </span><span style=\"background-color: #FFF5F5\"> that </span><span style=\"background-color: #FFF7F7\"> goes </span><span style=\"background-color: #FFFEFE\"> beyond </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFF6F6\"> the </span><span style=\"background-color: #FFFCFC\"> two </span><span style=\"background-color: #FFFCFC\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FF6B6B\"> the </span><span style=\"background-color: #FFF5F5\"> film </span><span style=\"background-color: #FF0000\"> is </span><span style=\"background-color: #FFE7E7\"> well </span><span style=\"background-color: #FFBDBD\"> acted </span><span style=\"background-color: #FFFDFD\"> and </span><span style=\"background-color: #FFF3F3\"> genuine </span><span style=\"background-color: #FFFCFC\"> , </span><span style=\"background-color: #FFF2F2\"> completely </span><span style=\"background-color: #FFF9F9\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFF7F7\"> ##vable </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFDFD\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> bollywood </span><span style=\"background-color: #FFF7F7\"> flick </span><span style=\"background-color: #FFB2B2\"> ##s </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF7F7\"> the </span><span style=\"background-color: #FFFDFD\"> main </span><span style=\"background-color: #FFFDFD\"> faults </span><span style=\"background-color: #FFBCBC\"> of </span><span style=\"background-color: #FF9090\"> the </span><span style=\"background-color: #FFFBFB\"> film </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> i </span><span style=\"background-color: #FFFAFA\"> saw </span><span style=\"background-color: #FFDCDC\"> it </span><span style=\"background-color: #FFFDFD\"> was </span><span style=\"background-color: #FFFCFC\"> first </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF6F6\"> that </span><span style=\"background-color: #FFEAEA\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFEFE\"> lovers </span><span style=\"background-color: #FFFAFA\"> seem </span><span style=\"background-color: #FFFEFE\"> drawn </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> necessarily </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> much </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFEFE\"> fact </span><span style=\"background-color: #FFFDFD\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> dead </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFEFE\"> rewards </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> may </span><span style=\"background-color: #FFFEFE\"> play </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> part </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> sexual </span><span style=\"background-color: #FFFEFE\"> awakening </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFEBEB\"> the </span><span style=\"background-color: #FFF9F9\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> but </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFFEFE\"> will </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> turn </span><span style=\"background-color: #FFFEFE\"> homosexual </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFBFB\"> it </span><span style=\"background-color: #FFF9F9\"> seems </span><span style=\"background-color: #FFFDFD\"> clear </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFAFA\"> the </span><span style=\"background-color: #FFFDFD\"> beginning </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFEEEE\"> the </span><span style=\"background-color: #FFFBFB\"> film </span><span style=\"background-color: #FFFAFA\"> that </span><span style=\"background-color: #FFEFEF\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFDFD\"> characters </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFDFD\"> quite </span><span style=\"background-color: #FFFEFE\"> heterosexual </span><span style=\"background-color: #FFFEFE\"> when </span><span style=\"background-color: #FFFEFE\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFEFE\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFDFD\"> end </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFF5F5\"> the </span><span style=\"background-color: #FFFCFC\"> movie </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFEFE\"> , </span><br><br>[Visualize Attention of BERT_5]<br><span style=\"background-color: #FFFEFE\"> [CLS] </span><span style=\"background-color: #FFFCFC\"> this </span><span style=\"background-color: #FFE9E9\"> was </span><span style=\"background-color: #FFEEEE\"> a </span><span style=\"background-color: #FF0000\"> great </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFF5F5\"> quite </span><span style=\"background-color: #FFFEFE\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFDFD\"> critic </span><span style=\"background-color: #FFFDFD\"> ##ises </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFDFD\"> oppressive </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> importance </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFEFE\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> duty </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> so </span><span style=\"background-color: #FFFEFE\"> on </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> heart </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFDFD\"> a </span><span style=\"background-color: #FFFDFD\"> touching </span><span style=\"background-color: #FFFEFE\"> love </span><span style=\"background-color: #FFFEFE\"> story </span><span style=\"background-color: #FFFBFB\"> that </span><span style=\"background-color: #FFFCFC\"> goes </span><span style=\"background-color: #FFFEFE\"> beyond </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFBFB\"> is </span><span style=\"background-color: #FFF9F9\"> well </span><span style=\"background-color: #FFFEFE\"> acted </span><span style=\"background-color: #FFFDFD\"> and </span><span style=\"background-color: #FFF5F5\"> genuine </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFBFB\"> completely </span><span style=\"background-color: #FFFEFE\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFFDFD\"> ##vable </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> bollywood </span><span style=\"background-color: #FFFEFE\"> flick </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> main </span><span style=\"background-color: #FFF9F9\"> faults </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> i </span><span style=\"background-color: #FFFDFD\"> saw </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> was </span><span style=\"background-color: #FFFDFD\"> first </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> lovers </span><span style=\"background-color: #FFFEFE\"> seem </span><span style=\"background-color: #FFFEFE\"> drawn </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> necessarily </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> much </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> fact </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> dead </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFEFE\"> rewards </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> may </span><span style=\"background-color: #FFFEFE\"> play </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> part </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> sexual </span><span style=\"background-color: #FFFEFE\"> awakening </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> but </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFFEFE\"> will </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> turn </span><span style=\"background-color: #FFFEFE\"> homosexual </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFDFD\"> seems </span><span style=\"background-color: #FFFEFE\"> clear </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFEFE\"> quite </span><span style=\"background-color: #FFFEFE\"> heterosexual </span><span style=\"background-color: #FFFEFE\"> when </span><span style=\"background-color: #FFFEFE\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFEFE\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> movie </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFEFE\"> , </span><br><br>[Visualize Attention of BERT_6]<br><span style=\"background-color: #FFFEFE\"> [CLS] </span><span style=\"background-color: #FFFDFD\"> this </span><span style=\"background-color: #FFC0C0\"> was </span><span style=\"background-color: #FFF3F3\"> a </span><span style=\"background-color: #FF0000\"> great </span><span style=\"background-color: #FFFCFC\"> film </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFBFB\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFF2F2\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFDFD\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFDFD\"> society </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFDFD\"> is </span><span style=\"background-color: #FFEAEA\"> quite </span><span style=\"background-color: #FFFCFC\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFC3C3\"> critic </span><span style=\"background-color: #FFEEEE\"> ##ises </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFF9F9\"> great </span><span style=\"background-color: #FFFDFD\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFDFD\"> that </span><span style=\"background-color: #FFFCFC\"> many </span><span style=\"background-color: #FFFDFD\"> find </span><span style=\"background-color: #FFB6B6\"> oppressive </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> importance </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFEFE\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> duty </span><span style=\"background-color: #FFFAFA\"> and </span><span style=\"background-color: #FFFDFD\"> so </span><span style=\"background-color: #FFFDFD\"> on </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF7F7\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFE7E7\"> heart </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFFAFA\"> is </span><span style=\"background-color: #FFF8F8\"> a </span><span style=\"background-color: #FFE6E6\"> touching </span><span style=\"background-color: #FFFDFD\"> love </span><span style=\"background-color: #FFFCFC\"> story </span><span style=\"background-color: #FFF6F6\"> that </span><span style=\"background-color: #FFF8F8\"> goes </span><span style=\"background-color: #FFF9F9\"> beyond </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFDFD\"> is </span><span style=\"background-color: #FFFAFA\"> well </span><span style=\"background-color: #FFFDFD\"> acted </span><span style=\"background-color: #FFFDFD\"> and </span><span style=\"background-color: #FFF4F4\"> genuine </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFEBEB\"> completely </span><span style=\"background-color: #FFF1F1\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFFBFB\"> ##vable </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFDFD\"> end </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFAFA\"> bollywood </span><span style=\"background-color: #FFFDFD\"> flick </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> main </span><span style=\"background-color: #FFF1F1\"> faults </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> i </span><span style=\"background-color: #FFFDFD\"> saw </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> was </span><span style=\"background-color: #FFFEFE\"> first </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> lovers </span><span style=\"background-color: #FFFEFE\"> seem </span><span style=\"background-color: #FFFEFE\"> drawn </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> necessarily </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> much </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> fact </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFDFD\"> dead </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFEFE\"> rewards </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> may </span><span style=\"background-color: #FFFEFE\"> play </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> part </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> sexual </span><span style=\"background-color: #FFFEFE\"> awakening </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> but </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFFEFE\"> will </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> turn </span><span style=\"background-color: #FFFEFE\"> homosexual </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFDFD\"> seems </span><span style=\"background-color: #FFFEFE\"> clear </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFEFE\"> quite </span><span style=\"background-color: #FFFEFE\"> heterosexual </span><span style=\"background-color: #FFFEFE\"> when </span><span style=\"background-color: #FFFEFE\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFEFE\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> movie </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFEFE\"> , </span><br><br>[Visualize Attention of BERT_7]<br><span style=\"background-color: #FFFEFE\"> [CLS] </span><span style=\"background-color: #FFFCFC\"> this </span><span style=\"background-color: #FFF8F8\"> was </span><span style=\"background-color: #FFDBDB\"> a </span><span style=\"background-color: #FFCDCD\"> great </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFFBFB\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFDFD\"> is </span><span style=\"background-color: #FFFBFB\"> quite </span><span style=\"background-color: #FFFAFA\"> into </span><span style=\"background-color: #FFFDFD\"> ##ler </span><span style=\"background-color: #FFFCFC\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFFBFB\"> critic </span><span style=\"background-color: #FFFDFD\"> ##ises </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFF1F1\"> find </span><span style=\"background-color: #FFF8F8\"> oppressive </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> importance </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFEFE\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> duty </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> so </span><span style=\"background-color: #FFFEFE\"> on </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFEBEB\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFF9F9\"> heart </span><span style=\"background-color: #FFF2F2\"> of </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFE8E8\"> is </span><span style=\"background-color: #FF8B8B\"> a </span><span style=\"background-color: #FF9797\"> touching </span><span style=\"background-color: #FFFDFD\"> love </span><span style=\"background-color: #FFFDFD\"> story </span><span style=\"background-color: #FFE8E8\"> that </span><span style=\"background-color: #FFD5D5\"> goes </span><span style=\"background-color: #FFFCFC\"> beyond </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF7F7\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FF1B1B\"> is </span><span style=\"background-color: #FFADAD\"> well </span><span style=\"background-color: #FFEDED\"> acted </span><span style=\"background-color: #FFF9F9\"> and </span><span style=\"background-color: #FFB7B7\"> genuine </span><span style=\"background-color: #FFFDFD\"> , </span><span style=\"background-color: #FF8787\"> completely </span><span style=\"background-color: #FF0000\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFDADA\"> ##vable </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFDFD\"> end </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF7F7\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> bollywood </span><span style=\"background-color: #FFFEFE\"> flick </span><span style=\"background-color: #FFF8F8\"> ##s </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFEFE\"> main </span><span style=\"background-color: #FFBEBE\"> faults </span><span style=\"background-color: #FFF1F1\"> of </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFDFD\"> i </span><span style=\"background-color: #FFF6F6\"> saw </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFFDFD\"> was </span><span style=\"background-color: #FFFDFD\"> first </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF6F6\"> that </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> lovers </span><span style=\"background-color: #FFDADA\"> seem </span><span style=\"background-color: #FFFEFE\"> drawn </span><span style=\"background-color: #FFFDFD\"> to </span><span style=\"background-color: #FFFEFE\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFDFD\"> necessarily </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFDFD\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFDFD\"> much </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFCFC\"> fact </span><span style=\"background-color: #FFFCFC\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFDFD\"> are </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFDFD\"> dead </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFDFD\"> with </span><span style=\"background-color: #FFEBEB\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFF4F4\"> no </span><span style=\"background-color: #FFFEFE\"> rewards </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> may </span><span style=\"background-color: #FFFEFE\"> play </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> part </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> sexual </span><span style=\"background-color: #FFFEFE\"> awakening </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> but </span><span style=\"background-color: #FFFDFD\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFFBFB\"> will </span><span style=\"background-color: #FFFDFD\"> not </span><span style=\"background-color: #FFFEFE\"> turn </span><span style=\"background-color: #FFFEFE\"> homosexual </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFF6F6\"> seems </span><span style=\"background-color: #FFFAFA\"> clear </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFCFC\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFF9F9\"> are </span><span style=\"background-color: #FFE3E3\"> quite </span><span style=\"background-color: #FFFDFD\"> heterosexual </span><span style=\"background-color: #FFFEFE\"> when </span><span style=\"background-color: #FFFEFE\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFEFE\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> movie </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFEFE\"> , </span><br><br>[Visualize Attention of BERT_8]<br><span style=\"background-color: #FFFAFA\"> [CLS] </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> was </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FF4444\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFE2E2\"> tri </span><span style=\"background-color: #FFF4F4\"> ##bad </span><span style=\"background-color: #FFFDFD\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFEFE\"> quite </span><span style=\"background-color: #FFFEFE\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FF0F0F\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> critic </span><span style=\"background-color: #FFFEFE\"> ##ises </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFDFD\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> oppressive </span><span style=\"background-color: #FFFCFC\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFBFB\"> marriages </span><span style=\"background-color: #FFFBFB\"> by </span><span style=\"background-color: #FFF9F9\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> importance </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFF0F0\"> status </span><span style=\"background-color: #FFFDFD\"> and </span><span style=\"background-color: #FFE9E9\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFCFC\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFBFB\"> ##yp </span><span style=\"background-color: #FFFDFD\"> ##oc </span><span style=\"background-color: #FFFDFD\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFF9F9\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> their </span><span style=\"background-color: #FFF7F7\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFCFC\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFCFC\"> duty </span><span style=\"background-color: #FFF4F4\"> and </span><span style=\"background-color: #FFFAFA\"> so </span><span style=\"background-color: #FFFCFC\"> on </span><span style=\"background-color: #FF0000\"> . </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FF9898\"> the </span><span style=\"background-color: #FFFEFE\"> heart </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> touching </span><span style=\"background-color: #FFFEFE\"> love </span><span style=\"background-color: #FFFEFE\"> story </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> goes </span><span style=\"background-color: #FFFEFE\"> beyond </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFAFA\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FF1616\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FFFEFE\"> well </span><span style=\"background-color: #FFFEFE\"> acted </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> genuine </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> completely </span><span style=\"background-color: #FFFEFE\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFFEFE\"> ##vable </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFAFA\"> bollywood </span><span style=\"background-color: #FFFEFE\"> flick </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FF0E0E\"> . </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> main </span><span style=\"background-color: #FFFEFE\"> faults </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> i </span><span style=\"background-color: #FFFEFE\"> saw </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> was </span><span style=\"background-color: #FFFEFE\"> first </span><span style=\"background-color: #FFFDFD\"> , </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFDFD\"> lovers </span><span style=\"background-color: #FFFEFE\"> seem </span><span style=\"background-color: #FFFEFE\"> drawn </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> necessarily </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFDFD\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFDFD\"> as </span><span style=\"background-color: #FFFEFE\"> much </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> fact </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFDFD\"> stuck </span><span style=\"background-color: #FFFCFC\"> in </span><span style=\"background-color: #FFFCFC\"> dead </span><span style=\"background-color: #FFFBFB\"> end </span><span style=\"background-color: #FFF3F3\"> marriages </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFFDFD\"> passion </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> no </span><span style=\"background-color: #FFF6F6\"> rewards </span><span style=\"background-color: #FF0101\"> . </span><span style=\"background-color: #FFFEFE\"> this </span><span style=\"background-color: #FFFEFE\"> may </span><span style=\"background-color: #FFFEFE\"> play </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> part </span><span style=\"background-color: #FFFDFD\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> sexual </span><span style=\"background-color: #FFFEFE\"> awakening </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FF3131\"> , </span><span style=\"background-color: #FFF2F2\"> but </span><span style=\"background-color: #FFFDFD\"> most </span><span style=\"background-color: #FFF7F7\"> people </span><span style=\"background-color: #FFFBFB\"> stuck </span><span style=\"background-color: #FFFAFA\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFBFB\"> same </span><span style=\"background-color: #FFFDFD\"> situation </span><span style=\"background-color: #FFFDFD\"> will </span><span style=\"background-color: #FFFCFC\"> not </span><span style=\"background-color: #FFFDFD\"> turn </span><span style=\"background-color: #FFEAEA\"> homosexual </span><span style=\"background-color: #FF0404\"> . </span><span style=\"background-color: #FFFEFE\"> it </span><span style=\"background-color: #FFFEFE\"> seems </span><span style=\"background-color: #FFFEFE\"> clear </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> two </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFFEFE\"> quite </span><span style=\"background-color: #FFFCFC\"> heterosexual </span><span style=\"background-color: #FFFEFE\"> when </span><span style=\"background-color: #FFF7F7\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFBFB\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFCFC\"> movie </span><span style=\"background-color: #FFFDFD\"> with </span><span style=\"background-color: #FFFDFD\"> aa </span><span style=\"background-color: #FFFCFC\"> ##sho </span><span style=\"background-color: #FFF5F5\"> ##k </span><span style=\"background-color: #FFDADA\"> , </span><br><br>[Visualize Attention of BERT_9]<br><span style=\"background-color: #FFFBFB\"> [CLS] </span><span style=\"background-color: #FFFDFD\"> this </span><span style=\"background-color: #FFF8F8\"> was </span><span style=\"background-color: #FFEBEB\"> a </span><span style=\"background-color: #FFF5F5\"> great </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> every </span><span style=\"background-color: #FFFEFE\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFF4F4\"> tackles </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFEFE\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFBFB\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFAFA\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFDFD\"> that </span><span style=\"background-color: #FFFAFA\"> is </span><span style=\"background-color: #FFFBFB\"> quite </span><span style=\"background-color: #FFF9F9\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFDFD\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> any </span><span style=\"background-color: #FFFDFD\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFDFD\"> . </span><span style=\"background-color: #FFFBFB\"> it </span><span style=\"background-color: #FFD5D5\"> critic </span><span style=\"background-color: #FFE8E8\"> ##ises </span><span style=\"background-color: #FFF1F1\"> a </span><span style=\"background-color: #FFFEFE\"> great </span><span style=\"background-color: #FFFBFB\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFCFC\"> customs </span><span style=\"background-color: #FFFCFC\"> that </span><span style=\"background-color: #FFFEFE\"> many </span><span style=\"background-color: #FFFAFA\"> find </span><span style=\"background-color: #FFF9F9\"> oppressive </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFDFD\"> importance </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFDFD\"> religious </span><span style=\"background-color: #FFFCFC\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFCFC\"> ##oc </span><span style=\"background-color: #FFFDFD\"> ##ris </span><span style=\"background-color: #FFFCFC\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFCFC\"> sex </span><span style=\"background-color: #FFFCFC\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFFDFD\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFF9F9\"> making </span><span style=\"background-color: #FFFDFD\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF2F2\"> the </span><span style=\"background-color: #FFFCFC\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFDFD\"> duty </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFDFD\"> so </span><span style=\"background-color: #FFFCFC\"> on </span><span style=\"background-color: #FFFDFD\"> . </span><span style=\"background-color: #FFF8F8\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFEFEF\"> heart </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFA3A3\"> is </span><span style=\"background-color: #FF0000\"> a </span><span style=\"background-color: #FFDADA\"> touching </span><span style=\"background-color: #FFF5F5\"> love </span><span style=\"background-color: #FFF7F7\"> story </span><span style=\"background-color: #FFDFDF\"> that </span><span style=\"background-color: #FFC0C0\"> goes </span><span style=\"background-color: #FFFBFB\"> beyond </span><span style=\"background-color: #FFFDFD\"> such </span><span style=\"background-color: #FFFBFB\"> limitations </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFCFC\"> society </span><span style=\"background-color: #FFFEFE\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFDFD\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFFDFD\"> . </span><span style=\"background-color: #FFF9F9\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FF9898\"> is </span><span style=\"background-color: #FFE7E7\"> well </span><span style=\"background-color: #FFECEC\"> acted </span><span style=\"background-color: #FFF4F4\"> and </span><span style=\"background-color: #FFDCDC\"> genuine </span><span style=\"background-color: #FFFCFC\"> , </span><span style=\"background-color: #FFD9D9\"> completely </span><span style=\"background-color: #FFD1D1\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFF1F1\"> ##vable </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFDFD\"> , </span><span style=\"background-color: #FFFBFB\"> unlike </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> bollywood </span><span style=\"background-color: #FFFEFE\"> flick </span><span style=\"background-color: #FFFCFC\"> ##s </span><span style=\"background-color: #FFFDFD\"> . </span><span style=\"background-color: #FFD7D7\"> the </span><span style=\"background-color: #FFF2F2\"> main </span><span style=\"background-color: #FFD5D5\"> faults </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFDFD\"> i </span><span style=\"background-color: #FFFCFC\"> saw </span><span style=\"background-color: #FFFCFC\"> it </span><span style=\"background-color: #FFFCFC\"> was </span><span style=\"background-color: #FFFAFA\"> first </span><span style=\"background-color: #FFFBFB\"> , </span><span style=\"background-color: #FFE0E0\"> that </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFEFE\"> lovers </span><span style=\"background-color: #FFDADA\"> seem </span><span style=\"background-color: #FFFCFC\"> drawn </span><span style=\"background-color: #FFFCFC\"> to </span><span style=\"background-color: #FFFDFD\"> one </span><span style=\"background-color: #FFFDFD\"> another </span><span style=\"background-color: #FFFEFE\"> not </span><span style=\"background-color: #FFFEFE\"> necessarily </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFBFB\"> a </span><span style=\"background-color: #FFFDFD\"> natural </span><span style=\"background-color: #FFFDFD\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> much </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFF2F2\"> the </span><span style=\"background-color: #FFFCFC\"> fact </span><span style=\"background-color: #FFF7F7\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFBFB\"> are </span><span style=\"background-color: #FFFBFB\"> stuck </span><span style=\"background-color: #FFFCFC\"> in </span><span style=\"background-color: #FFFDFD\"> dead </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFCFC\"> marriages </span><span style=\"background-color: #FFFDFD\"> with </span><span style=\"background-color: #FFFBFB\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFBFB\"> no </span><span style=\"background-color: #FFFDFD\"> rewards </span><span style=\"background-color: #FFFDFD\"> . </span><span style=\"background-color: #FFFBFB\"> this </span><span style=\"background-color: #FFFEFE\"> may </span><span style=\"background-color: #FFFEFE\"> play </span><span style=\"background-color: #FFFCFC\"> a </span><span style=\"background-color: #FFFEFE\"> part </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFBFB\"> sexual </span><span style=\"background-color: #FFFDFD\"> awakening </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> but </span><span style=\"background-color: #FFFEFE\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFEFE\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFFDFD\"> will </span><span style=\"background-color: #FFFDFD\"> not </span><span style=\"background-color: #FFFEFE\"> turn </span><span style=\"background-color: #FFF8F8\"> homosexual </span><span style=\"background-color: #FFFDFD\"> . </span><span style=\"background-color: #FFFDFD\"> it </span><span style=\"background-color: #FFF5F5\"> seems </span><span style=\"background-color: #FFFAFA\"> clear </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> film </span><span style=\"background-color: #FFFAFA\"> that </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFF7F7\"> are </span><span style=\"background-color: #FFDDDD\"> quite </span><span style=\"background-color: #FFEBEB\"> heterosexual </span><span style=\"background-color: #FFFCFC\"> when </span><span style=\"background-color: #FFFEFE\"> radha </span><span style=\"background-color: #FFF7F7\"> does </span><span style=\"background-color: #FFF8F8\"> her </span><span style=\"background-color: #FFFEFE\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> movie </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFCFC\"> , </span><br><br>[Visualize Attention of BERT_10]<br><span style=\"background-color: #FFEDED\"> [CLS] </span><span style=\"background-color: #FFCBCB\"> this </span><span style=\"background-color: #FF9494\"> was </span><span style=\"background-color: #FFE2E2\"> a </span><span style=\"background-color: #FFD8D8\"> great </span><span style=\"background-color: #FFE3E3\"> film </span><span style=\"background-color: #FFF8F8\"> in </span><span style=\"background-color: #FFF7F7\"> every </span><span style=\"background-color: #FFFDFD\"> sense </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFBFB\"> word </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FFF2F2\"> it </span><span style=\"background-color: #FFF0F0\"> tackles </span><span style=\"background-color: #FFEDED\"> the </span><span style=\"background-color: #FFD4D4\"> subject </span><span style=\"background-color: #FFD7D7\"> of </span><span style=\"background-color: #FFF0F0\"> tri </span><span style=\"background-color: #FFF2F2\"> ##bad </span><span style=\"background-color: #FFDEDE\"> ##ism </span><span style=\"background-color: #FFF6F6\"> in </span><span style=\"background-color: #FFD0D0\"> a </span><span style=\"background-color: #FFE2E2\"> society </span><span style=\"background-color: #FFE7E7\"> that </span><span style=\"background-color: #FFEEEE\"> is </span><span style=\"background-color: #FFB3B3\"> quite </span><span style=\"background-color: #FFF7F7\"> into </span><span style=\"background-color: #FFFBFB\"> ##ler </span><span style=\"background-color: #FFFAFA\"> ##ant </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFF2F2\"> any </span><span style=\"background-color: #FFFCFC\"> deviation </span><span style=\"background-color: #FFF5F5\"> ##s </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFCFC\"> norm </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FFEFEF\"> it </span><span style=\"background-color: #FF8282\"> critic </span><span style=\"background-color: #FFE8E8\"> ##ises </span><span style=\"background-color: #FFE8E8\"> a </span><span style=\"background-color: #FFE0E0\"> great </span><span style=\"background-color: #FFD3D3\"> many </span><span style=\"background-color: #FFF6F6\"> indian </span><span style=\"background-color: #FFF2F2\"> customs </span><span style=\"background-color: #FFC9C9\"> that </span><span style=\"background-color: #FFF4F4\"> many </span><span style=\"background-color: #FFE4E4\"> find </span><span style=\"background-color: #FFE8E8\"> oppressive </span><span style=\"background-color: #FFF0F0\"> such </span><span style=\"background-color: #FFF4F4\"> as </span><span style=\"background-color: #FFD4D4\"> the </span><span style=\"background-color: #FFFDFD\"> arranging </span><span style=\"background-color: #FFFAFA\"> of </span><span style=\"background-color: #FFFAFA\"> marriages </span><span style=\"background-color: #FFFBFB\"> by </span><span style=\"background-color: #FFFAFA\"> others </span><span style=\"background-color: #FFE7E7\"> , </span><span style=\"background-color: #FFD0D0\"> the </span><span style=\"background-color: #FFF0F0\"> importance </span><span style=\"background-color: #FFF2F2\"> of </span><span style=\"background-color: #FFFCFC\"> status </span><span style=\"background-color: #FFFDFD\"> and </span><span style=\"background-color: #FFFCFC\"> face </span><span style=\"background-color: #FFF1F1\"> , </span><span style=\"background-color: #FFEFEF\"> religious </span><span style=\"background-color: #FFF5F5\"> h </span><span style=\"background-color: #FFF6F6\"> ##yp </span><span style=\"background-color: #FFF3F3\"> ##oc </span><span style=\"background-color: #FFF3F3\"> ##ris </span><span style=\"background-color: #FFF9F9\"> ##y </span><span style=\"background-color: #FFF9F9\"> , </span><span style=\"background-color: #FFF9F9\"> sex </span><span style=\"background-color: #FFF7F7\"> ##ism </span><span style=\"background-color: #FFF1F1\"> , </span><span style=\"background-color: #FFCDCD\"> the </span><span style=\"background-color: #FFF9F9\"> valuation </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFF0F0\"> women </span><span style=\"background-color: #FFF9F9\"> in </span><span style=\"background-color: #FFFCFC\"> terms </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFFBFB\"> their </span><span style=\"background-color: #FFFCFC\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFDFD\"> capacity </span><span style=\"background-color: #FFF6F6\"> , </span><span style=\"background-color: #FFD3D3\"> the </span><span style=\"background-color: #FFFBFB\"> binding </span><span style=\"background-color: #FFF1F1\"> concepts </span><span style=\"background-color: #FFE6E6\"> of </span><span style=\"background-color: #FFF1F1\"> duty </span><span style=\"background-color: #FFF1F1\"> and </span><span style=\"background-color: #FFEEEE\"> so </span><span style=\"background-color: #FFF0F0\"> on </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FFF1F1\"> at </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFEFEF\"> heart </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFEEEE\"> the </span><span style=\"background-color: #FFF0F0\"> film </span><span style=\"background-color: #FFE3E3\"> is </span><span style=\"background-color: #FFE5E5\"> a </span><span style=\"background-color: #FFE0E0\"> touching </span><span style=\"background-color: #FFECEC\"> love </span><span style=\"background-color: #FFFBFB\"> story </span><span style=\"background-color: #FFC7C7\"> that </span><span style=\"background-color: #FFF5F5\"> goes </span><span style=\"background-color: #FFF4F4\"> beyond </span><span style=\"background-color: #FFC0C0\"> such </span><span style=\"background-color: #FFDFDF\"> limitations </span><span style=\"background-color: #FFF7F7\"> of </span><span style=\"background-color: #FFEFEF\"> the </span><span style=\"background-color: #FFF4F4\"> society </span><span style=\"background-color: #FFF0F0\"> which </span><span style=\"background-color: #FFDEDE\"> the </span><span style=\"background-color: #FFF7F7\"> two </span><span style=\"background-color: #FFFBFB\"> protagonists </span><span style=\"background-color: #FFFDFD\"> find </span><span style=\"background-color: #FFF9F9\"> themselves </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FFF3F3\"> the </span><span style=\"background-color: #FFF7F7\"> film </span><span style=\"background-color: #FFE9E9\"> is </span><span style=\"background-color: #FFF4F4\"> well </span><span style=\"background-color: #FFEEEE\"> acted </span><span style=\"background-color: #FFF3F3\"> and </span><span style=\"background-color: #FFF4F4\"> genuine </span><span style=\"background-color: #FFE4E4\"> , </span><span style=\"background-color: #FFBEBE\"> completely </span><span style=\"background-color: #FFF7F7\"> bel </span><span style=\"background-color: #FFFCFC\"> ##ie </span><span style=\"background-color: #FFFAFA\"> ##vable </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFFDFD\"> beginning </span><span style=\"background-color: #FFFBFB\"> to </span><span style=\"background-color: #FFFDFD\"> end </span><span style=\"background-color: #FFF1F1\"> , </span><span style=\"background-color: #FFF9F9\"> unlike </span><span style=\"background-color: #FFFBFB\"> most </span><span style=\"background-color: #FFF1F1\"> bollywood </span><span style=\"background-color: #FFF4F4\"> flick </span><span style=\"background-color: #FFF7F7\"> ##s </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FF5656\"> the </span><span style=\"background-color: #FFBDBD\"> main </span><span style=\"background-color: #FF0000\"> faults </span><span style=\"background-color: #FFE9E9\"> of </span><span style=\"background-color: #FFE9E9\"> the </span><span style=\"background-color: #FFF2F2\"> film </span><span style=\"background-color: #FFE2E2\"> as </span><span style=\"background-color: #FFD8D8\"> i </span><span style=\"background-color: #FFEBEB\"> saw </span><span style=\"background-color: #FFF0F0\"> it </span><span style=\"background-color: #FFF2F2\"> was </span><span style=\"background-color: #FFE7E7\"> first </span><span style=\"background-color: #FFCFCF\"> , </span><span style=\"background-color: #FF1818\"> that </span><span style=\"background-color: #FFE7E7\"> the </span><span style=\"background-color: #FFF6F6\"> two </span><span style=\"background-color: #FFF6F6\"> lovers </span><span style=\"background-color: #FFBFBF\"> seem </span><span style=\"background-color: #FFFDFD\"> drawn </span><span style=\"background-color: #FFF4F4\"> to </span><span style=\"background-color: #FFFDFD\"> one </span><span style=\"background-color: #FFFDFD\"> another </span><span style=\"background-color: #FFF8F8\"> not </span><span style=\"background-color: #FFFCFC\"> necessarily </span><span style=\"background-color: #FFF2F2\"> by </span><span style=\"background-color: #FFF7F7\"> a </span><span style=\"background-color: #FFFDFD\"> natural </span><span style=\"background-color: #FFFDFD\"> affinity </span><span style=\"background-color: #FFF7F7\"> for </span><span style=\"background-color: #FFFBFB\"> each </span><span style=\"background-color: #FFFCFC\"> other </span><span style=\"background-color: #FFFCFC\"> as </span><span style=\"background-color: #FFF7F7\"> much </span><span style=\"background-color: #FFF9F9\"> as </span><span style=\"background-color: #FFBEBE\"> the </span><span style=\"background-color: #FFCDCD\"> fact </span><span style=\"background-color: #FF8888\"> that </span><span style=\"background-color: #FFF2F2\"> they </span><span style=\"background-color: #FFF4F4\"> are </span><span style=\"background-color: #FFF1F1\"> stuck </span><span style=\"background-color: #FFF4F4\"> in </span><span style=\"background-color: #FFE4E4\"> dead </span><span style=\"background-color: #FFF4F4\"> end </span><span style=\"background-color: #FFF6F6\"> marriages </span><span style=\"background-color: #FFDFDF\"> with </span><span style=\"background-color: #FFE0E0\"> no </span><span style=\"background-color: #FFEDED\"> passion </span><span style=\"background-color: #FFDCDC\"> and </span><span style=\"background-color: #FFE1E1\"> no </span><span style=\"background-color: #FFFCFC\"> rewards </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FFB4B4\"> this </span><span style=\"background-color: #FFE5E5\"> may </span><span style=\"background-color: #FFF4F4\"> play </span><span style=\"background-color: #FFF6F6\"> a </span><span style=\"background-color: #FFFCFC\"> part </span><span style=\"background-color: #FFF1F1\"> in </span><span style=\"background-color: #FFC0C0\"> the </span><span style=\"background-color: #FFFAFA\"> sexual </span><span style=\"background-color: #FFF6F6\"> awakening </span><span style=\"background-color: #FFF1F1\"> of </span><span style=\"background-color: #FFF3F3\"> the </span><span style=\"background-color: #FFF5F5\"> characters </span><span style=\"background-color: #FFFCFC\"> , </span><span style=\"background-color: #FFF3F3\"> but </span><span style=\"background-color: #FFF3F3\"> most </span><span style=\"background-color: #FFF1F1\"> people </span><span style=\"background-color: #FFF6F6\"> stuck </span><span style=\"background-color: #FFF6F6\"> in </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFFDFD\"> same </span><span style=\"background-color: #FFDCDC\"> situation </span><span style=\"background-color: #FFE2E2\"> will </span><span style=\"background-color: #FFCFCF\"> not </span><span style=\"background-color: #FFF3F3\"> turn </span><span style=\"background-color: #FFEBEB\"> homosexual </span><span style=\"background-color: #FFFCFC\"> . </span><span style=\"background-color: #FFD2D2\"> it </span><span style=\"background-color: #FF6060\"> seems </span><span style=\"background-color: #FFEBEB\"> clear </span><span style=\"background-color: #FFF7F7\"> from </span><span style=\"background-color: #FFF3F3\"> the </span><span style=\"background-color: #FFF8F8\"> beginning </span><span style=\"background-color: #FFF9F9\"> of </span><span style=\"background-color: #FFE5E5\"> the </span><span style=\"background-color: #FFE7E7\"> film </span><span style=\"background-color: #FFB6B6\"> that </span><span style=\"background-color: #FFDFDF\"> the </span><span style=\"background-color: #FFF5F5\"> two </span><span style=\"background-color: #FFF2F2\"> characters </span><span style=\"background-color: #FFFAFA\"> are </span><span style=\"background-color: #FFB2B2\"> quite </span><span style=\"background-color: #FFEEEE\"> heterosexual </span><span style=\"background-color: #FFECEC\"> when </span><span style=\"background-color: #FF6565\"> radha </span><span style=\"background-color: #FFF6F6\"> does </span><span style=\"background-color: #FFF5F5\"> her </span><span style=\"background-color: #FFC8C8\"> scene </span><span style=\"background-color: #FFF9F9\"> at </span><span style=\"background-color: #FFF6F6\"> the </span><span style=\"background-color: #FFF1F1\"> end </span><span style=\"background-color: #FFFAFA\"> of </span><span style=\"background-color: #FFEAEA\"> the </span><span style=\"background-color: #FFE7E7\"> movie </span><span style=\"background-color: #FFE4E4\"> with </span><span style=\"background-color: #FFFAFA\"> aa </span><span style=\"background-color: #FFF7F7\"> ##sho </span><span style=\"background-color: #FFEDED\"> ##k </span><span style=\"background-color: #FFF3F3\"> , </span><br><br>[Visualize Attention of BERT_11]<br><span style=\"background-color: #FFFEFE\"> [CLS] </span><span style=\"background-color: #FFE8E8\"> this </span><span style=\"background-color: #FF2222\"> was </span><span style=\"background-color: #FFCBCB\"> a </span><span style=\"background-color: #FF6767\"> great </span><span style=\"background-color: #FFFCFC\"> film </span><span style=\"background-color: #FFE3E3\"> in </span><span style=\"background-color: #FFD2D2\"> every </span><span style=\"background-color: #FFF8F8\"> sense </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFEFEF\"> word </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFECEC\"> it </span><span style=\"background-color: #FFEBEB\"> tackles </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> subject </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> tri </span><span style=\"background-color: #FFFEFE\"> ##bad </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> a </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFDFD\"> that </span><span style=\"background-color: #FFFEFE\"> is </span><span style=\"background-color: #FF5C5C\"> quite </span><span style=\"background-color: #FFFDFD\"> into </span><span style=\"background-color: #FFFEFE\"> ##ler </span><span style=\"background-color: #FFFEFE\"> ##ant </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> any </span><span style=\"background-color: #FFFEFE\"> deviation </span><span style=\"background-color: #FFFEFE\"> ##s </span><span style=\"background-color: #FFFEFE\"> from </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> norm </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF9F9\"> it </span><span style=\"background-color: #FFF4F4\"> critic </span><span style=\"background-color: #FFFDFD\"> ##ises </span><span style=\"background-color: #FFFDFD\"> a </span><span style=\"background-color: #FF0F0F\"> great </span><span style=\"background-color: #FFFCFC\"> many </span><span style=\"background-color: #FFFEFE\"> indian </span><span style=\"background-color: #FFFEFE\"> customs </span><span style=\"background-color: #FFFEFE\"> that </span><span style=\"background-color: #FFFDFD\"> many </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFDFD\"> oppressive </span><span style=\"background-color: #FFFEFE\"> such </span><span style=\"background-color: #FFFEFE\"> as </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> arranging </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFEFE\"> by </span><span style=\"background-color: #FFFEFE\"> others </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> importance </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> status </span><span style=\"background-color: #FFFEFE\"> and </span><span style=\"background-color: #FFFEFE\"> face </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> religious </span><span style=\"background-color: #FFFEFE\"> h </span><span style=\"background-color: #FFFEFE\"> ##yp </span><span style=\"background-color: #FFFEFE\"> ##oc </span><span style=\"background-color: #FFFEFE\"> ##ris </span><span style=\"background-color: #FFFEFE\"> ##y </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> sex </span><span style=\"background-color: #FFFEFE\"> ##ism </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> valuation </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> women </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> terms </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> their </span><span style=\"background-color: #FFFEFE\"> baby </span><span style=\"background-color: #FFFEFE\"> making </span><span style=\"background-color: #FFFEFE\"> capacity </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> binding </span><span style=\"background-color: #FFFEFE\"> concepts </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> duty </span><span style=\"background-color: #FFEAEA\"> and </span><span style=\"background-color: #FFF8F8\"> so </span><span style=\"background-color: #FFFCFC\"> on </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF1F1\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFBDBD\"> heart </span><span style=\"background-color: #FFF2F2\"> of </span><span style=\"background-color: #FFF9F9\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFDEDE\"> is </span><span style=\"background-color: #FFBEBE\"> a </span><span style=\"background-color: #FF9D9D\"> touching </span><span style=\"background-color: #FFFDFD\"> love </span><span style=\"background-color: #FFFCFC\"> story </span><span style=\"background-color: #FF8080\"> that </span><span style=\"background-color: #FFD1D1\"> goes </span><span style=\"background-color: #FF7373\"> beyond </span><span style=\"background-color: #FFFBFB\"> such </span><span style=\"background-color: #FFFEFE\"> limitations </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> society </span><span style=\"background-color: #FFFDFD\"> which </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFEFE\"> protagonists </span><span style=\"background-color: #FFFEFE\"> find </span><span style=\"background-color: #FFFEFE\"> themselves </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF6F6\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFD5D5\"> is </span><span style=\"background-color: #FFC7C7\"> well </span><span style=\"background-color: #FFEFEF\"> acted </span><span style=\"background-color: #FFEBEB\"> and </span><span style=\"background-color: #FFDCDC\"> genuine </span><span style=\"background-color: #FFBBBB\"> , </span><span style=\"background-color: #FF0000\"> completely </span><span style=\"background-color: #FFBEBE\"> bel </span><span style=\"background-color: #FFFEFE\"> ##ie </span><span style=\"background-color: #FFF3F3\"> ##vable </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFEFE\"> to </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFEDED\"> , </span><span style=\"background-color: #FFEFEF\"> unlike </span><span style=\"background-color: #FFEAEA\"> most </span><span style=\"background-color: #FFFEFE\"> bollywood </span><span style=\"background-color: #FFFDFD\"> flick </span><span style=\"background-color: #FFECEC\"> ##s </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFEAEA\"> the </span><span style=\"background-color: #FFCCCC\"> main </span><span style=\"background-color: #FFAEAE\"> faults </span><span style=\"background-color: #FFD6D6\"> of </span><span style=\"background-color: #FFF3F3\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFF6F6\"> as </span><span style=\"background-color: #FFEAEA\"> i </span><span style=\"background-color: #FFA3A3\"> saw </span><span style=\"background-color: #FFFCFC\"> it </span><span style=\"background-color: #FFEAEA\"> was </span><span style=\"background-color: #FF7C7C\"> first </span><span style=\"background-color: #FFF7F7\"> , </span><span style=\"background-color: #FFDFDF\"> that </span><span style=\"background-color: #FFFCFC\"> the </span><span style=\"background-color: #FFFDFD\"> two </span><span style=\"background-color: #FFFEFE\"> lovers </span><span style=\"background-color: #FFF7F7\"> seem </span><span style=\"background-color: #FFFCFC\"> drawn </span><span style=\"background-color: #FFFDFD\"> to </span><span style=\"background-color: #FFFEFE\"> one </span><span style=\"background-color: #FFFEFE\"> another </span><span style=\"background-color: #FFF2F2\"> not </span><span style=\"background-color: #FFFEFE\"> necessarily </span><span style=\"background-color: #FFFBFB\"> by </span><span style=\"background-color: #FFFDFD\"> a </span><span style=\"background-color: #FFFEFE\"> natural </span><span style=\"background-color: #FFFEFE\"> affinity </span><span style=\"background-color: #FFFEFE\"> for </span><span style=\"background-color: #FFFEFE\"> each </span><span style=\"background-color: #FFFEFE\"> other </span><span style=\"background-color: #FFFDFD\"> as </span><span style=\"background-color: #FFEFEF\"> much </span><span style=\"background-color: #FFFCFC\"> as </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFBFB\"> fact </span><span style=\"background-color: #FFF9F9\"> that </span><span style=\"background-color: #FFFEFE\"> they </span><span style=\"background-color: #FFFDFD\"> are </span><span style=\"background-color: #FFFBFB\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFDFD\"> dead </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> marriages </span><span style=\"background-color: #FFFCFC\"> with </span><span style=\"background-color: #FFF8F8\"> no </span><span style=\"background-color: #FFFEFE\"> passion </span><span style=\"background-color: #FFF8F8\"> and </span><span style=\"background-color: #FFF7F7\"> no </span><span style=\"background-color: #FFFDFD\"> rewards </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFFCFC\"> this </span><span style=\"background-color: #FFE8E8\"> may </span><span style=\"background-color: #FFEBEB\"> play </span><span style=\"background-color: #FFF5F5\"> a </span><span style=\"background-color: #FFF8F8\"> part </span><span style=\"background-color: #FFFAFA\"> in </span><span style=\"background-color: #FFF6F6\"> the </span><span style=\"background-color: #FFFEFE\"> sexual </span><span style=\"background-color: #FFF8F8\"> awakening </span><span style=\"background-color: #FFFBFB\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> , </span><span style=\"background-color: #FFF3F3\"> but </span><span style=\"background-color: #FFF9F9\"> most </span><span style=\"background-color: #FFFEFE\"> people </span><span style=\"background-color: #FFFCFC\"> stuck </span><span style=\"background-color: #FFFEFE\"> in </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFDFD\"> same </span><span style=\"background-color: #FFFEFE\"> situation </span><span style=\"background-color: #FFF6F6\"> will </span><span style=\"background-color: #FFB0B0\"> not </span><span style=\"background-color: #FFFDFD\"> turn </span><span style=\"background-color: #FFFDFD\"> homosexual </span><span style=\"background-color: #FFFEFE\"> . </span><span style=\"background-color: #FFF9F9\"> it </span><span style=\"background-color: #FFCECE\"> seems </span><span style=\"background-color: #FFD1D1\"> clear </span><span style=\"background-color: #FFFDFD\"> from </span><span style=\"background-color: #FFF7F7\"> the </span><span style=\"background-color: #FFFEFE\"> beginning </span><span style=\"background-color: #FFFDFD\"> of </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFDFD\"> film </span><span style=\"background-color: #FFF1F1\"> that </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFCFC\"> two </span><span style=\"background-color: #FFFEFE\"> characters </span><span style=\"background-color: #FFFEFE\"> are </span><span style=\"background-color: #FFDEDE\"> quite </span><span style=\"background-color: #FFFEFE\"> heterosexual </span><span style=\"background-color: #FFFEFE\"> when </span><span style=\"background-color: #FFFDFD\"> radha </span><span style=\"background-color: #FFFEFE\"> does </span><span style=\"background-color: #FFFEFE\"> her </span><span style=\"background-color: #FFFDFD\"> scene </span><span style=\"background-color: #FFFEFE\"> at </span><span style=\"background-color: #FFFEFE\"> the </span><span style=\"background-color: #FFFEFE\"> end </span><span style=\"background-color: #FFFEFE\"> of </span><span style=\"background-color: #FFFDFD\"> the </span><span style=\"background-color: #FFFEFE\"> movie </span><span style=\"background-color: #FFFEFE\"> with </span><span style=\"background-color: #FFFEFE\"> aa </span><span style=\"background-color: #FFFEFE\"> ##sho </span><span style=\"background-color: #FFFEFE\"> ##k </span><span style=\"background-color: #FFFCFC\"> , </span><br><br>[Visualize Attention of BERT_12]<br><span style=\"background-color: #FFE6E6\"> [CLS] </span><span style=\"background-color: #FFD7D7\"> this </span><span style=\"background-color: #FF2424\"> was </span><span style=\"background-color: #FF9393\"> a </span><span style=\"background-color: #FF0000\"> great </span><span style=\"background-color: #FFEAEA\"> film </span><span style=\"background-color: #FFE9E9\"> in </span><span style=\"background-color: #FFBCBC\"> every </span><span style=\"background-color: #FFF7F7\"> sense </span><span style=\"background-color: #FFFCFC\"> of </span><span style=\"background-color: #FFFAFA\"> the </span><span style=\"background-color: #FFF6F6\"> word </span><span style=\"background-color: #FF9090\"> . </span><span style=\"background-color: #FFDEDE\"> it </span><span style=\"background-color: #FFB2B2\"> tackles </span><span style=\"background-color: #FFF2F2\"> the </span><span style=\"background-color: #FFE5E5\"> subject </span><span style=\"background-color: #FFE8E8\"> of </span><span style=\"background-color: #FFE6E6\"> tri </span><span style=\"background-color: #FFF0F0\"> ##bad </span><span style=\"background-color: #FFD7D7\"> ##ism </span><span style=\"background-color: #FFF1F1\"> in </span><span style=\"background-color: #FFDDDD\"> a </span><span style=\"background-color: #FFC0C0\"> society </span><span style=\"background-color: #FFE8E8\"> that </span><span style=\"background-color: #FFF0F0\"> is </span><span style=\"background-color: #FF9F9F\"> quite </span><span style=\"background-color: #FFF6F6\"> into </span><span style=\"background-color: #FFFBFB\"> ##ler </span><span style=\"background-color: #FFFAFA\"> ##ant </span><span style=\"background-color: #FFFAFA\"> of </span><span style=\"background-color: #FFEEEE\"> any </span><span style=\"background-color: #FFF4F4\"> deviation </span><span style=\"background-color: #FFF9F9\"> ##s </span><span style=\"background-color: #FFFBFB\"> from </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFF7F7\"> norm </span><span style=\"background-color: #FF7979\"> . </span><span style=\"background-color: #FFE5E5\"> it </span><span style=\"background-color: #FF8787\"> critic </span><span style=\"background-color: #FFBCBC\"> ##ises </span><span style=\"background-color: #FFDADA\"> a </span><span style=\"background-color: #FFA0A0\"> great </span><span style=\"background-color: #FFCECE\"> many </span><span style=\"background-color: #FFF0F0\"> indian </span><span style=\"background-color: #FFE9E9\"> customs </span><span style=\"background-color: #FFC4C4\"> that </span><span style=\"background-color: #FFDEDE\"> many </span><span style=\"background-color: #FFC0C0\"> find </span><span style=\"background-color: #FFCCCC\"> oppressive </span><span style=\"background-color: #FFEDED\"> such </span><span style=\"background-color: #FFF5F5\"> as </span><span style=\"background-color: #FFE1E1\"> the </span><span style=\"background-color: #FFE1E1\"> arranging </span><span style=\"background-color: #FFE5E5\"> of </span><span style=\"background-color: #FFB9B9\"> marriages </span><span style=\"background-color: #FFDDDD\"> by </span><span style=\"background-color: #FFB2B2\"> others </span><span style=\"background-color: #FFE6E6\"> , </span><span style=\"background-color: #FFDEDE\"> the </span><span style=\"background-color: #FFE8E8\"> importance </span><span style=\"background-color: #FFEFEF\"> of </span><span style=\"background-color: #FFB7B7\"> status </span><span style=\"background-color: #FFF0F0\"> and </span><span style=\"background-color: #FFD3D3\"> face </span><span style=\"background-color: #FFEEEE\"> , </span><span style=\"background-color: #FFEAEA\"> religious </span><span style=\"background-color: #FFF6F6\"> h </span><span style=\"background-color: #FFF5F5\"> ##yp </span><span style=\"background-color: #FFF2F2\"> ##oc </span><span style=\"background-color: #FFEFEF\"> ##ris </span><span style=\"background-color: #FFF6F6\"> ##y </span><span style=\"background-color: #FFF7F7\"> , </span><span style=\"background-color: #FFEDED\"> sex </span><span style=\"background-color: #FFF7F7\"> ##ism </span><span style=\"background-color: #FFEEEE\"> , </span><span style=\"background-color: #FFDCDC\"> the </span><span style=\"background-color: #FFE9E9\"> valuation </span><span style=\"background-color: #FFF3F3\"> of </span><span style=\"background-color: #FFE0E0\"> women </span><span style=\"background-color: #FFF6F6\"> in </span><span style=\"background-color: #FFF6F6\"> terms </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFF6F6\"> their </span><span style=\"background-color: #FFECEC\"> baby </span><span style=\"background-color: #FFF7F7\"> making </span><span style=\"background-color: #FFF4F4\"> capacity </span><span style=\"background-color: #FFEFEF\"> , </span><span style=\"background-color: #FFDFDF\"> the </span><span style=\"background-color: #FFDCDC\"> binding </span><span style=\"background-color: #FFE7E7\"> concepts </span><span style=\"background-color: #FFEFEF\"> of </span><span style=\"background-color: #FFEAEA\"> duty </span><span style=\"background-color: #FFE0E0\"> and </span><span style=\"background-color: #FFE0E0\"> so </span><span style=\"background-color: #FFDDDD\"> on </span><span style=\"background-color: #FF7272\"> . </span><span style=\"background-color: #FFBEBE\"> at </span><span style=\"background-color: #FFAEAE\"> the </span><span style=\"background-color: #FFADAD\"> heart </span><span style=\"background-color: #FFCFCF\"> of </span><span style=\"background-color: #FFDCDC\"> the </span><span style=\"background-color: #FFEEEE\"> film </span><span style=\"background-color: #FF8F8F\"> is </span><span style=\"background-color: #FF1313\"> a </span><span style=\"background-color: #FF8A8A\"> touching </span><span style=\"background-color: #FFEAEA\"> love </span><span style=\"background-color: #FFF0F0\"> story </span><span style=\"background-color: #FF7E7E\"> that </span><span style=\"background-color: #FFB1B1\"> goes </span><span style=\"background-color: #FFABAB\"> beyond </span><span style=\"background-color: #FFD9D9\"> such </span><span style=\"background-color: #FFE0E0\"> limitations </span><span style=\"background-color: #FFE6E6\"> of </span><span style=\"background-color: #FFEBEB\"> the </span><span style=\"background-color: #FFA1A1\"> society </span><span style=\"background-color: #FFF0F0\"> which </span><span style=\"background-color: #FFEDED\"> the </span><span style=\"background-color: #FFF2F2\"> two </span><span style=\"background-color: #FFF9F9\"> protagonists </span><span style=\"background-color: #FFF8F8\"> find </span><span style=\"background-color: #FFF9F9\"> themselves </span><span style=\"background-color: #FF7C7C\"> . </span><span style=\"background-color: #FFC1C1\"> the </span><span style=\"background-color: #FFF4F4\"> film </span><span style=\"background-color: #FF1B1B\"> is </span><span style=\"background-color: #FFB8B8\"> well </span><span style=\"background-color: #FFBCBC\"> acted </span><span style=\"background-color: #FFDBDB\"> and </span><span style=\"background-color: #FFBCBC\"> genuine </span><span style=\"background-color: #FFB7B7\"> , </span><span style=\"background-color: #FF4343\"> completely </span><span style=\"background-color: #FF6D6D\"> bel </span><span style=\"background-color: #FFFCFC\"> ##ie </span><span style=\"background-color: #FFDADA\"> ##vable </span><span style=\"background-color: #FFDEDE\"> from </span><span style=\"background-color: #FFE8E8\"> beginning </span><span style=\"background-color: #FFE1E1\"> to </span><span style=\"background-color: #FFDDDD\"> end </span><span style=\"background-color: #FFE5E5\"> , </span><span style=\"background-color: #FFF2F2\"> unlike </span><span style=\"background-color: #FFF2F2\"> most </span><span style=\"background-color: #FFEDED\"> bollywood </span><span style=\"background-color: #FFF3F3\"> flick </span><span style=\"background-color: #FFD7D7\"> ##s </span><span style=\"background-color: #FF7979\"> . </span><span style=\"background-color: #FFA0A0\"> the </span><span style=\"background-color: #FFC2C2\"> main </span><span style=\"background-color: #FF5757\"> faults </span><span style=\"background-color: #FFC0C0\"> of </span><span style=\"background-color: #FFCBCB\"> the </span><span style=\"background-color: #FFF2F2\"> film </span><span style=\"background-color: #FFE9E9\"> as </span><span style=\"background-color: #FFDEDE\"> i </span><span style=\"background-color: #FF9999\"> saw </span><span style=\"background-color: #FFE6E6\"> it </span><span style=\"background-color: #FFE6E6\"> was </span><span style=\"background-color: #FF9C9C\"> first </span><span style=\"background-color: #FFCDCD\"> , </span><span style=\"background-color: #FF3B3B\"> that </span><span style=\"background-color: #FFE9E9\"> the </span><span style=\"background-color: #FFF2F2\"> two </span><span style=\"background-color: #FFF6F6\"> lovers </span><span style=\"background-color: #FFBEBE\"> seem </span><span style=\"background-color: #FFF3F3\"> drawn </span><span style=\"background-color: #FFE8E8\"> to </span><span style=\"background-color: #FFF8F8\"> one </span><span style=\"background-color: #FFF9F9\"> another </span><span style=\"background-color: #FFE7E7\"> not </span><span style=\"background-color: #FFF6F6\"> necessarily </span><span style=\"background-color: #FFF0F0\"> by </span><span style=\"background-color: #FFF5F5\"> a </span><span style=\"background-color: #FFF6F6\"> natural </span><span style=\"background-color: #FFF1F1\"> affinity </span><span style=\"background-color: #FFF3F3\"> for </span><span style=\"background-color: #FFF9F9\"> each </span><span style=\"background-color: #FFFAFA\"> other </span><span style=\"background-color: #FFF3F3\"> as </span><span style=\"background-color: #FFE3E3\"> much </span><span style=\"background-color: #FFEDED\"> as </span><span style=\"background-color: #FFD1D1\"> the </span><span style=\"background-color: #FFB7B7\"> fact </span><span style=\"background-color: #FFA5A5\"> that </span><span style=\"background-color: #FFF4F4\"> they </span><span style=\"background-color: #FFEEEE\"> are </span><span style=\"background-color: #FFC6C6\"> stuck </span><span style=\"background-color: #FFE6E6\"> in </span><span style=\"background-color: #FFE2E2\"> dead </span><span style=\"background-color: #FFE7E7\"> end </span><span style=\"background-color: #FFB8B8\"> marriages </span><span style=\"background-color: #FFC8C8\"> with </span><span style=\"background-color: #FFE0E0\"> no </span><span style=\"background-color: #FFD1D1\"> passion </span><span style=\"background-color: #FFABAB\"> and </span><span style=\"background-color: #FFD9D9\"> no </span><span style=\"background-color: #FF8C8C\"> rewards </span><span style=\"background-color: #FF7373\"> . </span><span style=\"background-color: #FFD6D6\"> this </span><span style=\"background-color: #FFDBDB\"> may </span><span style=\"background-color: #FFD1D1\"> play </span><span style=\"background-color: #FFE7E7\"> a </span><span style=\"background-color: #FFF2F2\"> part </span><span style=\"background-color: #FFE7E7\"> in </span><span style=\"background-color: #FFAEAE\"> the </span><span style=\"background-color: #FFD0D0\"> sexual </span><span style=\"background-color: #FF8B8B\"> awakening </span><span style=\"background-color: #FFE6E6\"> of </span><span style=\"background-color: #FFEEEE\"> the </span><span style=\"background-color: #FFEDED\"> characters </span><span style=\"background-color: #FF8888\"> , </span><span style=\"background-color: #FFE1E1\"> but </span><span style=\"background-color: #FFE1E1\"> most </span><span style=\"background-color: #FFDCDC\"> people </span><span style=\"background-color: #FF9B9B\"> stuck </span><span style=\"background-color: #FFEAEA\"> in </span><span style=\"background-color: #FFE5E5\"> the </span><span style=\"background-color: #FFD7D7\"> same </span><span style=\"background-color: #FFADAD\"> situation </span><span style=\"background-color: #FFD6D6\"> will </span><span style=\"background-color: #FFB7B7\"> not </span><span style=\"background-color: #FFB8B8\"> turn </span><span style=\"background-color: #FFAFAF\"> homosexual </span><span style=\"background-color: #FF7474\"> . </span><span style=\"background-color: #FFE8E8\"> it </span><span style=\"background-color: #FF7E7E\"> seems </span><span style=\"background-color: #FFDEDE\"> clear </span><span style=\"background-color: #FFCACA\"> from </span><span style=\"background-color: #FFEAEA\"> the </span><span style=\"background-color: #FFA9A9\"> beginning </span><span style=\"background-color: #FFEDED\"> of </span><span style=\"background-color: #FFE9E9\"> the </span><span style=\"background-color: #FFEDED\"> film </span><span style=\"background-color: #FFACAC\"> that </span><span style=\"background-color: #FFECEC\"> the </span><span style=\"background-color: #FFE8E8\"> two </span><span style=\"background-color: #FFEFEF\"> characters </span><span style=\"background-color: #FFF1F1\"> are </span><span style=\"background-color: #FFB8B8\"> quite </span><span style=\"background-color: #FFD6D6\"> heterosexual </span><span style=\"background-color: #FFE2E2\"> when </span><span style=\"background-color: #FF7676\"> radha </span><span style=\"background-color: #FFECEC\"> does </span><span style=\"background-color: #FFF0F0\"> her </span><span style=\"background-color: #FFD3D3\"> scene </span><span style=\"background-color: #FFE9E9\"> at </span><span style=\"background-color: #FFF8F8\"> the </span><span style=\"background-color: #FFD5D5\"> end </span><span style=\"background-color: #FFFAFA\"> of </span><span style=\"background-color: #FFEFEF\"> the </span><span style=\"background-color: #FFECEC\"> movie </span><span style=\"background-color: #FFE6E6\"> with </span><span style=\"background-color: #FFF6F6\"> aa </span><span style=\"background-color: #FFF6F6\"> ##sho </span><span style=\"background-color: #FFE3E3\"> ##k </span><span style=\"background-color: #FFDEDE\"> , </span><br><br>[Visualize Attention of BERT_ALL]<br><span style=\"background-color: #FFE6E6\"> [CLS] </span><span style=\"background-color: #FFD7D7\"> this </span><span style=\"background-color: #FF2424\"> was </span><span style=\"background-color: #FF9393\"> a </span><span style=\"background-color: #FF0000\"> great </span><span style=\"background-color: #FFEAEA\"> film </span><span style=\"background-color: #FFE9E9\"> in </span><span style=\"background-color: #FFBCBC\"> every </span><span style=\"background-color: #FFF7F7\"> sense </span><span style=\"background-color: #FFFCFC\"> of </span><span style=\"background-color: #FFFAFA\"> the </span><span style=\"background-color: #FFF6F6\"> word </span><span style=\"background-color: #FF9393\"> . </span><span style=\"background-color: #FFDEDE\"> it </span><span style=\"background-color: #FFB3B3\"> tackles </span><span style=\"background-color: #FFF3F3\"> the </span><span style=\"background-color: #FFE5E5\"> subject </span><span style=\"background-color: #FFEAEA\"> of </span><span style=\"background-color: #FFE7E7\"> tri </span><span style=\"background-color: #FFF0F0\"> ##bad </span><span style=\"background-color: #FFE7E7\"> ##ism </span><span style=\"background-color: #FFF5F5\"> in </span><span style=\"background-color: #FFE2E2\"> a </span><span style=\"background-color: #FFE0E0\"> society </span><span style=\"background-color: #FFE8E8\"> that </span><span style=\"background-color: #FFF0F0\"> is </span><span style=\"background-color: #FF9F9F\"> quite </span><span style=\"background-color: #FFF6F6\"> into </span><span style=\"background-color: #FFFCFC\"> ##ler </span><span style=\"background-color: #FFFAFA\"> ##ant </span><span style=\"background-color: #FFFBFB\"> of </span><span style=\"background-color: #FFEFEF\"> any </span><span style=\"background-color: #FFF5F5\"> deviation </span><span style=\"background-color: #FFFAFA\"> ##s </span><span style=\"background-color: #FFFCFC\"> from </span><span style=\"background-color: #FFFBFB\"> the </span><span style=\"background-color: #FFFBFB\"> norm </span><span style=\"background-color: #FF7D7D\"> . </span><span style=\"background-color: #FFE6E6\"> it </span><span style=\"background-color: #FF8888\"> critic </span><span style=\"background-color: #FFBCBC\"> ##ises </span><span style=\"background-color: #FFDADA\"> a </span><span style=\"background-color: #FFA0A0\"> great </span><span style=\"background-color: #FFCFCF\"> many </span><span style=\"background-color: #FFF5F5\"> indian </span><span style=\"background-color: #FFF1F1\"> customs </span><span style=\"background-color: #FFC5C5\"> that </span><span style=\"background-color: #FFF0F0\"> many </span><span style=\"background-color: #FFC0C0\"> find </span><span style=\"background-color: #FFD2D2\"> oppressive </span><span style=\"background-color: #FFEEEE\"> such </span><span style=\"background-color: #FFF5F5\"> as </span><span style=\"background-color: #FFE7E7\"> the </span><span style=\"background-color: #FFEFEF\"> arranging </span><span style=\"background-color: #FFF3F3\"> of </span><span style=\"background-color: #FFE7E7\"> marriages </span><span style=\"background-color: #FFF1F1\"> by </span><span style=\"background-color: #FFE3E3\"> others </span><span style=\"background-color: #FFE6E6\"> , </span><span style=\"background-color: #FFE4E4\"> the </span><span style=\"background-color: #FFEFEF\"> importance </span><span style=\"background-color: #FFF5F5\"> of </span><span style=\"background-color: #FFD4D4\"> status </span><span style=\"background-color: #FFF5F5\"> and </span><span style=\"background-color: #FFDADA\"> face </span><span style=\"background-color: #FFEEEE\"> , </span><span style=\"background-color: #FFEFEF\"> religious </span><span style=\"background-color: #FFF8F8\"> h </span><span style=\"background-color: #FFF7F7\"> ##yp </span><span style=\"background-color: #FFF5F5\"> ##oc </span><span style=\"background-color: #FFF2F2\"> ##ris </span><span style=\"background-color: #FFF9F9\"> ##y </span><span style=\"background-color: #FFF7F7\"> , </span><span style=\"background-color: #FFF6F6\"> sex </span><span style=\"background-color: #FFF9F9\"> ##ism </span><span style=\"background-color: #FFEEEE\"> , </span><span style=\"background-color: #FFE2E2\"> the </span><span style=\"background-color: #FFEEEE\"> valuation </span><span style=\"background-color: #FFF8F8\"> of </span><span style=\"background-color: #FFEEEE\"> women </span><span style=\"background-color: #FFF7F7\"> in </span><span style=\"background-color: #FFF7F7\"> terms </span><span style=\"background-color: #FFF8F8\"> of </span><span style=\"background-color: #FFF8F8\"> their </span><span style=\"background-color: #FFEFEF\"> baby </span><span style=\"background-color: #FFF9F9\"> making </span><span style=\"background-color: #FFF9F9\"> capacity </span><span style=\"background-color: #FFEFEF\"> , </span><span style=\"background-color: #FFE1E1\"> the </span><span style=\"background-color: #FFF0F0\"> binding </span><span style=\"background-color: #FFEDED\"> concepts </span><span style=\"background-color: #FFF2F2\"> of </span><span style=\"background-color: #FFEFEF\"> duty </span><span style=\"background-color: #FFE2E2\"> and </span><span style=\"background-color: #FFE1E1\"> so </span><span style=\"background-color: #FFDEDE\"> on </span><span style=\"background-color: #FF7676\"> . </span><span style=\"background-color: #FFBEBE\"> at </span><span style=\"background-color: #FFB1B1\"> the </span><span style=\"background-color: #FFADAD\"> heart </span><span style=\"background-color: #FFD0D0\"> of </span><span style=\"background-color: #FFDDDD\"> the </span><span style=\"background-color: #FFEFEF\"> film </span><span style=\"background-color: #FF8F8F\"> is </span><span style=\"background-color: #FF1313\"> a </span><span style=\"background-color: #FF8C8C\"> touching </span><span style=\"background-color: #FFEDED\"> love </span><span style=\"background-color: #FFF0F0\"> story </span><span style=\"background-color: #FF7E7E\"> that </span><span style=\"background-color: #FFB1B1\"> goes </span><span style=\"background-color: #FFACAC\"> beyond </span><span style=\"background-color: #FFDBDB\"> such </span><span style=\"background-color: #FFE3E3\"> limitations </span><span style=\"background-color: #FFF4F4\"> of </span><span style=\"background-color: #FFF2F2\"> the </span><span style=\"background-color: #FFD8D8\"> society </span><span style=\"background-color: #FFF0F0\"> which </span><span style=\"background-color: #FFEEEE\"> the </span><span style=\"background-color: #FFF5F5\"> two </span><span style=\"background-color: #FFFAFA\"> protagonists </span><span style=\"background-color: #FFF9F9\"> find </span><span style=\"background-color: #FFFAFA\"> themselves </span><span style=\"background-color: #FF8080\"> . </span><span style=\"background-color: #FFC1C1\"> the </span><span style=\"background-color: #FFF5F5\"> film </span><span style=\"background-color: #FF1B1B\"> is </span><span style=\"background-color: #FFB8B8\"> well </span><span style=\"background-color: #FFBCBC\"> acted </span><span style=\"background-color: #FFDBDB\"> and </span><span style=\"background-color: #FFBDBD\"> genuine </span><span style=\"background-color: #FFB7B7\"> , </span><span style=\"background-color: #FF4343\"> completely </span><span style=\"background-color: #FF6C6C\"> bel </span><span style=\"background-color: #FFFCFC\"> ##ie </span><span style=\"background-color: #FFDADA\"> ##vable </span><span style=\"background-color: #FFDEDE\"> from </span><span style=\"background-color: #FFE8E8\"> beginning </span><span style=\"background-color: #FFE1E1\"> to </span><span style=\"background-color: #FFDDDD\"> end </span><span style=\"background-color: #FFE5E5\"> , </span><span style=\"background-color: #FFF2F2\"> unlike </span><span style=\"background-color: #FFF2F2\"> most </span><span style=\"background-color: #FFEEEE\"> bollywood </span><span style=\"background-color: #FFF3F3\"> flick </span><span style=\"background-color: #FFD7D7\"> ##s </span><span style=\"background-color: #FF7D7D\"> . </span><span style=\"background-color: #FFA0A0\"> the </span><span style=\"background-color: #FFC2C2\"> main </span><span style=\"background-color: #FF5757\"> faults </span><span style=\"background-color: #FFC0C0\"> of </span><span style=\"background-color: #FFCBCB\"> the </span><span style=\"background-color: #FFF3F3\"> film </span><span style=\"background-color: #FFE9E9\"> as </span><span style=\"background-color: #FFE0E0\"> i </span><span style=\"background-color: #FF9999\"> saw </span><span style=\"background-color: #FFE6E6\"> it </span><span style=\"background-color: #FFE6E6\"> was </span><span style=\"background-color: #FF9C9C\"> first </span><span style=\"background-color: #FFCDCD\"> , </span><span style=\"background-color: #FF3B3B\"> that </span><span style=\"background-color: #FFE9E9\"> the </span><span style=\"background-color: #FFF6F6\"> two </span><span style=\"background-color: #FFF7F7\"> lovers </span><span style=\"background-color: #FFBFBF\"> seem </span><span style=\"background-color: #FFF6F6\"> drawn </span><span style=\"background-color: #FFEEEE\"> to </span><span style=\"background-color: #FFFAFA\"> one </span><span style=\"background-color: #FFF9F9\"> another </span><span style=\"background-color: #FFE7E7\"> not </span><span style=\"background-color: #FFF6F6\"> necessarily </span><span style=\"background-color: #FFF0F0\"> by </span><span style=\"background-color: #FFF6F6\"> a </span><span style=\"background-color: #FFF7F7\"> natural </span><span style=\"background-color: #FFF2F2\"> affinity </span><span style=\"background-color: #FFF6F6\"> for </span><span style=\"background-color: #FFFAFA\"> each </span><span style=\"background-color: #FFFBFB\"> other </span><span style=\"background-color: #FFF4F4\"> as </span><span style=\"background-color: #FFE3E3\"> much </span><span style=\"background-color: #FFEDED\"> as </span><span style=\"background-color: #FFD1D1\"> the </span><span style=\"background-color: #FFB7B7\"> fact </span><span style=\"background-color: #FFA5A5\"> that </span><span style=\"background-color: #FFF5F5\"> they </span><span style=\"background-color: #FFEFEF\"> are </span><span style=\"background-color: #FFCFCF\"> stuck </span><span style=\"background-color: #FFE9E9\"> in </span><span style=\"background-color: #FFE3E3\"> dead </span><span style=\"background-color: #FFEAEA\"> end </span><span style=\"background-color: #FFC3C3\"> marriages </span><span style=\"background-color: #FFC8C8\"> with </span><span style=\"background-color: #FFE0E0\"> no </span><span style=\"background-color: #FFD2D2\"> passion </span><span style=\"background-color: #FFABAB\"> and </span><span style=\"background-color: #FFDADA\"> no </span><span style=\"background-color: #FF9292\"> rewards </span><span style=\"background-color: #FF7777\"> . </span><span style=\"background-color: #FFD7D7\"> this </span><span style=\"background-color: #FFDBDB\"> may </span><span style=\"background-color: #FFD1D1\"> play </span><span style=\"background-color: #FFE7E7\"> a </span><span style=\"background-color: #FFF2F2\"> part </span><span style=\"background-color: #FFE7E7\"> in </span><span style=\"background-color: #FFB2B2\"> the </span><span style=\"background-color: #FFE2E2\"> sexual </span><span style=\"background-color: #FF9B9B\"> awakening </span><span style=\"background-color: #FFE9E9\"> of </span><span style=\"background-color: #FFEEEE\"> the </span><span style=\"background-color: #FFEDED\"> characters </span><span style=\"background-color: #FF8B8B\"> , </span><span style=\"background-color: #FFE2E2\"> but </span><span style=\"background-color: #FFE4E4\"> most </span><span style=\"background-color: #FFE2E2\"> people </span><span style=\"background-color: #FFD8D8\"> stuck </span><span style=\"background-color: #FFEFEF\"> in </span><span style=\"background-color: #FFF3F3\"> the </span><span style=\"background-color: #FFEEEE\"> same </span><span style=\"background-color: #FFCECE\"> situation </span><span style=\"background-color: #FFD8D8\"> will </span><span style=\"background-color: #FFB8B8\"> not </span><span style=\"background-color: #FFC1C1\"> turn </span><span style=\"background-color: #FFD5D5\"> homosexual </span><span style=\"background-color: #FF7878\"> . </span><span style=\"background-color: #FFE9E9\"> it </span><span style=\"background-color: #FF7F7F\"> seems </span><span style=\"background-color: #FFDEDE\"> clear </span><span style=\"background-color: #FFCACA\"> from </span><span style=\"background-color: #FFEAEA\"> the </span><span style=\"background-color: #FFA9A9\"> beginning </span><span style=\"background-color: #FFEDED\"> of </span><span style=\"background-color: #FFEAEA\"> the </span><span style=\"background-color: #FFEEEE\"> film </span><span style=\"background-color: #FFADAD\"> that </span><span style=\"background-color: #FFECEC\"> the </span><span style=\"background-color: #FFEDED\"> two </span><span style=\"background-color: #FFF0F0\"> characters </span><span style=\"background-color: #FFF3F3\"> are </span><span style=\"background-color: #FFB8B8\"> quite </span><span style=\"background-color: #FFE3E3\"> heterosexual </span><span style=\"background-color: #FFE3E3\"> when </span><span style=\"background-color: #FF7676\"> radha </span><span style=\"background-color: #FFEEEE\"> does </span><span style=\"background-color: #FFF1F1\"> her </span><span style=\"background-color: #FFD4D4\"> scene </span><span style=\"background-color: #FFEAEA\"> at </span><span style=\"background-color: #FFF9F9\"> the </span><span style=\"background-color: #FFD6D6\"> end </span><span style=\"background-color: #FFFAFA\"> of </span><span style=\"background-color: #FFF0F0\"> the </span><span style=\"background-color: #FFEEEE\"> movie </span><span style=\"background-color: #FFEDED\"> with </span><span style=\"background-color: #FFF6F6\"> aa </span><span style=\"background-color: #FFF6F6\"> ##sho </span><span style=\"background-color: #FFE3E3\"> ##k </span><span style=\"background-color: #FFE0E0\"> , </span><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiAFbLgCLJBF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}